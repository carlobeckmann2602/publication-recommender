-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.06370' ...
--- pdf content written to temp file '/scraper/data/temp/2312.06370.txt'.
- calculate vectors for publication id '2312.06370' ...
--- tempfile '/scraper/data/temp/2312.06370.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.06370', 'title': 'On the maximum degree of induced subgraphs of the Kneser graph'}} to database.
-- collect api metadata of publication id '2312.06363' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.06363' ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 65, in run
    self.scrape_publications(start_at=pub_count, max_results=ArxivApiScraper.interval, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 170, in scrape_publications
    pdf_content = self.pdf_scraper.read_pdf(pdf_url, arxiv_id)
  File "/scraper/scraper/pdf_scraper.py", line 12, in read_pdf
    if self.pull(url, self.temp_file):
  File "/scraper/scraper/pdf_scraper.py", line 46, in pull
    txt_file.write(text)
UnicodeEncodeError: 'utf-8' codec can't encode characters in position 10999-11002: surrogates not allowed
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 265 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.08370, published 2023-12-13T18:59:07.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
- scraping 'http://export.arxiv.org/api/' for newest 874 publications at distance 0 from newest (0) ...
-- collect api metadata of publication id '2312.09244' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09244' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09244.txt'.
- calculate vectors for publication id '2312.09244' ...
--- tempfile '/scraper/data/temp/2312.09244.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09244', 'title': 'Helping or Herding? Reward Model Ensembles Mitigate but do not Eliminate Reward Hacking'}} to database.
-- collect api metadata of publication id '2312.09240' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09240' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09240.txt'.
- calculate vectors for publication id '2312.09240' ...
--- tempfile '/scraper/data/temp/2312.09240.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09240', 'title': 'Fractional corner charges induced by fragile topology in threefold symmetric two-dimensional materials'}} to database.
-- collect api metadata of publication id '2312.09222' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09222' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09222.txt'.
- calculate vectors for publication id '2312.09222' ...
--- tempfile '/scraper/data/temp/2312.09222.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09222', 'title': 'Mosaic-SDF for 3D Generative Models'}} to database.
-- collect api metadata of publication id '2312.09212' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09212' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09212.txt'.
- calculate vectors for publication id '2312.09212' ...
--- tempfile '/scraper/data/temp/2312.09212.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09212', 'title': 'The Twisted Gradient Flow strong coupling with Parallel Tempering on Boundary Conditions'}} to database.
-- collect api metadata of publication id '2312.09204' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09204' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09204.txt'.
- calculate vectors for publication id '2312.09204' ...
--- tempfile '/scraper/data/temp/2312.09204.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09204', 'title': 'Tuning the Josephson diode response with an ac current'}} to database.
-- collect api metadata of publication id '2312.09202' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09202' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09202.txt'.
- calculate vectors for publication id '2312.09202' ...
--- tempfile '/scraper/data/temp/2312.09202.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09202', 'title': 'On the evolution of structure in triangle-free graphs'}} to database.
-- collect api metadata of publication id '2312.09198' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09198' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09198.txt'.
- calculate vectors for publication id '2312.09198' ...
--- tempfile '/scraper/data/temp/2312.09198.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09198', 'title': 'Weaving Pathways for Justice with GPT: LLM-driven automated drafting of interactive legal applications'}} to database.
-- collect api metadata of publication id '2312.09195' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09195' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09195.txt'.
- calculate vectors for publication id '2312.09195' ...
--- tempfile '/scraper/data/temp/2312.09195.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09195', 'title': 'Isocrystals and limits of rigid local Langlands correspondences'}} to database.
-- collect api metadata of publication id '2312.09188' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09188' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09188.txt'.
- calculate vectors for publication id '2312.09188' ...
--- tempfile '/scraper/data/temp/2312.09188.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09188', 'title': 'JWST Reveals Star Formation Across a Spiral Arm in M33'}} to database.
-- collect api metadata of publication id '2312.09181' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09181' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09181.txt'.
- calculate vectors for publication id '2312.09181' ...
--- tempfile '/scraper/data/temp/2312.09181.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09181', 'title': 'Improving Efficiency of Diffusion Models via Multi-Stage Framework and Tailored Multi-Decoder Architectures'}} to database.
-- collect api metadata of publication id '2312.09171' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09171' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09171.txt'.
- calculate vectors for publication id '2312.09171' ...
--- tempfile '/scraper/data/temp/2312.09171.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09171', 'title': 'Coupled quintessence inspired by warm inflation'}} to database.
-- collect api metadata of publication id '2312.09170' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09170' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09170.txt'.
- calculate vectors for publication id '2312.09170' ...
--- tempfile '/scraper/data/temp/2312.09170.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09170', 'title': 'Memlumor: a luminescent memory device for photonic neuromorphic computing'}} to database.
-- collect api metadata of publication id '2312.09167' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09167' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09167.txt'.
- calculate vectors for publication id '2312.09167' ...
--- tempfile '/scraper/data/temp/2312.09167.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09167', 'title': 'Maximizing Nash Social Welfare under Two-Sided Preferences'}} to database.
-- collect api metadata of publication id '2312.09157' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09157' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09157.txt'.
- calculate vectors for publication id '2312.09157' ...
--- tempfile '/scraper/data/temp/2312.09157.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09157', 'title': 'Saxl conjecture and the tensor square of unipotent characters of GL(n,q)'}} to database.
-- collect api metadata of publication id '2312.09143' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09143' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09143.txt'.
- calculate vectors for publication id '2312.09143' ...
--- tempfile '/scraper/data/temp/2312.09143.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09143', 'title': 'F1-EV Score: Measuring the Likelihood of Estimating a Good Decision Threshold for Semi-Supervised Anomaly Detection'}} to database.
-- collect api metadata of publication id '2312.09123' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09123' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09123.txt'.
- calculate vectors for publication id '2312.09123' ...
--- tempfile '/scraper/data/temp/2312.09123.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09123', 'title': 'MRL-PoS: A Multi-agent Reinforcement Learning based Proof of Stake Consensus Algorithm for Blockchain'}} to database.
-- collect api metadata of publication id '2312.09122' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09122' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09122.txt'.
- calculate vectors for publication id '2312.09122' ...
--- tempfile '/scraper/data/temp/2312.09122.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09122', 'title': "Whitehead's problem and condensed mathematics"}} to database.
-- collect api metadata of publication id '2312.09118' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09118' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09118.txt'.
- calculate vectors for publication id '2312.09118' ...
--- tempfile '/scraper/data/temp/2312.09118.txt' has been deleted.
- saving publication to database ...
-- successfully saved {'savePublication': {'exId': '2312.09118', 'title': 'LayerZero'}} to database.
-- collect api metadata of publication id '2312.09115' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is not in database. proceeding ...
- collect pdf content of publication id '2312.09115' ...
--- pdf content written to temp file '/scraper/data/temp/2312.09115.txt'.
- calculate vectors for publication id '2312.09115' ...
--- tempfile '/scraper/data/temp/2312.09115.txt' has been deleted.
- saving publication to database ...
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/gql/transport/aiohttp.py", line 304, in raise_response_error
    resp.raise_for_status()
  File "/usr/local/lib/python3.10/site-packages/aiohttp/client_reqrep.py", line 1059, in raise_for_status
    raise ClientResponseError(
aiohttp.client_exceptions.ClientResponseError: 413, message='Payload Too Large', url=URL('http://nest:3000/graphql')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 203, in scrape_publications
    self.db_api.add_arxiv_pub(pub)
  File "/scraper/db/database_api.py", line 117, in add_arxiv_pub
    result = self.gql_client.execute(mutation, variable_values=params)
  File "/usr/local/lib/python3.10/site-packages/gql/client.py", line 388, in execute
    data = loop.run_until_complete(
  File "/usr/local/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.10/site-packages/gql/client.py", line 285, in execute_async
    return await session.execute(
  File "/usr/local/lib/python3.10/site-packages/gql/client.py", line 1220, in execute
    result = await self._execute(
  File "/usr/local/lib/python3.10/site-packages/gql/client.py", line 1126, in _execute
    result = await asyncio.wait_for(
  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 445, in wait_for
    return fut.result()
  File "/usr/local/lib/python3.10/site-packages/gql/transport/aiohttp.py", line 326, in execute
    await raise_response_error(resp, 'No "data" or "errors" keys in answer')
  File "/usr/local/lib/python3.10/site-packages/gql/transport/aiohttp.py", line 306, in raise_response_error
    raise TransportServerError(str(e), e.status) from e
gql.transport.exceptions.TransportServerError: 413, message='Payload Too Large', url=URL('http://nest:3000/graphql')
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
-- collect api metadata of publication id '2312.07047' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07047 ...
-- collect api metadata of publication id '2312.07041' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07041 ...
-- collect api metadata of publication id '2312.07038' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07038 ...
-- collect api metadata of publication id '2312.07035' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07035 ...
-- collect api metadata of publication id '2312.07019' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07019 ...
-- collect api metadata of publication id '2312.07009' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07009 ...
-- collect api metadata of publication id '2312.07005' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07005 ...
-- collect api metadata of publication id '2312.07004' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07004 ...
-- collect api metadata of publication id '2312.07000' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07000 ...
-- collect api metadata of publication id '2312.06992' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06992 ...
-- collect api metadata of publication id '2312.06989' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06989 ...
-- collect api metadata of publication id '2312.06981' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06981 ...
-- collect api metadata of publication id '2312.06963' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06963 ...
-- collect api metadata of publication id '2312.06962' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06962 ...
-- collect api metadata of publication id '2312.06961' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06961 ...
-- collect api metadata of publication id '2312.06953' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06953 ...
-- collect api metadata of publication id '2312.06950' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06950 ...
-- collect api metadata of publication id '2312.06940' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06940 ...
-- collect api metadata of publication id '2312.06939' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06939 ...
-- collect api metadata of publication id '2312.06928' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06928 ...
-- collect api metadata of publication id '2312.06914' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06914 ...
-- collect api metadata of publication id '2312.06906' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06906 ...
-- collect api metadata of publication id '2312.06902' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06902 ...
-- collect api metadata of publication id '2312.06900' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06900 ...
-- collect api metadata of publication id '2312.06895' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06895 ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
-- collect api metadata of publication id '2312.07047' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07047 ...
-- collect api metadata of publication id '2312.07041' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07041 ...
-- collect api metadata of publication id '2312.07038' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07038 ...
-- collect api metadata of publication id '2312.07035' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07035 ...
-- collect api metadata of publication id '2312.07019' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07019 ...
-- collect api metadata of publication id '2312.07009' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07009 ...
-- collect api metadata of publication id '2312.07005' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07005 ...
-- collect api metadata of publication id '2312.07004' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07004 ...
-- collect api metadata of publication id '2312.07000' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07000 ...
-- collect api metadata of publication id '2312.06992' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06992 ...
-- collect api metadata of publication id '2312.06989' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06989 ...
-- collect api metadata of publication id '2312.06981' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06981 ...
-- collect api metadata of publication id '2312.06963' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06963 ...
-- collect api metadata of publication id '2312.06962' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06962 ...
-- collect api metadata of publication id '2312.06961' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06961 ...
-- collect api metadata of publication id '2312.06953' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06953 ...
-- collect api metadata of publication id '2312.06950' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06950 ...
-- collect api metadata of publication id '2312.06940' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06940 ...
-- collect api metadata of publication id '2312.06939' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06939 ...
-- collect api metadata of publication id '2312.06928' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06928 ...
-- collect api metadata of publication id '2312.06914' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06914 ...
-- collect api metadata of publication id '2312.06906' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06906 ...
-- collect api metadata of publication id '2312.06902' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06902 ...
-- collect api metadata of publication id '2312.06900' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06900 ...
-- collect api metadata of publication id '2312.06895' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06895 ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
-- collect api metadata of publication id '2312.07047' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07047 ...
-- collect api metadata of publication id '2312.07041' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07041 ...
-- collect api metadata of publication id '2312.07038' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07038 ...
-- collect api metadata of publication id '2312.07035' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07035 ...
-- collect api metadata of publication id '2312.07019' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07019 ...
-- collect api metadata of publication id '2312.07009' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07009 ...
-- collect api metadata of publication id '2312.07005' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07005 ...
-- collect api metadata of publication id '2312.07004' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07004 ...
-- collect api metadata of publication id '2312.07000' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07000 ...
-- collect api metadata of publication id '2312.06992' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06992 ...
-- collect api metadata of publication id '2312.06989' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06989 ...
-- collect api metadata of publication id '2312.06981' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06981 ...
-- collect api metadata of publication id '2312.06963' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06963 ...
-- collect api metadata of publication id '2312.06962' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06962 ...
-- collect api metadata of publication id '2312.06961' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06961 ...
-- collect api metadata of publication id '2312.06953' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06953 ...
-- collect api metadata of publication id '2312.06950' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06950 ...
-- collect api metadata of publication id '2312.06940' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06940 ...
-- collect api metadata of publication id '2312.06939' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06939 ...
-- collect api metadata of publication id '2312.06928' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06928 ...
-- collect api metadata of publication id '2312.06914' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06914 ...
-- collect api metadata of publication id '2312.06906' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06906 ...
-- collect api metadata of publication id '2312.06902' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06902 ...
-- collect api metadata of publication id '2312.06900' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06900 ...
-- collect api metadata of publication id '2312.06895' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06895 ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
-- collect api metadata of publication id '2312.07047' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07047 ...
-- collect api metadata of publication id '2312.07041' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07041 ...
-- collect api metadata of publication id '2312.07038' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07038 ...
-- collect api metadata of publication id '2312.07035' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07035 ...
-- collect api metadata of publication id '2312.07019' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07019 ...
-- collect api metadata of publication id '2312.07009' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07009 ...
-- collect api metadata of publication id '2312.07005' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07005 ...
-- collect api metadata of publication id '2312.07004' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07004 ...
-- collect api metadata of publication id '2312.07000' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07000 ...
-- collect api metadata of publication id '2312.06992' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06992 ...
-- collect api metadata of publication id '2312.06989' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06989 ...
-- collect api metadata of publication id '2312.06981' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06981 ...
-- collect api metadata of publication id '2312.06963' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06963 ...
-- collect api metadata of publication id '2312.06962' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06962 ...
-- collect api metadata of publication id '2312.06961' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06961 ...
-- collect api metadata of publication id '2312.06953' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06953 ...
-- collect api metadata of publication id '2312.06950' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06950 ...
-- collect api metadata of publication id '2312.06940' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06940 ...
-- collect api metadata of publication id '2312.06939' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06939 ...
-- collect api metadata of publication id '2312.06928' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06928 ...
-- collect api metadata of publication id '2312.06914' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06914 ...
-- collect api metadata of publication id '2312.06906' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06906 ...
-- collect api metadata of publication id '2312.06902' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06902 ...
-- collect api metadata of publication id '2312.06900' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06900 ...
-- collect api metadata of publication id '2312.06895' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06895 ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 45, in run
    id_new = self.scrape_newest_id() # '2311.17055'
  File "/scraper/scraper/arxiv_api_scraper.py", line 105, in scrape_newest_id
    print("-- found newest publication with id '" + arxiv_id + "'.")
TypeError: can only concatenate str (not "NoneType") to str
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.09244'.
--- id_new: 2312.09244 -> YY:23, MM: 12, NUM: 9244
--- pub_count: 283, interval: 25
- scraping 'http://export.arxiv.org/api/' for newest 25 publications at distance 283 from newest (0) ...
-- collect api metadata of publication id '2312.07047' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07047 ...
-- collect api metadata of publication id '2312.07041' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07041 ...
-- collect api metadata of publication id '2312.07038' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07038 ...
-- collect api metadata of publication id '2312.07035' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07035 ...
-- collect api metadata of publication id '2312.07019' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07019 ...
-- collect api metadata of publication id '2312.07009' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07009 ...
-- collect api metadata of publication id '2312.07005' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07005 ...
-- collect api metadata of publication id '2312.07004' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07004 ...
-- collect api metadata of publication id '2312.07000' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.07000 ...
-- collect api metadata of publication id '2312.06992' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06992 ...
-- collect api metadata of publication id '2312.06989' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06989 ...
-- collect api metadata of publication id '2312.06981' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06981 ...
-- collect api metadata of publication id '2312.06963' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06963 ...
-- collect api metadata of publication id '2312.06962' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06962 ...
-- collect api metadata of publication id '2312.06961' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06961 ...
-- collect api metadata of publication id '2312.06953' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06953 ...
-- collect api metadata of publication id '2312.06950' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06950 ...
-- collect api metadata of publication id '2312.06940' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06940 ...
-- collect api metadata of publication id '2312.06939' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06939 ...
-- collect api metadata of publication id '2312.06928' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06928 ...
-- collect api metadata of publication id '2312.06914' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06914 ...
-- collect api metadata of publication id '2312.06906' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06906 ...
-- collect api metadata of publication id '2312.06902' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06902 ...
-- collect api metadata of publication id '2312.06900' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06900 ...
-- collect api metadata of publication id '2312.06895' ...
- requesting db api if arxiv id is already in database ...
-- requested arxiv id is already in database. skipping 2312.06895 ...
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 45, in run
    id_new = self.scrape_newest_id() # '2311.17055'
  File "/scraper/scraper/arxiv_api_scraper.py", line 105, in scrape_newest_id
    print("-- found newest publication with id '" + arxiv_id + "'.")
TypeError: can only concatenate str (not "NoneType") to str
ArxivApiScraper.run()
- requesting db api for arxiv publication count ...
-- found 283 entries.
- requesting db api for oldest arxiv publication ...
-- found arxiv id 2312.09244, published 2023-12-14T18:59:04.000Z.
- scraping 'http://export.arxiv.org/api/' for newest arxiv publication ...
-- found newest publication with id '2312.08370'.
--- id_new: 2312.08370 -> YY:23, MM: 12, NUM: 8370
- scraping 'http://export.arxiv.org/api/' for newest -874 publications at distance 0 from newest (0) ...
Traceback (most recent call last):
  File "/scraper/main.py", line 5, in <module>
    ac.run()
  File "/scraper/scraper/arxiv_api_scraper.py", line 59, in run
    self.scrape_publications(start_at=0, max_results=distance, descending=True)
  File "/scraper/scraper/arxiv_api_scraper.py", line 123, in scrape_publications
    with libreq.urlopen(url) as self.response:
  File "/usr/local/lib/python3.10/urllib/request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.10/urllib/request.py", line 525, in open
    response = meth(req, response)
  File "/usr/local/lib/python3.10/urllib/request.py", line 634, in http_response
    response = self.parent.error(
  File "/usr/local/lib/python3.10/urllib/request.py", line 563, in error
    return self._call_chain(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 496, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.10/urllib/request.py", line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 400: Bad Request
 *  Terminal will be reused by tasks, press any key to close it. 
