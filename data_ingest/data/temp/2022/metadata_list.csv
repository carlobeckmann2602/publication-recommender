arxiv_id,title,authors,src,url,pub_date,upd_date,doi,abstract
2201.00278,Bistability of the large-scale dynamics in quasi-two-dimensional turbulence,"['Xander M. de Wit', 'Adrian van Kan', 'Alexandros Alexakis']",ARXIV,http://arxiv.org/pdf/2201.00278v2,2022-01-02T02:35:55Z,2022-03-18T15:02:09Z,"['10.48550/arXiv.2201.00278', '10.1017/jfm.2022.209']","In many geophysical and astrophysical flows, suppression of fluctuations along one direction of the flow drives a quasi-2D upscale flux of kinetic energy, leading to the formation of strong vortex condensates at the largest scales. Recent studies have shown that the transition towards this condensate state is hysteretic, giving rise to a limited bistable range in which both the condensate state as well as the regular 3D state can exist at the same parameter values. In this work, we use direct numerical simulations of thin-layer flow to investigate whether this bistable range survives as the domain size and turbulence intensity are increased. By studying the time scales at which rare transitions occur from one state into the other, we find that the bistable range grows as the box size and/or Reynolds number Re are increased, showing that the bistability is neither a finite-size nor a finite-Re effect. We furthermore predict a crossover from a bimodal regime at low box size, low Re to a regime of pure hysteresis at high box size, high Re, in which any transition from one state to the other is prohibited at any finite time scale."
2201.00474,Asymptotics of $k$-nearest neighbor Riesz energies,"['Douglas P. Hardin', 'Edward B. Saff', 'Oleksandr Vlasiuk']",ARXIV,http://arxiv.org/pdf/2201.00474v2,2022-01-03T05:01:38Z,2023-03-20T03:56:54Z,['10.48550/arXiv.2201.00474'],"We obtain new asymptotic results about systems of $ N $ particles governed by Riesz interactions involving $ k $-nearest neighbors of each particle as $N\to\infty$. These results include a generalization to weighted Riesz potentials with external field. Such interactions offer an appealing alternative to other approaches for reducing the computational complexity of an $ N $-body interaction. We find the first-order term of the large $ N $ asymptotics and characterize the limiting distribution of the minimizers. We also obtain results about the $ \Gamma $-convergence of such interactions, and describe minimizers on the 1-dimensional flat torus in the absence of external field, for all $ N $."
2201.00246,Machine Learning approach to the Floquet--Lindbladian problem,"['V. Volokitin', 'I. Meyerov', 'S. Denisov']",ARXIV,http://arxiv.org/pdf/2201.00246v2,2022-01-01T22:36:15Z,2022-01-21T19:29:32Z,"['10.48550/arXiv.2201.00246', '10.1063/5.0086062']","Similar to its classical version, quantum Markovian evolution can be either time-discrete or time-continuous. Discrete quantum Markovian evolution is usually modeled with completely-positive trace-preserving maps while time-continuous evolution is often specified with superoperators referred to as ""Lindbladians"". Here we address the following question: Being given a quantum map, can we find a Lindbladian which generates an evolution identical -- when monitored at discrete instances of time -- to the one induced by the map? It was demonstrated that the problem of getting the answer to this question can be reduced to an NP-complete (in the dimension $N$ of the Hilbert space the evolution takes place in) problem. We approach this question from a different perspective by considering a variety of Machine Learning (ML) methods and trying to estimate their potential ability to give the correct answer. Complimentary, we use the performance of different ML methods as a tool to check the hypothesis that the answer to the question is encoded in spectral properties of the so-called Choi matrix, which can be constructed from the given quantum map. As a test bed, we use two single-qubit models for which the answer can be obtained by using the reduction procedure. The outcome of our experiment is that, for a given map, the property of being generated by a time-independent Lindbladian is encoded both in the eigenvalues and the eigenstates of the corresponding Choi matrix."
2201.00425,The Fixed Point Property of Quasi-Point-Separable Topological Vector Spaces,['Jinlu Li'],ARXIV,http://arxiv.org/pdf/2201.00425v1,2022-01-02T22:15:24Z,2022-01-02T22:15:24Z,['10.48550/arXiv.2201.00425'],"In this paper, we introduce the concept of quasi-point-separable topological vector spaces, which has the following important properties: 1.In general, the conditions for a topological vector space to be quasi-point-separable is not very difficult to check; 2.The class of quasi-point-separable topological vector spaces is very large that includes locally convex topological vector spaces and pseudonorm adjoint topological vector spaces as special cases; 3.Every quasi-point-separable Housdorrf topological vector space has the fixed point property (that is, every continuous self-mapping on any given nonempty closed and convex subset has a fixed point), which is the result of the main theorem of this paper (Theorem 4.1). Furthermore, we provide some concrete examples of quasi-point-separable topological vector spaces, which are not locally convex. It follows that the main theorem of this paper is a proper extension of Tychonoffs fixed point theorem on locally convex topological vector spaces."
2201.00457,Exploring Motion and Appearance Information for Temporal Sentence Grounding,"['Daizong Liu', 'Xiaoye Qu', 'Pan Zhou', 'Yang Liu']",ARXIV,http://arxiv.org/pdf/2201.00457v1,2022-01-03T02:44:18Z,2022-01-03T02:44:18Z,['10.48550/arXiv.2201.00457'],"This paper addresses temporal sentence grounding. Previous works typically solve this task by learning frame-level video features and align them with the textual information. A major limitation of these works is that they fail to distinguish ambiguous video frames with subtle appearance differences due to frame-level feature extraction. Recently, a few methods adopt Faster R-CNN to extract detailed object features in each frame to differentiate the fine-grained appearance similarities. However, the object-level features extracted by Faster R-CNN suffer from missing motion analysis since the object detection model lacks temporal modeling. To solve this issue, we propose a novel Motion-Appearance Reasoning Network (MARN), which incorporates both motion-aware and appearance-aware object features to better reason object relations for modeling the activity among successive frames. Specifically, we first introduce two individual video encoders to embed the video into corresponding motion-oriented and appearance-aspect object representations. Then, we develop separate motion and appearance branches to learn motion-guided and appearance-guided object relations, respectively. At last, both motion and appearance information from two branches are associated to generate more representative features for final grounding. Extensive experiments on two challenging datasets (Charades-STA and TACoS) show that our proposed MARN significantly outperforms previous state-of-the-art methods by a large margin."
2201.00379,Some Modifications of Getzler's Grading technique,['Andres Larrain-Hubach'],ARXIV,http://arxiv.org/pdf/2201.00379v1,2022-01-02T17:12:39Z,2022-01-02T17:12:39Z,['10.48550/arXiv.2201.00379'],This paper reviews the grading technique developed by Getzler to prove the local index theorem and shows how to adapt it to compute the leading terms of asymptotic expansions of traces of heat kernels in two other situations.
2201.00305,Congruence relations satisfied by quaternionic modular forms,['Shoyu Nagaoka'],ARXIV,http://arxiv.org/pdf/2201.00305v1,2022-01-02T06:32:51Z,2022-01-02T06:32:51Z,['10.48550/arXiv.2201.00305'],The theory of quaternionic modular forms has been studied for decades as an example of the modular forms of many variables. The purpose of this study is to provide some congruence relations satisfied by such quaternionic modular forms.
2201.00449,Aerogel from sustainably grown bacterial cellulose pellicle as thermally insulative film for building envelope,"['Blaise Fleury', 'Eldho Abraham', 'Joshua A. De La Cruz', 'Varun S. Chandrasekar', 'Bohdan Senyuk', 'Qingkun Liu', 'Vladyslav Cherpak', 'Sungoh Park', 'Jan Bart ten Hove', 'Ivan I. Smalyukh']",ARXIV,http://arxiv.org/pdf/2201.00449v1,2022-01-03T01:52:02Z,2022-01-03T01:52:02Z,"['10.48550/arXiv.2201.00449', '10.1021/acsami.0c08879']","Improving building energy performance requires the development of new highly insulative materials. An affordable retrofitting solution comprising a thin film could improve the resistance to heat flow in both residential and commercial buildings and reduce overall energy consumption. Here we propose cellulose aerogel films formed from pellicles produced by the bacteria Gluconacetobacter hansenii as insulation materials. We studied the impact of density and nanostructure on the aerogels' thermal properties. Thermal conductivity as low as 13 mW/(K*m) was measured for native pellicle-based aerogels dried as-is with minimal post-treatment. The use of waste from the beer brewing industry as a solution to grow the pellicle maintained the cellulose yield obtained with standard Hestrin-Schramm medium, making our product more affordable and sustainable. In the future, our work can be extended through further diversification of the sources of substrate among food wastes, facilitating larger potential production and applications."
2201.00283,DF-SSmVEP: Dual Frequency Aggregated Steady-State Motion Visual Evoked Potential Design with Bifold Canonical Correlation Analysis,"['Raika Karimi', 'Arash Mohammadi', 'Amir Asif', 'Habib Benali']",ARXIV,http://arxiv.org/pdf/2201.00283v1,2022-01-02T04:10:54Z,2022-01-02T04:10:54Z,['10.48550/arXiv.2201.00283'],"Recent advancements in Electroencephalography (EEG) sensor technologies and signal processing algorithms have paved the way for further evolution of Brain Computer Interfaces (BCI). When it comes to Signal Processing (SP) for BCI, there has been a surge of interest on Steady-State motion-Visual Evoked Potentials (SSmVEP), where motion stimulation is utilized to address key issues associated with conventional light-flashing/flickering. Such benefits, however, come with the price of having less accuracy and less Information Transfer Rate (ITR). In this regard, the paper focuses on the design of a novel SSmVEP paradigm without using resources such as trial time, phase, and/or number of targets to enhance the ITR. The proposed design is based on the intuitively pleasing idea of integrating more than one motion within a single SSmVEP target stimuli, simultaneously. To elicit SSmVEP, we designed a novel and innovative dual frequency aggregated modulation paradigm, referred to as the Dual Frequency Aggregated steady-state motion Visual Evoked Potential (DF-SSmVEP), by concurrently integrating ""Radial Zoom"" and ""Rotation"" motions in a single target without increasing the trial length. Compared to conventional SSmVEPs, the proposed DF-SSmVEP framework consists of two motion modes integrated and shown simultaneously each modulated by a specific target frequency. The paper also develops a specific unsupervised classification model, referred to as the Bifold Canonical Correlation Analysis (BCCA), based on two motion frequencies per target. The proposed DF-SSmVEP is evaluated based on a real EEG dataset and the results corroborate its superiority. The proposed DF-SSmVEP outperforms its counterparts and achieved an average ITR of 30.7 +/- 1.97 and an average accuracy of 92.5 +/- 2.04."
2201.00392,Fast and High-Quality Image Denoising via Malleable Convolutions,"['Yifan Jiang', 'Bartlomiej Wronski', 'Ben Mildenhall', 'Jonathan T. Barron', 'Zhangyang Wang', 'Tianfan Xue']",ARXIV,http://arxiv.org/pdf/2201.00392v3,2022-01-02T18:35:20Z,2022-08-09T00:47:24Z,['10.48550/arXiv.2201.00392'],"Most image denoising networks apply a single set of static convolutional kernels across the entire input image. This is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Dynamic convolution tries to address this issue by using per-pixel convolution kernels, but this greatly increases computational cost. In this work, we present Malleable Convolution (MalleConv), which performs spatial-varying processing with minimal computational overhead. MalleConv uses a smaller set of spatially-varying convolution kernels, a compromise between static and per-pixel convolution kernels. These spatially-varying kernels are produced by an efficient predictor network running on a downsampled input, making them much more efficient to compute than per-pixel kernels produced by a full-resolution image, and also enlarging the network's receptive field compared with static kernels. These kernels are then jointly upsampled and applied to a full-resolution feature map through an efficient on-the-fly slicing operator with minimum memory overhead. To demonstrate the effectiveness of MalleConv, we use it to build an efficient denoising network we call MalleNet. MalleNet achieves high-quality results without very deep architectures, making it 8.9x faster than the best performing denoising algorithms while achieving similar visual quality. We also show that a single MalleConv layer added to a standard convolution-based backbone can significantly reduce the computational cost or boost image quality at a similar cost. More information is on our project page: \url{https://yifanjiang.net/MalleConv.html}"
2201.00114,"Machine learning analysis of cocaine addiction informed by DAT, SERT, and NET-based interactome networks","['Hongsong Feng', 'Kaifu Gao', 'Dong Chen', 'Alfred J Robison', 'Edmund Ellsworth', 'Guo-Wei Wei']",ARXIV,http://arxiv.org/pdf/2201.00114v1,2022-01-01T04:49:20Z,2022-01-01T04:49:20Z,['10.48550/arXiv.2201.00114'],"Cocaine addiction is a psychosocial disorder induced by the chronic use of cocaine and causes a large of number deaths around the world. Despite many decades' effort, no drugs have been approved by the Food and Drug Administration (FDA) for the treatment of cocaine dependence. Cocaine dependence is neurological and involves many interacting proteins in the interactome. Among them, dopamine transporter (DAT), serotonin transporter (SERT), and norepinephrine transporter (NET) are three major targets. Each of these targets has a large protein-protein interaction (PPI) network which must be considered in the anti-cocaine addiction drug discovery. This work presents DAT, SERT, and NET interactome network-informed machine learning/deep learning (ML/DL) studies of cocaine addiction. We collect and analyze 61 protein targets out 460 proteins in the DAT, SERT, and NET PPI networks that have sufficient existing inhibitor datasets. Utilizing autoencoder and other ML algorithms, we build ML/DL models for these targets with 115,407 inhibitors to predict drug repurposing potentials and possible side effects. We further screen their absorption, distribution, metabolism, and excretion, and toxicity (ADMET) properties to search for nearly optimal leads for anti-cocaine addiction. Our approach sets up a systematic protocol for artificial intelligence (AI)-based anti-cocaine addiction lead discovery."
2201.00221,Event structure semantics for multiparty sessions,"['Ilaria Castellani', 'Mariangiola Dezani-Ciancaglini', 'Paola Giannini']",ARXIV,http://arxiv.org/pdf/2201.00221v2,2022-01-01T17:43:17Z,2022-05-17T04:58:09Z,['10.48550/arXiv.2201.00221'],"We propose an interpretation of multiparty sessions as ""flow event structures"", which allows concurrency between communications within a session to be explicitly represented. We show that this interpretation is equivalent, when the multiparty sessions can be described by global types, to an interpretation of global types as ""prime event structures""."
2201.00250,"The Affinity of the Sulfate- and Ether-Containing Surface-Active Ionic Liquids to Carbon Dioxide, Hydrogen Fluoride, Hydrogen Sulfide, and Water",['Vitaly V. Chaban'],ARXIV,http://arxiv.org/pdf/2201.00250v1,2022-01-01T22:50:09Z,2022-01-01T22:50:09Z,['10.48550/arXiv.2201.00250'],"The development of novel task-specific ionic liquids (ILs) represents an essential challenge in modern organic and physical chemistries. Recently we reported surface-active ILs contained the two well-known organic cations (1-butyl-3-methylimidazolium and tetrabutylammonium) and the two surface-active anions (lauryl sulfate, lauryl ether sulfate). In the present work, we investigate the affinity of these ionic compounds to the selected small molecules that exhibit practical implications: water, hydrogen fluoride, hydrogen sulfate, and carbon dioxide. We identified that the sulfate group, the ether groups, and the aromatic imidazole ring make the strongest contributions to the physical sorption of the polar gas molecules. In turn, the tetrabutylammonium cation, the saturated hydrocarbon chain of the anions, and the alkyl chains of 1-butyl-3-methylimidazolium contribute to a significantly smaller extent. The reported data are interesting in the context of using surface-active ILs in the oil industry to capture and store undesirable and toxic gases."
2201.00359,Gate-tuneable and chirality-dependent charge-to-spin conversion in Tellurium nanowires,"['Francesco Calavalle', 'Manuel Suárez-Rodríguez', 'Beatriz Martín-García', 'Annika Johansson', 'Diogo C. Vaz', 'Haozhe Yang', 'Igor V. Maznichenko', 'Sergey Ostanin Aurelio Mateo-Alonso', 'Andrey Chuvilin', 'Ingrid Mertig', 'Marco Gobbi', 'Fèlix Casanova', 'Luis E. Hueso']",ARXIV,http://arxiv.org/pdf/2201.00359v1,2022-01-02T14:11:46Z,2022-01-02T14:11:46Z,"['10.48550/arXiv.2201.00359', '10.1038/s41563-022-01211-7']","Chiral materials are the ideal playground for exploring the relation between symmetry, relativistic effects, and electronic transport. For instance, chiral organic molecules have been intensively studied to electrically generate spin-polarized currents in the last decade, but their poor electronic conductivity limits their potential for applications. Conversely, chiral inorganic materials such as Tellurium are excellent electrical transport materials, but have not been explored to enable the electrical control of spin polarization in devices. Here, we demonstrate the all-electrical generation, manipulation, and detection of spin polarization in chiral single-crystalline Tellurium nanowires. By recording a large (up to 7%) and chirality-dependent unidirectional magnetoresistance, we show that the orientation of the electrically generated spin polarization is determined by the nanowire handedness and uniquely follows the current direction, while its magnitude can be manipulated by an electrostatic gate. Our results pave the way for the development of magnet-free chirality-based spintronic devices."
2201.00357,Pseudorandom Vector Generation Using Elliptic Curves And Applications,['Chung Pang Mok'],ARXIV,http://arxiv.org/pdf/2201.00357v8,2022-01-02T13:21:49Z,2022-10-09T01:11:53Z,['10.48550/arXiv.2201.00357'],"In this paper we present, using the arithmetic of elliptic curves over finite fields, an algorithm for the efficient generation of a sequence of uniform pseudorandom vectors in high dimensions, that simulates a sample of a sequence of i.i.d. random variables, with values in the hypercube $[0,1]^d$ with uniform distribution. As an application, we obtain, in the discrete time simulation, an efficient algorithm to simulate, uniformly distributed sample path sequence of a sequence of independent standard Wiener processes. This could be employed for use, in the full history recursive multi-level Picard approximation method, for numerically solving the class of semilinear parabolic partial differential equations of the Kolmogorov type."
2201.00264,Estimating Discretization Error with Preset Orders of Accuracy and Fractional Refinement Ratios,['Sharp Chim Yui Lo'],ARXIV,http://arxiv.org/pdf/2201.00264v2,2022-01-01T23:54:13Z,2022-04-11T13:37:29Z,"['10.48550/arXiv.2201.00264', '10.1115/1.4056491']","Verification of solutions is crucial for establishing the reliability of simulations. A central challenge is to find an accurate and reliable estimate of the discretization error. Current approaches to this estimation rely on the observed order of accuracy; however, studies have shown that it may alter irregularly or become undefined. Therefore, we propose a grid refinement method which adopts constant orders given by the user, called the Preset Orders Expansion Method (POEM). The user is guaranteed to obtain the optimal set of orders through iterations and hence an accurate estimate of the discretization error. This method evaluates the reliability of the estimation by assessing the convergence of the expansion terms, which is fundamental for all grid refinement methods. We demonstrate these capabilities using advection and diffusion problems along different refinement paths. POEM requires a lower computational cost when the refinement ratio is higher. However, the estimated error suffers from higher uncertainty due to the reduced number of shared grid points. We circumvent this by using fractional refinement ratios and the Method of Interpolating Differences between Approximate Solutions (MIDAS). As a result, we can obtain a global estimate of the discretization error of lower uncertainty at a reduced computational cost."
2201.00445,Qubit assignment using time reversal,"['Evan Peters', 'Prasanth Shyamsundar', 'Andy C. Y. Li', 'Gabriel Perdue']",ARXIV,http://arxiv.org/pdf/2201.00445v2,2022-01-03T01:12:44Z,2023-01-09T18:56:45Z,"['10.48550/arXiv.2201.00445', '10.1103/PRXQuantum.3.040333']","As the number of qubits available on noisy quantum computers grows, it will become necessary to efficiently select a subset of physical qubits to use in a quantum computation. For any given quantum program and device there are many ways to assign physical qubits for execution of the program, and assignments will differ in performance due to the variability in quality across qubits and entangling operations on a single device. Evaluating the performance of each assignment using fidelity estimation introduces significant experimental overhead and will be infeasible for many applications, while relying on standard device benchmarks provides incomplete information about the performance of any specific program. Furthermore, the number of possible assignments grows combinatorially in the number of qubits on the device and in the program, motivating the use of heuristic optimization techniques. We approach this problem using simulated annealing with a cost function based on the Loschmidt Echo, a diagnostic that measures the reversibility of a quantum process. We provide theoretical justification for this choice of cost function by demonstrating that the optimal qubit assignment coincides with the optimal qubit assignment based on state fidelity in the weak error limit, and we provide experimental justification using diagnostics performed on Google's superconducting qubit devices. We then establish the performance of simulated annealing for qubit assignment using classical simulations of noisy devices as well as optimization experiments performed on a quantum processor. Our results demonstrate that the use of Loschmidt Echoes and simulated annealing provides a scalable and flexible approach to optimizing qubit assignment on near-term hardware."
2201.00312,Tunable Magnonic Chern Bands and Chiral Spin Currents in Magnetic Multilayers,"['Zhongqiang Hu', 'Liang Fu', 'Luqiao Liu']",ARXIV,http://arxiv.org/pdf/2201.00312v2,2022-01-02T07:05:20Z,2022-01-08T18:47:27Z,"['10.48550/arXiv.2201.00312', '10.1103/PhysRevLett.128.217201']","Realization of novel topological phases in magnonic band structures represents a new opportunity for the development of spintronics and magnonics with low power consumption. In this work, we show that in antiparallelly aligned magnetic multilayers, the long-range, chiral dipolar interaction generates bulk bands with non-zero Chern integers and magnonic surface states carrying chiral spin currents. The surface states are strictly localized and can be easily toggled between non-trivial and trivial phases through an external magnetic field. The realization of chiral surface spin currents in this dipolarly coupled heterostructure represents a magnonic implementation of the coupled wire model that has been extensively explored in electronic systems. Our work presents an easy-to-implement system for realizing topological magnonic surface states and low-dissipation spin current transport in a tunable manner."
2201.00036,The extremality of 2-partite Turán graphs with respect to the number of colorings,['Melissa M Fuentes'],ARXIV,http://arxiv.org/pdf/2201.00036v2,2021-12-31T19:30:07Z,2022-09-20T16:06:30Z,['10.48550/arXiv.2201.00036'],"We consider a problem proposed by Linial and Wilf to determine the structure of graphs that allows the maximum number of $q$-colorings among graphs with $n$ vertices and $m$ edges. Let $T_r(n)$ denote the Tur\'{a}n graph - the complete $r$-partite graph on $n$ vertices with partition sizes as equal as possible. We prove that for all odd integers $q\geq 5$ and sufficiently large $n$, the Tur\'{a}n graph $T_2(n)$ has at least as many $q$-colorings as any other graph $G$ with the same number of vertices and edges as $T_2(n)$, with equality holding if and only if $G=T_2(n)$. Our proof builds on methods by Norine and by Loh, Pikhurko, and Sudakov, which reduces the problem to a quadratic program."
2201.00423,Less can be more: Insights on the role of electrode microstructure in redox flow batteries from 2D direct numerical simulations,"['Simone Dussi', 'Chris H. Rycroft']",ARXIV,http://arxiv.org/pdf/2201.00423v1,2022-01-02T21:57:51Z,2022-01-02T21:57:51Z,['10.48550/arXiv.2201.00423'],"Understanding how to structure a porous electrode to facilitate fluid, mass, and charge transport is key to enhance the performance of electrochemical devices such as fuel cells, electrolyzers, and redox flow batteries (RFBs). Using a parallel computational framework, direct numerical simulations are carried out on idealized porous electrode microstructures for RFBs. Strategies to improve electrode design starting from a regular lattice are explored. We observe that by introducing vacancies in the ordered arrangement, it is possible to achieve higher voltage efficiency at a given current density, thanks to improved mixing of reactive species, despite reducing the total reactive surface. Careful engineering of the location of vacancies, resulting in a density gradient, outperforms disordered configurations. Our simulation framework is a new tool to explore transport phenomena in RFBs and our findings suggest new ways to design performant electrodes."
2201.00225,Neural networks based on ultrafast time-delayed effects in exciton-polaritons,"['Rafał Mirek', 'Andrzej Opala', 'Magdalena Furman', 'Mateusz Król', 'Krzysztof Tyszka', 'Bartłomiej Seredyński', 'Wojciech Pacuski', 'Jan Suffczyński', 'Jacek Szczytko', 'Michał Matuszewski', 'Barbara Piętka']",ARXIV,http://arxiv.org/pdf/2201.00225v1,2022-01-01T18:04:40Z,2022-01-01T18:04:40Z,"['10.48550/arXiv.2201.00225', '10.1103/PhysRevApplied.17.054037']",We demonstrate that time-delayed nonlinear effects in exciton-polaritons can be used to construct neural networks where information is coded in optical pulses arriving consecutively on the sample. The highly nonlinear effects are induced by time-dependent interactions with the excitonic reservoir. These nonlinearities allow to create a nonlinear XOR logic gate that can perform operations on the picosecond timescale. An optoelectronic neural network based on the constructed logic gate performs classification of spoken digits with a high accuracy rate.
2201.00422,Quantitative control of Wasserstein distance between Brownian motion and the Goldstein--Kac telegraph process,"['Gerardo Barrera', 'Jani Lukkarinen']",ARXIV,http://arxiv.org/pdf/2201.00422v3,2022-01-02T21:45:43Z,2022-05-19T19:47:03Z,"['10.48550/arXiv.2201.00422', '10.1214/22-AIHP1288']","In this manuscript, we provide a non-asymptotic process level control between the telegraph process and the Brownian motion with suitable diffusivity constant via a Wasserstein distance with quadratic average cost. In addition, we derive non-asymptotic estimates for the corresponding time average $p$-th moments. The proof relies on coupling techniques such as coin-flip coupling, synchronous coupling and the Koml\'os--Major--Tusn\'ady coupling."
2201.00189,On the Exact Linearization and Control of Flat Discrete-time Systems,"['Bernd Kolar', 'Johannes Diwold', 'Conrad Gstöttner', 'Markus Schöberl']",ARXIV,http://arxiv.org/pdf/2201.00189v2,2022-01-01T13:40:48Z,2022-12-28T07:46:59Z,"['10.48550/arXiv.2201.00189', '10.1080/00207179.2022.2152378']","The paper addresses the exact linearization of flat nonlinear discrete-time systems by generalized static or dynamic feedbacks which may also depend on forward-shifts of the new input. We first investigate the question which forward-shifts of a given flat output can be chosen in principle as a new input, and subsequently how to actually introduce the new input by a suitable feedback. With respect to the choice of a feasible input, easily verifiable conditions are derived. Introducing such a new input requires a feedback which may in general depend not only on this new input itself but also on its forward-shifts. This is similar to the continuous-time case, where feedbacks which depend on time derivatives of the closed-loop input - and in particular quasi-static ones - have already been used successfully for the exact linearization of flat systems since the nineties of the last century. For systems with a flat output that does not depend on forward-shifts of the input, it is shown how to systematically construct a new input such that the total number of the corresponding forward-shifts of the flat output is minimal. Furthermore, it is shown that in this case the calculation of a linearizing feedback is particularly simple, and the subsequent design of a discrete-time flatness-based tracking control is discussed. The presented theory is illustrated by the discretized models of a wheeled mobile robot and a 3DOF helicopter."
2201.00174,"On the Kantor product, II","['Renato Fehlberg Júnior', 'Ivan Kaygorodov']",ARXIV,http://arxiv.org/pdf/2201.00174v1,2022-01-01T11:50:40Z,2022-01-01T11:50:40Z,"['10.48550/arXiv.2201.00174', '10.15330/cmp.14.2.543-563']","We describe the Kantor square (and Kantor product) of multiplications, extending the classification proposed in [I. Kaygorodov, On the Kantor product, Journal of Algebra and Its Applications, 16 (2017), 9, 1750167]. Besides, we explicitly describe the Kantor square of some low dimensional algebras and give constructive methods for obtaining new transposed Poisson algebras and Poisson-Novikov algebras; and for classifying Poisson structures and commutative post-Lie structures on a given algebra."
2201.00197,Quantum Liang Information Flow as Causation Quantifier,"['Bin Yi', 'Sougato Bose']",ARXIV,http://arxiv.org/pdf/2201.00197v3,2022-01-01T14:51:04Z,2022-02-20T19:49:18Z,"['10.48550/arXiv.2201.00197', '10.1103/PhysRevLett.129.020501']","Liang information flow is a quantity widely used in classical network theory to quantify causation, and has been applied widely, for example, to finance and climate. The most striking aspect here is to freeze/subtract a certain node of the network to ascertain its causal influence to other nodes of the network. Such an approach is yet to be applied to quantum network dynamics. Here we generalize Liang information flow to the quantum domain using the von-Neumann entropy. Using that we propose to assess the relative importance of various nodes of a network to causally influence a target node. We exemplify the application by using small quantum networks."
2201.00106,Disturbance Observer-Based Boundary Control for an Anti-Stable Stochastic Heat Equation with Unknown Disturbance,"['Ze-Hao Wu', 'Hua-Cheng Zhou', 'Feiqi Deng', 'Bao-Zhu Guo']",ARXIV,http://arxiv.org/pdf/2201.00106v1,2022-01-01T03:48:54Z,2022-01-01T03:48:54Z,['10.48550/arXiv.2201.00106'],"In this paper, a novel control strategy namely disturbance observer-based control is first applied to stabilization and disturbance rejection for an anti-stable stochastic heat equation with Neumann boundary actuation and unknown boundary external disturbance generated by an exogenous system. A disturbance observer-based boundary control is designed based on the backstepping approach and estimation/cancellation strategy, where the unknown disturbance is estimated in real time by a disturbance observer and rejected in the closed-loop, while the in-domain multiplicative noise whose intensity is within a known finite interval is attenuated. It is shown that the resulting closed-loop system is exponentially stable in the sense of both mean square and almost surely. A numerical example is demonstrated to validate the effectiveness of the proposed control approach."
2201.00339,Factor tree copula models for item response data,"['Sayed H. Kadhem', 'Aristidis K. Nikoloulopoulos']",ARXIV,http://arxiv.org/pdf/2201.00339v1,2022-01-02T11:36:55Z,2022-01-02T11:36:55Z,['10.48550/arXiv.2201.00339'],"Factor copula models for item response data are more interpretable and fit better than (truncated) vine copula models when dependence can be explained through latent variables, but are not robust to violations of conditional independence. To circumvent these issues, truncated vines and factor copula models for item response data are joined to define a combined model, the so-called factor tree copula model, with individual benefits from each of the two approaches. Rather than adding factors and causing computational problems and difficulties in interpretation and identification, a truncated vine structure is assumed on the residuals conditional on one or two latent variables. This structure can be better explained as a conditional dependence given a few interpretable latent variables. On the one hand, the parsimonious feature of factor models remains intact and any residual dependencies are being taken into account on the other. We discuss estimation along with model selection. In particular, we propose model selection algorithms to choose a plausible factor tree copula model to capture the (residual) dependencies among the item responses. Our general methodology is demonstrated with an extensive simulation study and illustrated by analyzing Post Traumatic Stress Disorder."
2201.00232,Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels,"['Enyan Dai', 'Wei Jin', 'Hui Liu', 'Suhang Wang']",ARXIV,http://arxiv.org/pdf/2201.00232v1,2022-01-01T19:00:26Z,2022-01-01T19:00:26Z,['10.48550/arXiv.2201.00232'],"Graph Neural Networks (GNNs) have shown their great ability in modeling graph structured data. However, real-world graphs usually contain structure noises and have limited labeled nodes. The performance of GNNs would drop significantly when trained on such graphs, which hinders the adoption of GNNs on many applications. Thus, it is important to develop noise-resistant GNNs with limited labeled nodes. However, the work on this is rather limited. Therefore, we study a novel problem of developing robust GNNs on noisy graphs with limited labeled nodes. Our analysis shows that both the noisy edges and limited labeled nodes could harm the message-passing mechanism of GNNs. To mitigate these issues, we propose a novel framework which adopts the noisy edges as supervision to learn a denoised and dense graph, which can down-weight or eliminate noisy edges and facilitate message passing of GNNs to alleviate the issue of limited labeled nodes. The generated edges are further used to regularize the predictions of unlabeled nodes with label smoothness to better train GNNs. Experimental results on real-world datasets demonstrate the robustness of the proposed framework on noisy graphs with limited labeled nodes."
2201.00488,Exact Mobility edges and topological Anderson insulating phase in a slowly varying quasiperiodic model,"['Zhanpeng Lu', 'Zhihao Xu', 'Yunbo Zhang']",ARXIV,http://arxiv.org/pdf/2201.00488v3,2022-01-03T05:57:53Z,2022-07-19T09:39:52Z,"['10.48550/arXiv.2201.00488', '10.1002/andp.202200203']","We uncover the relationship of topology and disorder in a one-dimensional Su-Schrieffer-Heeger chain subjected to a slowly varying quasi-periodic modulation. By numerically calculating the disorder-averaged winding number and analytically studying the localization length of the zero modes, we obtain the topological phase diagram, which implies that the topological Anderson insulator (TAI) can be induced by a slowly varying quasi-periodic modulation. Moreover, unlike the localization properties in the TAI phase caused by random disorder, mobility edges can enter into the TAI region identified by the fractal dimension, the inverse participation ratio, and the spatial distributions of the wave functions, the boundaries of which coincide with our analytical results."
2201.00179,On Zero-Sum Two Person Perfect Information Semi-Markov Games,"['S. Sinha', 'K. G. Bakshi']",ARXIV,http://arxiv.org/pdf/2201.00179v2,2022-01-01T12:31:17Z,2023-02-14T16:02:24Z,['10.48550/arXiv.2201.00179'],A zero-sum two-person Perfect Information Semi-Markov game (PISMG) under limiting ratio average payoff has a value and both the maximiser and the minimiser have optimal pure semi-stationary strategies. We arrive at the result by first fixing an arbitrary initial state and forming the matrix of undiscounted payoffs corresponding to each pair of pure stationary strategies of the two players and proving that this matrix has a pure saddle point.
2201.00175,"Kondo effect in a non-Hermitian, $\mathcal{PT}$-symmetric Anderson model with Rashba spin-orbit coupling","['Vinayak M Kulkarni', 'Amit Gupta', 'N. S. Vidhyadhiraja']",ARXIV,http://arxiv.org/pdf/2201.00175v3,2022-01-01T12:03:47Z,2022-06-04T12:08:07Z,"['10.48550/arXiv.2201.00175', '10.1103/PhysRevB.106.075113']","The non-interacting and non-Hermitian, parity-time ($\mathcal{PT}$)-symmetric Anderson model exhibits an exceptional point (EP) at a non-Hermitian coupling $g=1$, which remains unrenormalized in the presence of interactions (Lourenco et al, arXiv:1806.03116), where the EP was shown to coincide with the quantum critical point (QCP) for Kondo destruction. In this work, we consider a quantum dot hybridizing with metallic leads having Rashba spin-orbit coupling ($\lambda$). We show that for a non-Hermitian hybridization, $\lambda$ can renormalize the exceptional point even in the non-interacting case, stabilizing $\mathcal{PT}$-symmetry beyond $g=1$. Through exact diagonalization of a zero-bandwidth, three-site model, we show that the quantum critical point and the exceptional point bifurcate, with the critical point for Kondo destruction at $g_c=1$, and the exceptional coupling being $g_{\scriptscriptstyle{EP}} > 1$ for all $U\neq 0$ and $\lambda\geq 0; \lambda\neq U/2$. On the line $\lambda=U/2$, the critical point and the EP again coincide at $g_c=g_{\scriptscriptstyle{EP}}=1$. The full model with finite bandwidth leads is investigated through the slave-boson approach, using which we show that, in the strong coupling regime, $\lambda$ and interactions co-operate in strongly reducing the critical point associated with Kondo destruction, below the $\lambda=0$ value."
2201.00378,Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring Platforms,"['Pau Ferrer-Cid', 'Jose M. Barcelo-Ordinas', 'Jorge Garcia-Vidal']",ARXIV,http://arxiv.org/pdf/2201.00378v4,2022-01-02T16:57:35Z,2022-08-23T08:28:32Z,"['10.48550/arXiv.2201.00378', '10.1109/JIOT.2022.3196154']","Air pollution monitoring platforms play a very important role in preventing and mitigating the effects of pollution. Recent advances in the field of graph signal processing have made it possible to describe and analyze air pollution monitoring networks using graphs. One of the main applications is the reconstruction of the measured signal in a graph using a subset of sensors. Reconstructing the signal using information from sensor neighbors can help improve the quality of network data, examples are filling in missing data with correlated neighboring nodes, or correcting a drifting sensor with neighboring sensors that are more accurate. This paper compares the use of various types of graph signal reconstruction methods applied to real data sets of Spanish air pollution reference stations. The methods considered are Laplacian interpolation, graph signal processing low-pass based graph signal reconstruction, and kernel-based graph signal reconstruction, and are compared on actual air pollution data sets measuring O3, NO2, and PM10. The ability of the methods to reconstruct the signal of a pollutant is shown, as well as the computational cost of this reconstruction. The results indicate the superiority of methods based on kernel-based graph signal reconstruction, as well as the difficulties of the methods to scale in an air pollution monitoring network with a large number of low-cost sensors. However, we show that scalability can be overcome with simple methods, such as partitioning the network using a clustering algorithm."
2201.00235,Simulating and Modeling the Risk of Conversational Search,"['Zhenduo Wang', 'Qingyao Ai']",ARXIV,http://arxiv.org/pdf/2201.00235v1,2022-01-01T19:37:14Z,2022-01-01T19:37:14Z,"['10.48550/arXiv.2201.00235', '10.1145/3507357']","In conversational search, agents can interact with users by asking clarifying questions to increase their chance to find better results. Many recent works and shared tasks in both NLP and IR communities have focused on identifying the need of asking clarifying questions and methodologies of generating them. These works assume asking clarifying questions is a safe alternative to retrieving results. As existing conversational search models are far from perfect, it's possible and common that they could retrieve or generate bad clarifying questions. Asking too many clarifying questions can also drain user's patience when the user prefers searching efficiency over correctness. Hence, these models can get backfired and harm user's search experience because of these risks by asking clarifying questions. In this work, we propose a simulation framework to simulate the risk of asking questions in conversational search and further revise a risk-aware conversational search model to control the risk. We show the model's robustness and effectiveness through extensive experiments on three conversations datasets, including MSDialog, Ubuntu Dialog Corpus, and Opendialkg in which we compare it with multiple baselines. We show that the risk-control module can work with two different re-ranker models and outperform all the baselines in most of our experiments."
2201.00363,Semi-Supervised Graph Attention Networks for Event Representation Learning,"['Joao Pedro Rodrigues Mattos', 'Ricardo M. Marcacini']",ARXIV,http://arxiv.org/pdf/2201.00363v1,2022-01-02T14:38:28Z,2022-01-02T14:38:28Z,['10.48550/arXiv.2201.00363'],"Event analysis from news and social networks is very useful for a wide range of social studies and real-world applications. Recently, event graphs have been explored to model event datasets and their complex relationships, where events are vertices connected to other vertices representing locations, people's names, dates, and various other event metadata. Graph representation learning methods are promising for extracting latent features from event graphs to enable the use of different classification algorithms. However, existing methods fail to meet essential requirements for event graphs, such as (i) dealing with semi-supervised graph embedding to take advantage of some labeled events, (ii) automatically determining the importance of the relationships between event vertices and their metadata vertices, as well as (iii) dealing with the graph heterogeneity. This paper presents GNEE (GAT Neural Event Embeddings), a method that combines Graph Attention Networks and Graph Regularization. First, an event graph regularization is proposed to ensure that all graph vertices receive event features, thereby mitigating the graph heterogeneity drawback. Second, semi-supervised graph embedding with self-attention mechanism considers existing labeled events, as well as learns the importance of relationships in the event graph during the representation learning process. A statistical analysis of experimental results with five real-world event graphs and six graph embedding methods shows that our GNEE outperforms state-of-the-art semi-supervised graph embedding methods."
2201.00374,Topical Classification of Food Safety Publications with a Knowledge Base,"['Piotr Sowinski', 'Katarzyna Wasielewska-Michniewska', 'Maria Ganzha', 'Marcin Paprzycki']",ARXIV,http://arxiv.org/pdf/2201.00374v2,2022-01-02T16:15:05Z,2022-01-04T15:05:57Z,"['10.48550/arXiv.2201.00374', '10.1007/978-981-19-4364-5_48']","The vast body of scientific publications presents an increasing challenge of finding those that are relevant to a given research question, and making informed decisions on their basis. This becomes extremely difficult without the use of automated tools. Here, one possible area for improvement is automatic classification of publication abstracts according to their topic. This work introduces a novel, knowledge base-oriented publication classifier. The proposed method focuses on achieving scalability and easy adaptability to other domains. Classification speed and accuracy are shown to be satisfactory, in the very demanding field of food safety. Further development and evaluation of the method is needed, as the proposed approach shows much potential."
2201.00341,Chiral Dynamics: Theory and Experiment -- A Tribute to Aron Bernstein,['Ulf-G. Meißner'],ARXIV,http://arxiv.org/pdf/2201.00341v1,2022-01-02T11:40:12Z,2022-01-02T11:40:12Z,['10.48550/arXiv.2201.00341'],I review and discuss the contributions of Aron Bernstein to the field of chiral dynamics.
2201.00396,First Principles Investigation of Transition Metal Doped WSe$_{2}$ Monolayer for Photocatalytic Water Splitting,"['Celine Wu', 'Xuan Luo']",ARXIV,http://arxiv.org/pdf/2201.00396v1,2022-01-02T19:28:46Z,2022-01-02T19:28:46Z,['10.48550/arXiv.2201.00396'],"Photocatalytic water splitting is a promising renewable energy source as an alternative for limited fossil fuels. The effectiveness of the conversion from solar energy to hydrogen fuel relies primarily on the material. Previously, researchers studied different TMDs such as WS$_{2}$, and PdSe$_{2}$. These materials perform well in certain aspects such as strong adsorption stability and promising abilities for HER, however, their band gaps are still not ideal. In this paper, we studied a new TMD material WSe$_{2}$, which is currently used in heterostructure photocatalysts. To our knowledge, this is the first assessment of using transition metal doped WSe$_{2}$ as potential photocatalysts for photocatalytic water splitting. Using first principles calculations, we evaluated the band gaps and other photocatalytic abilities of pristine WSe2 as well as Cr, Mo, Ta, and Re doped WSe$_{2}$. Compared to previously studied TMD materials, three of our newly studied materials (pristine, Mo doped, and Ta doped WSe$_{2}$)demonstrated more desirable band gaps, which are closer to being ideal (1.23eV); The band edge positions of our materials are also closer to the ideal reduction potential of H$^{+}$/H$_{2}$ and the oxidation potential of O$_{2}$/H$_{2}$O. Furthermore, Mo and Ta doped WSe$_{2}$ monolayers undergo an exothermic process, indicating stable monolayers. Of the three selected materials, pristine WSe$_{2}$ exhibits the strongest water adsorption abilities. Our results substantiates pristine, Mo doped, and Cr doped WSe$_{2}$ as potential photocatalysts for water splitting."
2201.00405,Two-mode squeezed state quantisation and semiclassical portraits,"['Jean-Pierre Gazeau', 'Véronique Hussin', 'James Moran', 'Kevin Zelaya']",ARXIV,http://arxiv.org/pdf/2201.00405v1,2022-01-02T19:41:29Z,2022-01-02T19:41:29Z,"['10.48550/arXiv.2201.00405', '10.1016/j.aop.2022.168888']","Quantisation with Gaussian type states offers certain advantages over other quantisation schemes, in particular, they can serve to regularise formally discontinuous classical functions leading to well defined quantum operators. In this work we define a squeezed state quantisation in two dimensions using several families of squeezed states for one- and two-mode configurations. The completeness relations of the squeezed states are exploited in order to tackle the quantisation and semiclassical analysis of a constrained position dependent mass model with harmonic potential. The effects of the squeezing parameters on the resulting operators and phase space functions are studied, and configuration space trajectories are compared between the classical and semiclassical models."
2201.00219,On the Correlation Functions of the Characteristic Polynomials of Random Matrices with Independent Entries: Interpolation Between Complex and Real Cases,['Ievgenii Afanasiev'],ARXIV,http://arxiv.org/pdf/2201.00219v1,2022-01-01T17:22:55Z,2022-01-01T17:22:55Z,['10.48550/arXiv.2201.00219'],"The paper is concerned with the correlation functions of the characteristic polynomials of random matrices with independent complex entries. We investigate how the asymptotic behavior of the correlation functions depends on the second moment of the common probability law of the matrix entries, a sort of ""reality measure"" of the entries. It is shown that the correlation functions behave like that for the Complex Ginibre Ensemble up to a factor depending only on the second moment and the fourth absolute moment of the common probability law of the matrix entries."
2201.00317,Recurrent Feature Propagation and Edge Skip-Connections for Automatic Abdominal Organ Segmentation,"['Zefan Yang', 'Di Lin', 'Dong Ni', 'Yi Wang']",ARXIV,http://arxiv.org/pdf/2201.00317v2,2022-01-02T08:33:19Z,2023-05-19T04:25:57Z,['10.48550/arXiv.2201.00317'],"Automatic segmentation of abdominal organs in computed tomography (CT) images can support radiation therapy and image-guided surgery workflows. Developing of such automatic solutions remains challenging mainly owing to complex organ interactions and blurry boundaries in CT images. To address these issues, we focus on effective spatial context modeling and explicit edge segmentation priors. Accordingly, we propose a 3D network with four main components trained end-to-end including shared encoder, edge detector, decoder with edge skip-connections (ESCs) and recurrent feature propagation head (RFP-Head). To capture wide-range spatial dependencies, the RFP-Head propagates and harvests local features through directed acyclic graphs (DAGs) formulated with recurrent connections in an efficient slice-wise manner, with regard to spatial arrangement of image units. To leverage edge information, the edge detector learns edge prior knowledge specifically tuned for semantic segmentation by exploiting intermediate features from the encoder with the edge supervision. The ESCs then aggregate the edge knowledge with multi-level decoder features to learn a hierarchy of discriminative features explicitly modeling complementarity between organs' interiors and edges for segmentation. We conduct extensive experiments on two challenging abdominal CT datasets with eight annotated organs. Experimental results show that the proposed network outperforms several state-of-the-art models, especially for the segmentation of small and complicated structures (gallbladder, esophagus, stomach, pancreas and duodenum). The code will be publicly available."
2201.00193,On the facet pivot simplex method for linear programming II: a linear iteration bound,['Yaguang Yang'],ARXIV,http://arxiv.org/pdf/2201.00193v1,2022-01-01T14:19:03Z,2022-01-01T14:19:03Z,['10.48550/arXiv.2201.00193'],"The Hirsch Conjecture stated that any $d$-dimensional polytope with n facets has a diameter at most equal to $n - d$. This conjecture was disproved by Santos (A counterexample to the Hirsch Conjecture, Annals of Mathematics, 172(1) 383-412, 2012). The implication of Santos' work is that all {\it vertex} pivot algorithms cannot solve the linear programming problem in the worst case in $n - d$ vertex pivot iterations. In the first part of this series of papers, we proposed a {\it facet} pivot method. In this paper, we show that the proposed facet pivot method can solve the canonical linear programming problem in the worst case in at most $n-d$ facet pivot iterations. This work was inspired by Smale's Problem 9 (Mathematical problems for the next century, In Arnold, V. I.; Atiyah, M.; Lax, P.; Mazur, B. Mathematics: frontiers and perspectives, American Mathematical Society, 271-294, 1999)."
2201.00424,Splicing ViT Features for Semantic Appearance Transfer,"['Narek Tumanyan', 'Omer Bar-Tal', 'Shai Bagon', 'Tali Dekel']",ARXIV,http://arxiv.org/pdf/2201.00424v1,2022-01-02T22:00:34Z,2022-01-02T22:00:34Z,['10.48550/arXiv.2201.00424'],"We present a method for semantically transferring the visual appearance of one natural image to another. Specifically, our goal is to generate an image in which objects in a source structure image are ""painted"" with the visual appearance of their semantically related objects in a target appearance image. Our method works by training a generator given only a single structure/appearance image pair as input. To integrate semantic information into our framework - a pivotal component in tackling this task - our key idea is to leverage a pre-trained and fixed Vision Transformer (ViT) model which serves as an external semantic prior. Specifically, we derive novel representations of structure and appearance extracted from deep ViT features, untwisting them from the learned self-attention modules. We then establish an objective function that splices the desired structure and appearance representations, interweaving them together in the space of ViT features. Our framework, which we term ""Splice"", does not involve adversarial training, nor does it require any additional input information such as semantic segmentation or correspondences, and can generate high-resolution results, e.g., work in HD. We demonstrate high quality results on a variety of in-the-wild image pairs, under significant variations in the number of objects, their pose and appearance."
2201.00351,Integrability from supersymmetric duality: a short review,['Ilmar Gahramanov'],ARXIV,http://arxiv.org/pdf/2201.00351v1,2022-01-02T12:53:35Z,2022-01-02T12:53:35Z,['10.48550/arXiv.2201.00351'],"Integrable models of statistical mechanics play a prominent role in modern mathematical physics, especially in conformal field theory, knot theory, combinatorics, topology, etc. In this brief review, we discuss a program of constructing integrable lattice spin models with the nearest neighbor interaction using methods inspired by the supersymmetric gauge theory computations, called gauge/YBE correspondence. After a brief introduction to the topic, we review some recent examples of this correspondence and the role of special functions and symmetries. Finally, we discuss future directions of research."
2201.00284,Sharp Bounds for the Concentration of the Resolvent in Convex Concentration Settings,['Cosme Louart'],ARXIV,http://arxiv.org/pdf/2201.00284v1,2022-01-02T04:14:26Z,2022-01-02T04:14:26Z,['10.48550/arXiv.2201.00284'],"Considering random matrix $X \in \mathcal M_{p,n}$ with independent columns satisfying the convex concentration properties issued from a famous theorem of Talagrand, we express the linear concentration of the resolvent $Q = (I_p - \frac{1}{n}XX^T) ^{-1}$ around a classical deterministic equivalent with a good observable diameter for the nuclear norm. The general proof relies on a decomposition of the resolvent as a series of powers of $X$."
2201.00426,Deep Learning and Linear Programming for Automated Ensemble Forecasting and Interpretation,"['Lars Lien Ankile', 'Kjartan Krange']",ARXIV,http://arxiv.org/pdf/2201.00426v2,2022-01-02T22:19:26Z,2022-11-25T20:26:39Z,['10.48550/arXiv.2201.00426'],"This paper presents an ensemble forecasting method that shows strong results on the M4 Competition dataset by decreasing feature and model selection assumptions, termed DONUT (DO Not UTilize human beliefs). Our assumption reductions, primarily consisting of auto-generated features and a more diverse model pool for the ensemble, significantly outperform the statistical, feature-based ensemble method FFORMA by Montero-Manso et al. (2020). We also investigate feature extraction with a Long Short-term Memory Network (LSTM) Autoencoder and find that such features contain crucial information not captured by standard statistical feature approaches. The ensemble weighting model uses LSTM and statistical features to combine the models accurately. The analysis of feature importance and interaction shows a slight superiority for LSTM features over the statistical ones alone. Clustering analysis shows that essential LSTM features differ from most statistical features and each other. We also find that increasing the solution space of the weighting model by augmenting the ensemble with new models is something the weighting model learns to use, thus explaining part of the accuracy gains. Moreover, we present a formal ex-post-facto analysis of an optimal combination and selection for ensembles, quantifying differences through linear optimization on the M4 dataset. Our findings indicate that classical statistical time series features, such as trend and seasonality, alone do not capture all relevant information for forecasting a time series. On the contrary, our novel LSTM features contain significantly more predictive power than the statistical ones alone, but combining the two feature sets proved the best in practice."
2201.00170,Hot Brownian motion of optically levitated nanodiamonds,"['François Rivière', 'Timothée de Guillebon', 'Damien Raynal', 'Martin Schmidt', 'Jean-Sébastien Lauret', 'Jean-François Roch', 'Loïc Rondin']",ARXIV,http://arxiv.org/pdf/2201.00170v2,2022-01-01T11:30:57Z,2022-02-17T08:43:06Z,"['10.48550/arXiv.2201.00170', '10.1021/acsphotonics.1c01642']","The Brownian motion of a particle hotter than its environment is an iconic out-of-equilibrium system. Its study provides valuable insights into nanoscale thermal effects. Notably, it supplies an excellent diagnosis of thermal effects in optically levitated particles, a promising platform for force sensing and quantum physics tests. Thus, understanding the relevant parameters in this effect is critical. In this context, we test the role of particles' shape and material, using optically levitated nanodiamonds hosting NV centers to measure the particles' internal temperature and center-of-mass dynamics. We present a model to assess the nanodiamond internal temperature from its dynamics, adaptable to other particles. We also demonstrate that other mechanisms affect the nanodiamond dynamics and its stability in the trap. Finally, our work, by showing levitating nanodiamonds as an excellent tool for studying nano-thermal effects, opens prospects for increasing the trapping stability of optically levitated particles."
2201.00456,Halliday-Suranyi Approach to the Anharmonic Oscillator,"['Nabin Bhatta', 'Tatsu Takeuchi']",ARXIV,http://arxiv.org/pdf/2201.00456v1,2022-01-03T02:43:33Z,2022-01-03T02:43:33Z,['10.48550/arXiv.2201.00456'],"In this contribution to Peter Suranyi Festschrift, we study the Halliday-Suranyi perturbation method for calculating the energy eigenvalues of the quartic anharmonic oscillator."
2201.00496,A Taxonomy of Non-dictatorial Unidimensional Domains,"['Shurojit Chatterji', 'Huaxia Zeng']",ARXIV,http://arxiv.org/pdf/2201.00496v3,2022-01-03T06:37:34Z,2022-10-24T08:04:27Z,['10.48550/arXiv.2201.00496'],"A preference domain is called a non-dictatorial domain if it allows the design of unanimous social choice functions (henceforth, rules) that are non-dictatorial and strategy-proof. We study a class of preference domains called unidimensional domains and establish that the unique seconds property (introduced by Aswal, Chatterji, and Sen (2003)) characterizes all non-dictatorial domains. The principal contribution is the subsequent exhaustive classification of all non-dictatorial, unidimensional domains and canonical strategy-proof rules on these domains, based on a simple property of two-voter rules called invariance. The preference domains that constitute the classification are semi-single-peaked domains (introduced by Chatterji, Sanver, and Sen (2013)) and semi-hybrid domains (introduced here) which are two appropriate weakenings of single-peaked domains and are shown to allow strategy-proof rules to depend on non-peak information of voters' preferences; the canonical rules for these domains are the projection rule and the hybrid rule respectively. As a refinement of the classification, single-peaked domains and hybrid domains emerge as the only unidimensional domains that force strategy-proof rules to be determined completely by voters' preference peaks."
2201.00367,"The (2,3)-generation of the finite 8-dimensional orthogonal groups","['M. A. Pellegrini', 'M. C. Tamburini Bellani']",ARXIV,http://arxiv.org/pdf/2201.00367v1,2022-01-02T15:15:59Z,2022-01-02T15:15:59Z,['10.48550/arXiv.2201.00367'],"We construct $(2,3)$-generators for the finite $8$-dimensional orthogonal groups, proving the following results: the groups $\Omega_8^+(q)$ and $P\Omega_8^+(q)$ are $(2,3)$-generated if and only if $q\geq 4$; the groups $\Omega_8^-(q)$ and $P\Omega_8^-(q)$ are $(2,3)$-generated for all $q\geq 2$."
2201.00121,Thermal transport controlled by intra- and inter-dot Coulomb interactions in sequential and cotunneling serially-coupled double quantum dots,"['Bashdar Rahman Pirot', 'Nzar Rauf Abdullah', 'Andrei Manolescu', 'Vidar Gudmundsson']",ARXIV,http://arxiv.org/pdf/2201.00121v1,2022-01-01T05:19:20Z,2022-01-01T05:19:20Z,"['10.48550/arXiv.2201.00121', '10.1016/j.physb.2021.413646']","We study thermoelectric transport through a serial double quantum dot (DQD) coupled to two metallic leads with different thermal energies. We take into account the electron sequential and cotunneling effects via different master equation approaches. In the absence of intra- and inter-dot Coulomb interactions, a small peak in thermoelectric and heat currents is found for $E_{\rm L} \text{=} E_{\rm R}$ indicating the Coulomb blockade DQD regime, where $E_{\rm L}(E_{\rm R})$ is the energy of the state of the left(right) quantum dot. In the presence of intra- and inter-dot Coulomb interactions with strengths U$_{\rm intra}$, and U$_{\rm inter}$, respectively, avoided crossings or resonance energies between the intra- and the inter-dot two-electron states, 2ES, are found. These resonances induce extra transport channels through the DQD leading to strong side peaks in the thermoelectric and heat currents at $ E_{\rm L} \text{-} E_{\rm R} = \pm (U_{\rm intra} \text{-} U_{\rm inter})$ in addition to the main peak generated at $E_{\rm L} \text{=} E_{\rm R}$. The current side peaks are enhanced by increased strength of the Coulomb interactions. Interestingly, the current side peaks are enhanced when cotunneling terms are considered in which the resonances of the 2ESs assist the electron cotunneling process through the system. Furthermore, the issue of coherences is carefully checked in the DQD-leads system via different approaches to the master equation, which are the Pauli, the Redfield, a first order Lindblad, and the first- and second order von-Neumann methods. We realize that the Pauli method gives a wrong results for the thermoelectric transport when the role of the coherences is relevant."
2201.00427,Quantum supremacy of the many-body fluctuations in the occupations of the excited particle states in a Bose-Einstein-condensed gas,"['Vitaly V. Kocharovsky', 'Vladimir V. Kocharovsky', 'Sergey V. Tarasov']",ARXIV,http://arxiv.org/pdf/2201.00427v2,2022-01-02T22:41:16Z,2022-02-16T17:25:07Z,['10.48550/arXiv.2201.00427'],"We find a universal analytic formula for a characteristic function (Fourier transform) of a joint probability distribution for the particle occupation numbers in a BEC gas and the Hafnian Master Theorem generalizing the famous Permanent Master Theorem of MacMahon. We suggest an appealing model, a multi-qubit BEC trap formed by a set of qubit potential wells, and discuss specifics of such an atomic boson-sampling system vs a photonic one. Finally, the process of many-body fluctuations in a BEC trap is #P-hard for computing. It could serve as a basis for demonstrating quantum supremacy of the many-body interacting systems over classical simulators."
2201.00346,Detail-Preserving Transformer for Light Field Image Super-Resolution,"['Shunzhou Wang', 'Tianfei Zhou', 'Yao Lu', 'Huijun Di']",ARXIV,http://arxiv.org/pdf/2201.00346v1,2022-01-02T12:33:23Z,2022-01-02T12:33:23Z,['10.48550/arXiv.2201.00346'],"Recently, numerous algorithms have been developed to tackle the problem of light field super-resolution (LFSR), i.e., super-resolving low-resolution light fields to gain high-resolution views. Despite delivering encouraging results, these approaches are all convolution-based, and are naturally weak in global relation modeling of sub-aperture images necessarily to characterize the inherent structure of light fields. In this paper, we put forth a novel formulation built upon Transformers, by treating LFSR as a sequence-to-sequence reconstruction task. In particular, our model regards sub-aperture images of each vertical or horizontal angular view as a sequence, and establishes long-range geometric dependencies within each sequence via a spatial-angular locally-enhanced self-attention layer, which maintains the locality of each sub-aperture image as well. Additionally, to better recover image details, we propose a detail-preserving Transformer (termed as DPT), by leveraging gradient maps of light field to guide the sequence learning. DPT consists of two branches, with each associated with a Transformer for learning from an original or gradient image sequence. The two branches are finally fused to obtain comprehensive feature representations for reconstruction. Evaluations are conducted on a number of light field datasets, including real-world scenes and synthetic data. The proposed method achieves superior performance comparing with other state-of-the-art schemes. Our code is publicly available at: https://github.com/BITszwang/DPT."
2201.00455,Actor-Critic Network for Q&A in an Adversarial Environment,['Bejan Sadeghian'],ARXIV,http://arxiv.org/pdf/2201.00455v1,2022-01-03T02:35:58Z,2022-01-03T02:35:58Z,['10.48550/arXiv.2201.00455'],"Significant work has been placed in the Q&A NLP space to build models that are more robust to adversarial attacks. Two key areas of focus are in generating adversarial data for the purposes of training against these situations or modifying existing architectures to build robustness within. This paper introduces an approach that joins these two ideas together to train a critic model for use in an almost reinforcement learning framework. Using the Adversarial SQuAD ""Add One Sent"" dataset we show that there are some promising signs for this method in protecting against Adversarial attacks."
2201.00492,Analysis on the composite nature of the light scalar mesons $f_{0}(980)$ and $a_0(980)$,"['Ze-Qiang Wang', 'Xian-Wei Kang', 'J. A. Oller', 'Lu Zhang']",ARXIV,http://arxiv.org/pdf/2201.00492v2,2022-01-03T06:20:36Z,2022-04-07T14:29:28Z,"['10.48550/arXiv.2201.00492', '10.1103/PhysRevD.105.074016']","We study the weight or compositeness of the $\pi\pi$-$K\bar{K}$ and $\pi\eta$-$K\bar{K}$ in the composition of the $f_0(980)$ and $a_0(980)$ resonances, respectively. Either we use the saturation of the total width and compositeness, or we use a Flatt\'e parameterization taking also into account the spectral function of a near-threshold resonance. We make connections and compare between these two methods. We take input values for the pole mass and width from several determinations in the literature. In addition, we take as third input either the total compositeness or the decay-width branching ratio to the lighter channel for each resonance. It turns out that for the poles considered the meson-meson components are dominant for the $f_0(980)$, while for the $a_0(980)$ resonance they are subdominant. We also provide partial decay widths and partial compositeness coefficients, so that the $K\bar{K}$ component is the most important one for the $f_0(980)$. Additionally, this study stresses the need to distinguish between the bare and dressed couplings and widths in a Flatt\'e parameterization. We elaborate on the connection between the partial-decay widths calculated in terms of the dressed couplings and the actual measured ones. Due to the coupled-channel dynamics when the pole lies near the heavier threshold in the second Riemann sheet some changes are needed with respect to standard relations."
2201.00132,SAFL: A Self-Attention Scene Text Recognizer with Focal Loss,"['Bao Hieu Tran', 'Thanh Le-Cong', 'Huu Manh Nguyen', 'Duc Anh Le', 'Thanh Hung Nguyen', 'Phi Le Nguyen']",ARXIV,http://arxiv.org/pdf/2201.00132v1,2022-01-01T06:51:03Z,2022-01-01T06:51:03Z,"['10.48550/arXiv.2201.00132', '10.1109/ICMLA51294.2020.00223']","In the last decades, scene text recognition has gained worldwide attention from both the academic community and actual users due to its importance in a wide range of applications. Despite achievements in optical character recognition, scene text recognition remains challenging due to inherent problems such as distortions or irregular layout. Most of the existing approaches mainly leverage recurrence or convolution-based neural networks. However, while recurrent neural networks (RNNs) usually suffer from slow training speed due to sequential computation and encounter problems as vanishing gradient or bottleneck, CNN endures a trade-off between complexity and performance. In this paper, we introduce SAFL, a self-attention-based neural network model with the focal loss for scene text recognition, to overcome the limitation of the existing approaches. The use of focal loss instead of negative log-likelihood helps the model focus more on low-frequency samples training. Moreover, to deal with the distortions and irregular texts, we exploit Spatial TransformerNetwork (STN) to rectify text before passing to the recognition network. We perform experiments to compare the performance of the proposed model with seven benchmarks. The numerical results show that our model achieves the best performance."
2201.00190,Robust and Efficient Hamiltonian Learning,"['Wenjun Yu', 'Jinzhao Sun', 'Zeyao Han', 'Xiao Yuan']",ARXIV,http://arxiv.org/pdf/2201.00190v4,2022-01-01T13:48:15Z,2023-06-23T06:41:50Z,"['10.48550/arXiv.2201.00190', '10.22331/q-2023-06-29-1045']","With the fast development of quantum technology, the sizes of both digital and analog quantum systems increase drastically. In order to have better control and understanding of the quantum hardware, an important task is to characterize the interaction, i.e., to learn the Hamiltonian, which determines both static and dynamic properties of the system. Conventional Hamiltonian learning methods either require costly process tomography or adopt impractical assumptions, such as prior information on the Hamiltonian structure and the ground or thermal states of the system. In this work, we present a robust and efficient Hamiltonian learning method that circumvents these limitations based only on mild assumptions. The proposed method can efficiently learn any Hamiltonian that is sparse on the Pauli basis using only short-time dynamics and local operations without any information on the Hamiltonian or preparing any eigenstates or thermal states. The method has a scalable complexity and a vanishing failure probability regarding the qubit number. Meanwhile, it performs robustly given the presence of state preparation and measurement errors and resiliently against a certain amount of circuit and shot noise. We numerically test the scaling and the estimation accuracy of the method for transverse field Ising Hamiltonian with random interaction strengths and molecular Hamiltonians, both with varying sizes and manually added noise. All these results verify the robustness and efficacy of the method, paving the way for a systematic understanding of the dynamics of large quantum systems."
2201.00117,Usability and Aesthetics: Better Together for Automated Repair of Web Pages,"['Thanh Le-Cong', 'Xuan Bach D. Le', 'Quyet-Thang Huynh', 'Phi-Le Nguyen']",ARXIV,http://arxiv.org/pdf/2201.00117v1,2022-01-01T05:13:43Z,2022-01-01T05:13:43Z,['10.48550/arXiv.2201.00117'],"With the recent explosive growth of mobile devices such as smartphones or tablets, guaranteeing consistent web appearance across all environments has become a significant problem. This happens simply because it is hard to keep track of the web appearance on different sizes and types of devices that render the web pages. Therefore, fixing the inconsistent appearance of web pages can be difficult, and the cost incurred can be huge, e.g., poor user experience and financial loss due to it. Recently, automated web repair techniques have been proposed to automatically resolve inconsistent web page appearance, focusing on improving usability. However, generated patches tend to disrupt the webpage's layout, rendering the repaired webpage aesthetically unpleasing, e.g., distorted images or misalignment of components. In this paper, we propose an automated repair approach for web pages based on meta-heuristic algorithms that can assure both usability and aesthetics. The key novelty that empowers our approach is a novel fitness function that allows us to optimistically evolve buggy web pages to find the best solution that optimizes both usability and aesthetics at the same time. Empirical evaluations show that our approach is able to successfully resolve mobile-friendly problems in 94% of the evaluation subjects, significantly outperforming state-of-the-art baseline techniques in terms of both usability and aesthetics."
2201.00150,Cross-Domain Deep Code Search with Few-Shot Meta Learning,"['Yitian Chai', 'Hongyu Zhang', 'Beijun Shen', 'Xiaodong Gu']",ARXIV,http://arxiv.org/pdf/2201.00150v5,2022-01-01T09:00:48Z,2022-12-03T06:25:06Z,"['10.48550/arXiv.2201.00150', '10.1145/3510003.3510125']","Recently, pre-trained programming language models such as CodeBERT have demonstrated substantial gains in code search. Despite showing great performance, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as SQL and Solidity. Unlike cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely, SQL and Solidity, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data."
2201.00242,Industrial Edge-based Cyber-Physical Systems -- Application Needs and Concerns for Realization,"['Martin Törngren', 'Haydn Thompson', 'Erik Herzog', 'Rafia Inam', 'James Gross', 'György Dán']",ARXIV,http://arxiv.org/pdf/2201.00242v1,2022-01-01T20:54:25Z,2022-01-01T20:54:25Z,"['10.48550/arXiv.2201.00242', '10.1145/3453142.3493507']","Industry is moving towards advanced Cyber-Physical Systems (CPS), with trends in smartness, automation, connectivity and collaboration. We examine the drivers and requirements for the use of edge computing in critical industrial applications. Our purpose is to provide a better understanding of industrial needs and to initiate a discussion on what role edge computing could take, complementing current industrial and embedded systems, and the cloud. Four domains are chosen for analysis with representative use-cases; manufacturing, transportation, the energy sector and networked applications in the defense domain. We further discuss challenges, open issues and suggested directions that are needed to pave the way for the use of edge computing in industrial CPS."
2201.00462,D-Former: A U-shaped Dilated Transformer for 3D Medical Image Segmentation,"['Yixuan Wu', 'Kuanlun Liao', 'Jintai Chen', 'Jinhong Wang', 'Danny Z. Chen', 'Honghao Gao', 'Jian Wu']",ARXIV,http://arxiv.org/pdf/2201.00462v2,2022-01-03T03:20:35Z,2022-01-10T02:57:28Z,['10.48550/arXiv.2201.00462'],"Computer-aided medical image segmentation has been applied widely in diagnosis and treatment to obtain clinically useful information of shapes and volumes of target organs and tissues. In the past several years, convolutional neural network (CNN) based methods (e.g., U-Net) have dominated this area, but still suffered from inadequate long-range information capturing. Hence, recent work presented computer vision Transformer variants for medical image segmentation tasks and obtained promising performances. Such Transformers model long-range dependency by computing pair-wise patch relations. However, they incur prohibitive computational costs, especially on 3D medical images (e.g., CT and MRI). In this paper, we propose a new method called Dilated Transformer, which conducts self-attention for pair-wise patch relations captured alternately in local and global scopes. Inspired by dilated convolution kernels, we conduct the global self-attention in a dilated manner, enlarging receptive fields without increasing the patches involved and thus reducing computational costs. Based on this design of Dilated Transformer, we construct a U-shaped encoder-decoder hierarchical architecture called D-Former for 3D medical image segmentation. Experiments on the Synapse and ACDC datasets show that our D-Former model, trained from scratch, outperforms various competitive CNN-based or Transformer-based segmentation models at a low computational cost without time-consuming per-training process."
2201.00259,Subspace modeling for fast and high-sensitivity X-ray chemical imaging,"['Jizhou Li', 'Bin Chen', 'Guibin Zan', 'Guannan Qian', 'Piero Pianetta', 'Yijin Liu']",ARXIV,http://arxiv.org/pdf/2201.00259v1,2022-01-01T23:26:06Z,2022-01-01T23:26:06Z,['10.48550/arXiv.2201.00259'],"Resolving morphological chemical phase transformations at the nanoscale is of vital importance to many scientific and industrial applications across various disciplines. The TXM-XANES imaging technique, by combining full field transmission X-ray microscopy (TXM) and X-ray absorption near edge structure (XANES), has been an emerging tool which operates by acquiring a series of microscopy images with multi-energy X-rays and fitting to obtain the chemical map. Its capability, however, is limited by the poor signal-to-noise ratios due to the system errors and low exposure illuminations for fast acquisition. In this work, by exploiting the intrinsic properties and subspace modeling of the TXM-XANES imaging data, we introduce a simple and robust denoising approach to improve the image quality, which enables fast and high-sensitivity chemical imaging. Extensive experiments on both synthetic and real datasets demonstrate the superior performance of the proposed method."
2201.00491,KerGNNs: Interpretable Graph Neural Networks with Graph Kernels,"['Aosong Feng', 'Chenyu You', 'Shiqiang Wang', 'Leandros Tassiulas']",ARXIV,http://arxiv.org/pdf/2201.00491v2,2022-01-03T06:16:30Z,2022-02-25T09:01:13Z,['10.48550/arXiv.2201.00491'],"Graph kernels are historically the most widely-used technique for graph classification tasks. However, these methods suffer from limited performance because of the hand-crafted combinatorial features of graphs. In recent years, graph neural networks (GNNs) have become the state-of-the-art method in downstream graph-related tasks due to their superior performance. Most GNNs are based on Message Passing Neural Network (MPNN) frameworks. However, recent studies show that MPNNs can not exceed the power of the Weisfeiler-Lehman (WL) algorithm in graph isomorphism test. To address the limitations of existing graph kernel and GNN methods, in this paper, we propose a novel GNN framework, termed \textit{Kernel Graph Neural Networks} (KerGNNs), which integrates graph kernels into the message passing process of GNNs. Inspired by convolution filters in convolutional neural networks (CNNs), KerGNNs adopt trainable hidden graphs as graph filters which are combined with subgraphs to update node embeddings using graph kernels. In addition, we show that MPNNs can be viewed as special cases of KerGNNs. We apply KerGNNs to multiple graph-related tasks and use cross-validation to make fair comparisons with benchmarks. We show that our method achieves competitive performance compared with existing state-of-the-art methods, demonstrating the potential to increase the representation ability of GNNs. We also show that the trained graph filters in KerGNNs can reveal the local graph structures of the dataset, which significantly improves the model interpretability compared with conventional GNN models."
2201.00406,There are no Collatz-m-Cycles with $m\leq 91$,['Christian Hercher'],ARXIV,http://arxiv.org/pdf/2201.00406v3,2022-01-02T19:43:02Z,2023-04-04T08:36:23Z,['10.48550/arXiv.2201.00406'],"The Collatz conjecture (or ""Syracuse problem"") considers recursively-defined sequences of positive integers where $n$ is succeeded by $\tfrac{n}{2}$, if $n$ is even, or $\tfrac{3n+1}{2}$, if $n$ is odd. The conjecture states that for all starting values $n$ the sequence eventually reaches the trivial cycle $1, 2, 1, 2, \ldots$ . We are interested in the existence of nontrivial cycles. Let $m$ be the number of local minima in such a nontrivial cycle. Simons and de Weger proved that $m \geq 76$. With newer bounds on the range of starting values for which the Collatz conjecture has been checked, one gets $m \geq 83$. In this paper, we prove $m \geq 92$. The last part of this paper considers what must be proven in order to raise the number of odd members a nontrivial cycle has to have to the next bound -- that is, to at least $K\geq1.375\cdot 10^{11}$. We prove that it suffices to show that, for every integer smaller than or equal to $1536\cdot2^{60}=3\cdot2^{69}$, the respective Collatz sequence enters the trivial cycle. This reduces the range of numbers to be checked by nearly $60$\%."
2201.00205,Some connections between higher moments portfolio optimization methods,"['Farshad Noravesh', 'Kristiaan Kerstens']",ARXIV,http://arxiv.org/pdf/2201.00205v1,2022-01-01T15:14:27Z,2022-01-01T15:14:27Z,['10.48550/arXiv.2201.00205'],"In this paper, different approaches to portfolio optimization having higher moments such as skewness and kurtosis are classified so that the reader can observe different paradigms and approaches in this field of research which is essential for practitioners in Hedge Funds in particular. Several methods based on different paradigms such as utility approach and multi-objective optimization are reviewed and the advantage and disadvantageous of these ideas are explained. Keywords: multi-objective optimization, portfolio optimization, scalarization, utility"
2201.00183,Banach algebras of symmetric functions on the polydisc,['Amol Sasane'],ARXIV,http://arxiv.org/pdf/2201.00183v2,2022-01-01T13:05:18Z,2022-01-06T17:01:00Z,['10.48550/arXiv.2201.00183'],"Let ${\mathbb{D}}=\{z\in \mathbb{C}:|z|<1\}$ and for an integer $d\geq 1$, let $S_d$ denote the symmetric group, consisting of of all permutations of the set $\{1,\cdots, d\}$. A function $f:{\mathbb{D}}^d\rightarrow \mathbb{C}$ is symmetric if $f(z_1,\cdots, z_d)=f(z_{\sigma(1)},\cdots, z_{\sigma (d)})$ for all $\sigma \in S_d$ and all $(z_1,\cdots, z_d)\in {\mathbb{D}}^d$. The polydisc algebra $A({\mathbb{D}}^d)$ is the Banach algebra of all holomorphic functions $f$ on the polydisc ${\mathbb{D}}^d$ that can be continuously extended to the closure of the polydisc in ${\mathbb{C}}^d$, with pointwise operations and the supremum norm (given by $\|f\|_\infty:=\sup_{\mathbf{z} \in {\mathbb{D}}^d} |f(\mathbf{z})|$). Let $A_{\textrm{sym}}({\mathbb{D}}^d)$ be the Banach subalgebra of $A({\mathbb{D}}^d)$ consisting of all symmetric functions in the polydisc algebra. Algebraic-analytic properties of $A_{\textrm{sym}}({\mathbb{D}}^d)$ are investigated. In particular, the following results are shown: the corona theorem, description of the maximal ideal space and its contractibility, Hermiteness, projective-freeness, and non-coherence."
2201.00494,Cluster Stability Selection,"['Gregory Faletto', 'Jacob Bien']",ARXIV,http://arxiv.org/pdf/2201.00494v1,2022-01-03T06:28:17Z,2022-01-03T06:28:17Z,['10.48550/arXiv.2201.00494'],"Stability selection (Meinshausen and Buhlmann, 2010) makes any feature selection method more stable by returning only those features that are consistently selected across many subsamples. We prove (in what is, to our knowledge, the first result of its kind) that for data containing highly correlated proxies for an important latent variable, the lasso typically selects one proxy, yet stability selection with the lasso can fail to select any proxy, leading to worse predictive performance than the lasso alone. We introduce cluster stability selection, which exploits the practitioner's knowledge that highly correlated clusters exist in the data, resulting in better feature rankings than stability selection in this setting. We consider several feature-combination approaches, including taking a weighted average of the features in each important cluster where weights are determined by the frequency with which cluster members are selected, which we show leads to better predictive models than previous proposals. We present generalizations of theoretical guarantees from Meinshausen and Buhlmann (2010) and Shah and Samworth (2012) to show that cluster stability selection retains the same guarantees. In summary, cluster stability selection enjoys the best of both worlds, yielding a sparse selected set that is both stable and has good predictive performance."
2201.00133,Photovoltaic effect by soft phonon excitation,"['Yoshihiro Okamura', 'Takahiro Morimoto', 'Naoki Ogawa', 'Yoshio Kaneko', 'Guang-Yu Guo', 'Masao Nakamura', 'Masashi Kawasaki', 'Naoto Nagaosa', 'Yoshinori Tokura', 'Youtarou Takahashi']",ARXIV,http://arxiv.org/pdf/2201.00133v1,2022-01-01T06:56:50Z,2022-01-01T06:56:50Z,"['10.48550/arXiv.2201.00133', '10.1073/pnas.2122313119']","Photodetection is an indispensable function of optoelectronic devices in modern communication and sensing systems. Contrary to the near-infrared/visible regions, the fast and sensitive photodetectors operated at room temperature for the far-infrared/terahertz regions are not well developed despite a possibly vast range of applications. The bulk photovoltaic effect (BPVE) in single-phase noncentrosymmetric materials based on the shift current mechanism enables less-dissipative energy conversion endowed with instantaneous responsivity owing to the quantum-mechanical geometric phase of electronic states. Nevertheless, the small-band-gap material for the low-energy BPVE inevitably suffers from the thermal noise due to the intrinsically high conductivity. Here, we demonstrate the shift current induced by soft-phonon excitations without creation of electron-hole pairs in the archetypal ferroelectric BaTiO3 by using the terahertz light, whose energy scale is three orders of magnitude smaller than the electronic band gap. At and above room temperature, we observe appreciable photocurrents caused by the soft-phonon excitation as large as that for electronic excitation and their strong phonon-mode dependence. The observed phonon-driven BPVE can be well accounted for by the shift current model considering the electron-phonon coupling in the displacement-type ferroelectrics as supported by the first-principles calculation. Our findings establish the efficient quantum BPVE arising from low-energy elementary excitations, suggesting the novel principle for the high-performance terahertz photodetectors."
2201.00467,maskGRU: Tracking Small Objects in the Presence of Large Background Motions,"['Constantine J. Roros', 'Avinash C. Kak']",ARXIV,http://arxiv.org/pdf/2201.00467v1,2022-01-03T04:10:02Z,2022-01-03T04:10:02Z,['10.48550/arXiv.2201.00467'],"We propose a recurrent neural network-based spatio-temporal framework named maskGRU for the detection and tracking of small objects in videos. While there have been many developments in the area of object tracking in recent years, tracking a small moving object amid other moving objects and actors (such as a ball amid moving players in sports footage) continues to be a difficult task. Existing spatio-temporal networks, such as convolutional Gated Recurrent Units (convGRUs), are difficult to train and have trouble accurately tracking small objects under such conditions. To overcome these difficulties, we developed the maskGRU framework that uses a weighted sum of the internal hidden state produced by a convGRU and a 3-channel mask of the tracked object's predicted bounding box as the hidden state to be used at the next time step of the underlying convGRU. We believe the technique of incorporating a mask into the hidden state through a weighted sum has two benefits: controlling the effect of exploding gradients and introducing an attention-like mechanism into the network by indicating where in the previous video frame the object is located. Our experiments show that maskGRU outperforms convGRU at tracking objects that are small relative to the video resolution even in the presence of other moving objects."
2201.00487,Language as Queries for Referring Video Object Segmentation,"['Jiannan Wu', 'Yi Jiang', 'Peize Sun', 'Zehuan Yuan', 'Ping Luo']",ARXIV,http://arxiv.org/pdf/2201.00487v2,2022-01-03T05:54:00Z,2022-03-13T13:05:11Z,['10.48550/arXiv.2201.00487'],"Referring video object segmentation (R-VOS) is an emerging cross-modal task that aims to segment the target object referred by a language expression in all video frames. In this work, we propose a simple and unified framework built upon Transformer, termed ReferFormer. It views the language as queries and directly attends to the most relevant regions in the video frames. Concretely, we introduce a small set of object queries conditioned on the language as the input to the Transformer. In this manner, all the queries are obligated to find the referred objects only. They are eventually transformed into dynamic kernels which capture the crucial object-level information, and play the role of convolution filters to generate the segmentation masks from feature maps. The object tracking is achieved naturally by linking the corresponding queries across frames. This mechanism greatly simplifies the pipeline and the end-to-end framework is significantly different from the previous methods. Extensive experiments on Ref-Youtube-VOS, Ref-DAVIS17, A2D-Sentences and JHMDB-Sentences show the effectiveness of ReferFormer. On Ref-Youtube-VOS, Refer-Former achieves 55.6J&F with a ResNet-50 backbone without bells and whistles, which exceeds the previous state-of-the-art performance by 8.4 points. In addition, with the strong Swin-Large backbone, ReferFormer achieves the best J&F of 64.2 among all existing methods. Moreover, we show the impressive results of 55.0 mAP and 43.7 mAP on A2D-Sentences andJHMDB-Sentences respectively, which significantly outperforms the previous methods by a large margin. Code is publicly available at https://github.com/wjn922/ReferFormer."
2201.00273,Disorder in Andreev reflection of a quantum Hall edge,"['Vladislav D. Kurilovich', 'Zachary M. Raines', 'Leonid I. Glazman']",ARXIV,http://arxiv.org/pdf/2201.00273v1,2022-01-02T02:18:10Z,2022-01-02T02:18:10Z,"['10.48550/arXiv.2201.00273', '10.1038/s41467-023-37794-1']","We develop a theory of charge transport along the quantum Hall edge proximitized by a ""dirty"" superconductor. Disorder randomizes the Andreev reflection rendering the conductance of a proximitized segment a stochastic quantity with zero average for a sufficiently long segment. We find the statistical distribution of the conductance and its dependence on electron density, magnetic field, and temperature."
2201.00296,A note on large induced subgraphs with prescribed residues in bipartite graphs,['Zach Hunter'],ARXIV,http://arxiv.org/pdf/2201.00296v1,2022-01-02T05:31:51Z,2022-01-02T05:31:51Z,['10.48550/arXiv.2201.00296'],"It was proved by Scott that for every $k\ge2$, there exists a constant $c(k)>0$ such that for every bipartite $n$-vertex graph $G$ without isolated vertices, there exists an induced subgraph $H$ of order at least $c(k)n$ such that $\textrm{deg}_H(v) \equiv 1\pmod{k}$ for each $v \in H$. Scott conjectured that $c(k) = \Omega(1/k)$, which would be tight up to the multiplicative constant. We confirm this conjecture."
2201.00454,Memory-Guided Semantic Learning Network for Temporal Sentence Grounding,"['Daizong Liu', 'Xiaoye Qu', 'Xing Di', 'Yu Cheng', 'Zichuan Xu', 'Pan Zhou']",ARXIV,http://arxiv.org/pdf/2201.00454v1,2022-01-03T02:32:06Z,2022-01-03T02:32:06Z,['10.48550/arXiv.2201.00454'],"Temporal sentence grounding (TSG) is crucial and fundamental for video understanding. Although the existing methods train well-designed deep networks with a large amount of data, we find that they can easily forget the rarely appeared cases in the training stage due to the off-balance data distribution, which influences the model generalization and leads to undesirable performance. To tackle this issue, we propose a memory-augmented network, called Memory-Guided Semantic Learning Network (MGSL-Net), that learns and memorizes the rarely appeared content in TSG tasks. Specifically, MGSL-Net consists of three main parts: a cross-modal inter-action module, a memory augmentation module, and a heterogeneous attention module. We first align the given video-query pair by a cross-modal graph convolutional network, and then utilize a memory module to record the cross-modal shared semantic features in the domain-specific persistent memory. During training, the memory slots are dynamically associated with both common and rare cases, alleviating the forgetting issue. In testing, the rare cases can thus be enhanced by retrieving the stored memories, resulting in better generalization. At last, the heterogeneous attention module is utilized to integrate the enhanced multi-modal features in both video and query domains. Experimental results on three benchmarks show the superiority of our method on both effectiveness and efficiency, which substantially improves the accuracy not only on the entire dataset but also on rare cases."
2201.00248,Transfer RL across Observation Feature Spaces via Model-Based Regularization,"['Yanchao Sun', 'Ruijie Zheng', 'Xiyao Wang', 'Andrew Cohen', 'Furong Huang']",ARXIV,http://arxiv.org/pdf/2201.00248v3,2022-01-01T22:41:19Z,2022-04-06T02:27:44Z,['10.48550/arXiv.2201.00248'],"In many reinforcement learning (RL) applications, the observation space is specified by human developers and restricted by physical realizations, and may thus be subject to dramatic changes over time (e.g. increased number of observable features). However, when the observation space changes, the previous policy will likely fail due to the mismatch of input features, and another policy must be trained from scratch, which is inefficient in terms of computation and sample complexity. Following theoretical insights, we propose a novel algorithm which extracts the latent-space dynamics in the source task, and transfers the dynamics model to the target task to use as a model-based regularizer. Our algorithm works for drastic changes of observation space (e.g. from vector-based observation to image-based observation), without any inter-task mapping or any prior knowledge of the target task. Empirical results show that our algorithm significantly improves the efficiency and stability of learning in the target task."
2201.00371,Revisiting Quantum Contextuality,['Philippe Grangier'],ARXIV,http://arxiv.org/pdf/2201.00371v1,2022-01-02T16:00:23Z,2022-01-02T16:00:23Z,['10.48550/arXiv.2201.00371'],"The purpose of this note is to complete the interesting review on quantum contextuality [1] that appeared recently. In particular we will introduce and discuss the ideas of extracontextuality and extravalence, that allow one to relate Kochen-Specker's and Gleason's theorems, and also to shift the emphasis from the first to the second one. We will also argue that whereas Kochen-Specker's is essentially a negative result (a no-go theorem), Gleason's is a positive one since it provides a mathematical justification of Born's rule. The link between these issues is provided by a specific quantum feature that we call extravalence."
2201.00428,All-optical Tuning of Indistinguishable Single-Photons Generated in Three-level Quantum Systems,"['Łukasz Dusanowski', 'Chris Gustin', 'Stephen Hughes', 'Christian Schneider', 'Sven Höfling']",ARXIV,http://arxiv.org/pdf/2201.00428v1,2022-01-02T22:58:05Z,2022-01-02T22:58:05Z,"['10.48550/arXiv.2201.00428', '10.1021/acs.nanolett.1c04700']","Resonance fluorescence of two-level quantum systems has emerged as a powerful tool in quantum information processing. Extension of this approach to higher-level systems provides new opportunities for quantum optics applications. Here we introduce a coherent driving scheme of a three-level ladder system utilizing Autler-Townes and ac Stark effects by resonant excitation with two laser fields. We propose theoretically and demonstrate experimentally the feasibility of this approach towards all-optical spectral tuning of quantum dot-based single-photon sources and investigate photon indistinguishability and purity levels. Our tuning technique allows for fast optical control of the quantum emitter spectrum which paves the way towards temporal and spectral shaping of the single photons, formation of topological Floquet states or generation of high-dimensional frequency-encoded quantum states of light."
2201.00429,Image Denoising with Control over Deep Network Hallucination,"['Qiyuan Liang', 'Florian Cassayre', 'Haley Owsianko', 'Majed El Helou', 'Sabine Süsstrunk']",ARXIV,http://arxiv.org/pdf/2201.00429v1,2022-01-02T23:08:32Z,2022-01-02T23:08:32Z,['10.48550/arXiv.2201.00429'],"Deep image denoisers achieve state-of-the-art results but with a hidden cost. As witnessed in recent literature, these deep networks are capable of overfitting their training distributions, causing inaccurate hallucinations to be added to the output and generalizing poorly to varying data. For better control and interpretability over a deep denoiser, we propose a novel framework exploiting a denoising network. We call it controllable confidence-based image denoising (CCID). In this framework, we exploit the outputs of a deep denoising network alongside an image convolved with a reliable filter. Such a filter can be a simple convolution kernel which does not risk adding hallucinated information. We propose to fuse the two components with a frequency-domain approach that takes into account the reliability of the deep network outputs. With our framework, the user can control the fusion of the two components in the frequency domain. We also provide a user-friendly map estimating spatially the confidence in the output that potentially contains network hallucination. Results show that our CCID not only provides more interpretability and control, but can even outperform both the quantitative performance of the deep denoiser and that of the reliable filter, especially when the test data diverge from the training data."
2201.00463,The APEX Large CO Heterodyne Orion Legacy Survey (ALCOHOLS). I. Survey overview,"['Thomas Stanke', 'H. G. Arce', 'J. Bally', 'P. Bergman', 'J. Carpenter', 'C. J. Davis', 'W. Dent', 'J. Di Francesco', 'J. Eislöffel', 'D. Froebrich', 'A. Ginsburg', 'M. Heyer', 'D. Johnstone', 'D. Mardones', 'M. J. McCaughrean', 'S. T. Megeath', 'F. Nakamura', 'M. D. Smith', 'A. Stutz', 'K. Tatematsu', 'C. Walker', 'J. P. Williams', 'H. Zinnecker', 'B. J. Swift', 'C. Kulesa', 'B. Peters', 'B. Duffy', 'J. Kloosterman', 'U. A. Yıldız', 'J. L. Pineda', 'C. De Breuck', 'Th. Klein']",ARXIV,http://arxiv.org/pdf/2201.00463v1,2022-01-03T03:28:10Z,2022-01-03T03:28:10Z,"['10.48550/arXiv.2201.00463', '10.1051/0004-6361/201937034']","The Orion molecular cloud complex harbours the nearest GMCs and site of high-mass star formation. Its YSO populations are thoroughly characterized. The region is therefore a prime target for the study of star formation. Here, we verify the performance of the SuperCAM 64 pixel heterodyne array on APEX. We give a descriptive overview of a set of wide-field CO(3-2) spectral cubes obtained towards the Orion GMC complex, aimed at characterizing the dynamics and structure of the extended molecular gas in diverse regions of the clouds, ranging from very active sites of clustered star formation in Orion B to comparatively quiet regions in southern Orion A. We present a 2.7 square degree (130pc$^2$) mapping survey in the CO(3-2) transition, obtained using SuperCAM on APEX at an angular resolution of 19"" (7600AU or 0.037pc at a distance of 400pc), covering L1622, NGC2071, NGC2068, OriB9, NGC2024, and NGC2023 in Orion B, and the southern part of the L1641 cloud in Orion A. We describe CO integrated emission and line moment maps and position-velocity diagrams and discuss a few sub-regions in some detail. Evidence for expanding bubbles is seen with lines splitting into double components, most prominently in NGC2024, where we argue that the bulk of the molecular gas is in the foreground of the HII region. High CO(3-2)/CO(1-0) line ratios reveal warm CO along the western edge of Orion B in the NGC2023/NGC2024 region facing the IC434 HII region. Multiple, well separated radial velocity components seen in L1641-S suggest that it consists of a sequence of clouds at increasingly larger distances. We find a small, spherical cloud - the 'Cow Nebula' globule - north of NGC2071. We trace high velocity line wings for the NGC2071-IR outflow and the NGC2024 CO jet. The protostellar dust core FIR4 (rather than FIR5) is the true driving source of the NGC2024 monopolar outflow."
2201.00270,Towards a secure API client generator for IoT devices,"['Anders Aaen Springborg', 'Martin Kaldahl Andersen', 'Kaare Holland Hattel', 'Michele Albano']",ARXIV,http://arxiv.org/pdf/2201.00270v1,2022-01-02T01:46:21Z,2022-01-02T01:46:21Z,['10.48550/arXiv.2201.00270'],"Given the success of IoT platforms, more developers and companies want to include the technology in their portfolio. However, in the case of single board microcontrollers, the support for networking operations is not ideal, and different IoT platforms allow access to the networking submodule via different libraries and system calls, leading to a steeper learning curve. Code generators for API clients can enhance productivity, but they tend to generate universal purpose code, and on the other hand the networking primitives of IoT devices are platform specific, especially when security mechanisms such as Transport Layer Security are part of the picture. This paper presents \texttt{cpp-tiny-client}, an API client generator developed as a plugin for the OpenAPI Generator project, which can tailor the generated code based on the IoT platform specified by the user. Our work allows to generate correct code for API clients for IoT devices, and thus can empower a developer with more productivity and a faster time-to-market for its own applications. By combining together mainstream technologies only, \texttt{cpp-tiny-client} offers a gentle learning curve. Moreover, experiments show that the generated code has a reasonable footprint, at least with respect to the IoT devices that were used in the validation of the work. The code related to this work is available through the OpenAPI Generator project~\cite{OpenAPIGenerator}. This technical report is an extension of~\cite{acmsac22}, and it integrates the information presented at the ACM SAC 2022 conference."
2201.00103,Robust Region Feature Synthesizer for Zero-Shot Object Detection,"['Peiliang Huang', 'Junwei Han', 'De Cheng', 'Dingwen Zhang']",ARXIV,http://arxiv.org/pdf/2201.00103v1,2022-01-01T03:09:15Z,2022-01-01T03:09:15Z,['10.48550/arXiv.2201.00103'],"Zero-shot object detection aims at incorporating class semantic vectors to realize the detection of (both seen and) unseen classes given an unconstrained test image. In this study, we reveal the core challenges in this research area: how to synthesize robust region features (for unseen objects) that are as intra-class diverse and inter-class separable as the real samples, so that strong unseen object detectors can be trained upon them. To address these challenges, we build a novel zero-shot object detection framework that contains an Intra-class Semantic Diverging component and an Inter-class Structure Preserving component. The former is used to realize the one-to-more mapping to obtain diverse visual features from each class semantic vector, preventing miss-classifying the real unseen objects as image backgrounds. While the latter is used to avoid the synthesized features too scattered to mix up the inter-class and foreground-background relationship. To demonstrate the effectiveness of the proposed approach, comprehensive experiments on PASCAL VOC, COCO, and DIOR datasets are conducted. Notably, our approach achieves the new state-of-the-art performance on PASCAL VOC and COCO and it is the first study to carry out zero-shot object detection in remote sensing imagery."
2201.00107,Quality-aware Part Models for Occluded Person Re-identification,"['Pengfei Wang', 'Changxing Ding', 'Zhiyin Shao', 'Zhibin Hong', 'Shengli Zhang', 'Dacheng Tao']",ARXIV,http://arxiv.org/pdf/2201.00107v1,2022-01-01T03:51:09Z,2022-01-01T03:51:09Z,['10.48550/arXiv.2201.00107'],"Occlusion poses a major challenge for person re-identification (ReID). Existing approaches typically rely on outside tools to infer visible body parts, which may be suboptimal in terms of both computational efficiency and ReID accuracy. In particular, they may fail when facing complex occlusions, such as those between pedestrians. Accordingly, in this paper, we propose a novel method named Quality-aware Part Models (QPM) for occlusion-robust ReID. First, we propose to jointly learn part features and predict part quality scores. As no quality annotation is available, we introduce a strategy that automatically assigns low scores to occluded body parts, thereby weakening the impact of occluded body parts on ReID results. Second, based on the predicted part quality scores, we propose a novel identity-aware spatial attention (ISA) module. In this module, a coarse identity-aware feature is utilized to highlight pixels of the target pedestrian, so as to handle the occlusion between pedestrians. Third, we design an adaptive and efficient approach for generating global features from common non-occluded regions with respect to each image pair. This design is crucial, but is often ignored by existing methods. QPM has three key advantages: 1) it does not rely on any outside tools in either the training or inference stages; 2) it handles occlusions caused by both objects and other pedestrians;3) it is highly computationally efficient. Experimental results on four popular databases for occluded ReID demonstrate that QPM consistently outperforms state-of-the-art methods by significant margins. The code of QPM will be released."
2201.00471,Revisiting Open World Object Detection,"['Xiaowei Zhao', 'Xianglong Liu', 'Yifan Shen', 'Yixuan Qiao', 'Yuqing Ma', 'Duorui Wang']",ARXIV,http://arxiv.org/pdf/2201.00471v2,2022-01-03T04:40:59Z,2022-01-04T04:58:06Z,['10.48550/arXiv.2201.00471'],"Open World Object Detection (OWOD), simulating the real dynamic world where knowledge grows continuously, attempts to detect both known and unknown classes and incrementally learn the identified unknown ones. We find that although the only previous OWOD work constructively puts forward to the OWOD definition, the experimental settings are unreasonable with the illogical benchmark, confusing metric calculation, and inappropriate method. In this paper, we rethink the OWOD experimental setting and propose five fundamental benchmark principles to guide the OWOD benchmark construction. Moreover, we design two fair evaluation protocols specific to the OWOD problem, filling the void of evaluating from the perspective of unknown classes. Furthermore, we introduce a novel and effective OWOD framework containing an auxiliary Proposal ADvisor (PAD) and a Class-specific Expelling Classifier (CEC). The non-parametric PAD could assist the RPN in identifying accurate unknown proposals without supervision, while CEC calibrates the over-confident activation boundary and filters out confusing predictions through a class-specific expelling function. Comprehensive experiments conducted on our fair benchmark demonstrate that our method outperforms other state-of-the-art object detection approaches in terms of both existing and our new metrics. Our benchmark and code are available at https://github.com/RE-OWOD/RE-OWOD."
2201.00400,Parametric analysis of the Lateral Distribution Function of Cherenkov light for Yakutsk EAS Array in the Energy Range 1-20 PeV,"['Falah Al-Zubaidi', 'A. A. Al-Rubaiee', 'B. Hariharan']",ARXIV,http://arxiv.org/pdf/2201.00400v1,2021-12-16T21:13:12Z,2021-12-16T21:13:12Z,"['10.48550/arXiv.2201.00400', '10.1088/1742-6596/1484/1/012023']","In this research, the simulation of lateral distribution function (LDF) of Cherenkov radiation was performed using CORSIKA software for two hadronic models QGSJET and GHEISHA. This simulation was performed for several elementary particles such as protons, iron nuclei, electrons and gamma quanta, in the range of energies 1-20 PeV for three zenith angles 0, 20 and 30 degrees. A parameterization of Cherenkov light LDF was performed for that simulated curves using Lorentzian function. The comparison between the obtained results for LDF of Cherenkov light with that measured with Yakutsk EAS array gave a good agreement within the distances of 100-1000 m from the shower axis."
2201.00443,Scene Graph Generation: A Comprehensive Survey,"['Guangming Zhu', 'Liang Zhang', 'Youliang Jiang', 'Yixuan Dang', 'Haoran Hou', 'Peiyi Shen', 'Mingtao Feng', 'Xia Zhao', 'Qiguang Miao', 'Syed Afaq Ali Shah', 'Mohammed Bennamoun']",ARXIV,http://arxiv.org/pdf/2201.00443v2,2022-01-03T00:55:33Z,2022-06-22T09:19:40Z,['10.48550/arXiv.2201.00443'],"Deep learning techniques have led to remarkable breakthroughs in the field of generic object detection and have spawned a lot of scene-understanding tasks in recent years. Scene graph has been the focus of research because of its powerful semantic representation and applications to scene understanding. Scene Graph Generation (SGG) refers to the task of automatically mapping an image into a semantic structural scene graph, which requires the correct labeling of detected objects and their relationships. Although this is a challenging task, the community has proposed a lot of SGG approaches and achieved good results. In this paper, we provide a comprehensive survey of recent achievements in this field brought about by deep learning techniques. We review 138 representative works that cover different input modalities, and systematically summarize existing methods of image-based SGG from the perspective of feature extraction and fusion. We attempt to connect and systematize the existing visual relationship detection methods, to summarize, and interpret the mechanisms and the strategies of SGG in a comprehensive way. Finally, we finish this survey with deep discussions about current existing problems and future research directions. This survey will help readers to develop a better understanding of the current research status and ideas."
2201.00448,Random vortex dynamics via functional stochastic differential equations,"['Zhongmin Qian', 'Endre Süli', 'Yihuang Zhang']",ARXIV,http://arxiv.org/pdf/2201.00448v2,2022-01-03T01:46:27Z,2022-09-06T19:41:30Z,['10.48550/arXiv.2201.00448'],"In this paper we present a novel, closed three-dimensional (3D) random vortex dynamics system, which is equivalent to the Navier--Stokes equations for incompressible viscous fluid flows. The new random vortex dynamics system consists of a stochastic differential equation which is, in contrast with the two-dimensional random vortex dynamics equations, coupled with a finite-dimensional ordinary functional differential equation. This new random vortex system paves the way for devising new numerical schemes (random vortex methods) for solving three-dimensional incompressible fluid flow equations by Monte Carlo simulations. In order to derive the 3D random vortex dynamics equations, we have developed two powerful tools: the first is the duality of the conditional distributions of a couple of Taylor diffusions, which provides a path space version of integration by parts; the second is a forward type Feynman--Kac formula representing solutions to nonlinear parabolic equations in terms of functional integration. These technical tools and the underlying ideas are likely to be useful in treating other nonlinear problems."
2201.00354,Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference,"['Hao Sun', 'Taiyi Wang']",ARXIV,http://arxiv.org/pdf/2201.00354v2,2022-01-02T13:09:40Z,2022-10-28T20:25:54Z,['10.48550/arXiv.2201.00354'],"Although it is well known that exploration plays a key role in Reinforcement Learning (RL), prevailing exploration strategies for continuous control tasks in RL are mainly based on naive isotropic Gaussian noise regardless of the causality relationship between action space and the task and consider all dimensions of actions equally important. In this work, we propose to conduct interventions on the primal action space to discover the causal relationship between the action space and the task reward. We propose the method of State-Wise Action Refined (SWAR), which addresses the issue of action space redundancy and promote causality discovery in RL. We formulate causality discovery in RL tasks as a state-dependent action space selection problem and propose two practical algorithms as solutions. The first approach, TD-SWAR, detects task-related actions during temporal difference learning, while the second approach, Dyn-SWAR, reveals important actions through dynamic model prediction. Empirically, both methods provide approaches to understand the decisions made by RL agents and improve learning efficiency in action-redundant tasks."
2201.00464,Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection,"['Yuxin Zhang', 'Jindong Wang', 'Yiqiang Chen', 'Han Yu', 'Tao Qin']",ARXIV,http://arxiv.org/pdf/2201.00464v1,2022-01-03T03:40:21Z,2022-01-03T03:40:21Z,['10.48550/arXiv.2201.00464'],"Unsupervised anomaly detection aims to build models to effectively detect unseen anomalies by only training on the normal data. Although previous reconstruction-based methods have made fruitful progress, their generalization ability is limited due to two critical challenges. First, the training dataset only contains normal patterns, which limits the model generalization ability. Second, the feature representations learned by existing models often lack representativeness which hampers the ability to preserve the diversity of normal patterns. In this paper, we propose a novel approach called Adaptive Memory Network with Self-supervised Learning (AMSL) to address these challenges and enhance the generalization ability in unsupervised anomaly detection. Based on the convolutional autoencoder structure, AMSL incorporates a self-supervised learning module to learn general normal patterns and an adaptive memory fusion module to learn rich feature representations. Experiments on four public multivariate time series datasets demonstrate that AMSL significantly improves the performance compared to other state-of-the-art methods. Specifically, on the largest CAP sleep stage detection dataset with 900 million samples, AMSL outperforms the second-best baseline by \textbf{4}\%+ in both accuracy and F1 score. Apart from the enhanced generalization ability, AMSL is also more robust against input noise."
2201.00452,Cellulose-Based Reflective Liquid Crystal Films as Optical Filters and Solar Gain Regulators,"['Joshua A. De La Cruz', 'Qingkun Liu', 'Bohdan Senyuk', 'Allister W. Frazier', 'Karthik Peddireddy', 'Ivan I. Smalyukh']",ARXIV,http://arxiv.org/pdf/2201.00452v1,2022-01-03T02:15:02Z,2022-01-03T02:15:02Z,"['10.48550/arXiv.2201.00452', '10.1021/acsphotonics.8b00289']","Many promising approaches for designing interactions of synthetic materials with light involve solid optical monocrystals and nanofabricated photonic crystal structures with spatially periodic variations of refractive index. Although their high costs limit current technological applications, remarkably, such photonic and optically anisotropic materials have also evolved throughout nature and enable narrow or broad-band spectral reflection of light. Here we use self-assembly of biomaterial cellulose nanocrystals to obtain three-layer films with helicoidal and nematic-like organization of the cellulose nanoparticles, which mimics naturally occurring polarization-insensitive reflectors found in the wings of Plusiotis resplendens beetles. These films were characterized with polarized optical microscopy and circular dichroism spectrometry, as well as scanning and transmission electron microscopies. These films exhibit high reflectivity tunable within the visible and near-infrared regions of the optical spectrum and may find applications ranging from color filters to smart cloth designs and in solar-gain-regulating building technologies."
2201.00280,Least-Squares Method for Inverse Medium Problems,"['Kazufumi Ito', 'Ying Liang', 'Jun Zou']",ARXIV,http://arxiv.org/pdf/2201.00280v1,2022-01-02T02:55:28Z,2022-01-02T02:55:28Z,['10.48550/arXiv.2201.00280'],"We present a two-stage least-squares method to inverse medium problems of reconstructing multiple unknown coefficients simultaneously from noisy data. A direct sampling method is applied to detect the location of the inhomogeneity in the first stage, while a total least-squares method with mixed regularization is used to recover the medium profile in the second stage. The total least-squares method is designed to minimize the residual of the model equation and the data fitting, along with an appropriate regularization, in an attempt to significantly improve the accuracy of the approximation obtained from the first stage. We shall also present an analysis on the well-posedness and convergence of this algorithm. Numerical experiments are carried out to verify the accuracies and robustness of this novel two-stage least-squares algorithm, with great tolerance of noise."
2201.00461,Biometrics in the Time of Pandemic: 40% Masked Face Recognition Degradation can be Reduced to 2%,"['Leonardo Queiroz', 'Kenneth Lai', 'Svetlana Yanushkevich', 'Vlad Shmerko']",ARXIV,http://arxiv.org/pdf/2201.00461v1,2022-01-03T03:17:06Z,2022-01-03T03:17:06Z,['10.48550/arXiv.2201.00461'],"In this study of the face recognition on masked versus unmasked faces generated using Flickr-Faces-HQ and SpeakingFaces datasets, we report 36.78% degradation of recognition performance caused by the mask-wearing at the time of pandemics, in particular, in border checkpoint scenarios. We have achieved better performance and reduced the degradation to 1.79% using advanced deep learning approaches in the cross-spectral domain."
2201.00180,IoT-based Route Recommendation for an Intelligent Waste Management System,"['Mohammadhossein Ghahramani', 'Mengchu Zhou', 'Anna Molter', 'Francesco Pilla']",ARXIV,http://arxiv.org/pdf/2201.00180v1,2022-01-01T12:36:22Z,2022-01-01T12:36:22Z,"['10.48550/arXiv.2201.00180', '10.1109/JIOT.2021.3132126']","The Internet of Things (IoT) is a paradigm characterized by a network of embedded sensors and services. These sensors are incorporated to collect various information, track physical conditions, e.g., waste bins' status, and exchange data with different centralized platforms. The need for such sensors is increasing; however, proliferation of technologies comes with various challenges. For example, how can IoT and its associated data be used to enhance waste management? In smart cities, an efficient waste management system is crucial. Artificial Intelligence (AI) and IoT-enabled approaches can empower cities to manage the waste collection. This work proposes an intelligent approach to route recommendation in an IoT-enabled waste management system given spatial constraints. It performs a thorough analysis based on AI-based methods and compares their corresponding results. Our solution is based on a multiple-level decision-making process in which bins' status and coordinates are taken into account to address the routing problem. Such AI-based models can help engineers design a sustainable infrastructure system."
2201.00169,Dynamic Scene Video Deblurring using Non-Local Attention,"['Maitreya Suin', 'A. N. Rajagopalan']",ARXIV,http://arxiv.org/pdf/2201.00169v1,2022-01-01T11:17:34Z,2022-01-01T11:17:34Z,['10.48550/arXiv.2201.00169'],"This paper tackles the challenging problem of video deblurring. Most of the existing works depend on implicit or explicit alignment for temporal information fusion which either increase the computational cost or result in suboptimal performance due to wrong alignment. In this study, we propose a factorized spatio-temporal attention to perform non-local operations across space and time to fully utilize the available information without depending on alignment. It shows superior performance compared to existing fusion techniques while being much efficient. Extensive experiments on multiple datasets demonstrate the superiority of our method."
2201.00381,Stability of multi-population traffic flows,"['Amaury Hayat', 'Benedetto Piccoli', 'Shengquan Xiang']",ARXIV,http://arxiv.org/pdf/2201.00381v1,2022-01-02T17:26:23Z,2022-01-02T17:26:23Z,['10.48550/arXiv.2201.00381'],"Traffic waves, known also as stop-and-go waves or phantom hams, appear naturally as traffic instabilities, also in confined environments as a ring-road. A multi-population traffic is studied on a ring-road, comprised of drivers with stable and unstable behavior. There exists a critical penetration rate of stable vehicles above which the system is stable, and under which the system is unstable. In the latter case, stop-and-go waves appear, provided enough cars are on the road. The critical penetration rate is explicitly computable, and, in reasonable situations, a small minority of aggressive drivers is enough to destabilize an otherwise very stable flow. This is a source of instability that a single population model would not be able to explain. Also, the multi-population system can be stable below the critical penetration rate if the number of cars is sufficiently small. Instability emerges as the number of cars increases, even if the traffic density remains the same (i.e. number of cars and road size increase similarly). This shows that small experiments could lead to deducing imprecise stability conditions."
2201.00113,"Electronic and Optical properties of Metallic Nitride: A comparative study between the MN (M=Al, Ga, In, Tl) monolayers","['Nzar Rauf Abdullah', 'Botan Jawdat Abdullah', 'Vidar Gudmundsson']",ARXIV,http://arxiv.org/pdf/2201.00113v1,2022-01-01T04:46:41Z,2022-01-01T04:46:41Z,"['10.48550/arXiv.2201.00113', '10.1016/j.ssc.2022.114705']","The electronic and the optical properties of metallic nitride (MN) monolayers are studied using a DFT formalism. In most of these monolayers, the electron density of the metallic atoms is much higher than that of the nitride atoms, and ionic, covalent, and metallic bonds are found in M-N bonds, resulting in fascinating electronic and optical properties. The optical band gap is varied from almost $0.0$ to $3.0$~eV for the MN monolayers depending on the bond type between the metallic and the nitride atoms, as well as the contribution of the type of orbitals around the Fermi energy. The optical properties such as the dielectric function, the excitation spectra, the refractive index, the reflectivity, and the optical conductivity of MN monolayers are calculated. The excitation energy and static dielectric constant are found to be inversely proportional to the band gap at low photon energy. The MN monolayers with a large band gap have good visible light functionality, while the MN monolayers with a lower band gap are found to be active in the infrared region. Furthermore, it is shown that the optical properties of MN monolayers show a strong anisotropy with respect to the polarization of the incoming light. Consequently, our results for the optical properties of MN monolayers show that they could be beneficial in optoelectronic device applications."
2201.00228,The Complexity of Dynamic Least-Squares Regression,"['Shunhua Jiang', 'Binghui Peng', 'Omri Weinstein']",ARXIV,http://arxiv.org/pdf/2201.00228v2,2022-01-01T18:36:17Z,2023-04-06T15:06:09Z,['10.48550/arXiv.2201.00228'],"We settle the complexity of dynamic least-squares regression (LSR), where rows and labels $(\mathbf{A}^{(t)}, \mathbf{b}^{(t)})$ can be adaptively inserted and/or deleted, and the goal is to efficiently maintain an $\epsilon$-approximate solution to $\min_{\mathbf{x}^{(t)}} \| \mathbf{A}^{(t)} \mathbf{x}^{(t)} - \mathbf{b}^{(t)} \|_2$ for all $t\in [T]$. We prove sharp separations ($d^{2-o(1)}$ vs. $\sim d$) between the amortized update time of: (i) Fully vs. Partially dynamic $0.01$-LSR; (ii) High vs. low-accuracy LSR in the partially-dynamic (insertion-only) setting. Our lower bounds follow from a gap-amplification reduction -- reminiscent of iterative refinement -- rom the exact version of the Online Matrix Vector Conjecture (OMv) [HKNS15], to constant approximate OMv over the reals, where the $i$-th online product $\mathbf{H}\mathbf{v}^{(i)}$ only needs to be computed to $0.1$-relative error. All previous fine-grained reductions from OMv to its approximate versions only show hardness for inverse polynomial approximation $\epsilon = n^{-\omega(1)}$ (additive or multiplicative) . This result is of independent interest in fine-grained complexity and for the investigation of the OMv Conjecture, which is still widely open."
2201.00459,A sampling scheme for estimating the prevalence of a pandemic,"['Ze Liu', 'Siyu Yi', ' Jianghu', ' Dong', 'Min-Qian Liu', 'Yongdao Zhou']",ARXIV,http://arxiv.org/pdf/2201.00459v1,2022-01-03T03:07:18Z,2022-01-03T03:07:18Z,['10.48550/arXiv.2201.00459'],"The spread of COVID-19 makes it essential to investigate its prevalence. In such investigation research, as far as we know, the widely-used sampling methods didn't use the information sufficiently about the numbers of the previously diagnosed cases, which provides a priori information about the true numbers of infections. This motivates us to develop a new, two-stage sampling method in this paper, which utilises the information about the distributions of both population and diagnosed cases, to investigate the prevalence more efficiently. The global likelihood sampling, a robust and efficient sampler to draw samples from any probability density function, is used in our sampling strategy, and thus, our new method can automatically adapt to the complicated distributions of population and cases. Moreover, the corresponding estimating method is simple, which facilitates the practical implementation. Some recommendations for practical implementation are given. Finally, several simulations and a practical example verified its efficiency."
2201.00470,Estimating Rate of Change for Nonlinear Trajectories in the Framework of Individual Measurement Occasions: A New Perspective on Growth Curves,"['Jin Liu', 'Robert A. Perera']",ARXIV,http://arxiv.org/pdf/2201.00470v6,2022-01-03T04:34:59Z,2023-02-19T02:46:39Z,['10.48550/arXiv.2201.00470'],"Researchers are often interested in examining between-individual differences in within-individual processes. If the process under investigation is tracked for a long time, its trajectory may show a certain degree of nonlinearity, so that the rate-of-change is not constant. A fundamental goal of modeling such nonlinear processes is to estimate model parameters that reflect meaningful aspects of change, including the parameters related to change and other parameters that shed light on substantive hypotheses. However, if the measurement occasion is unstructured, existing models cannot simultaneously estimate these two types of parameters. This article has three goals. First, we view the change over time as the area under the curve (AUC) of the rate-of-change versus time (r-t) graph. Second, using the instantaneous rate-of-change midway through a time interval to approximate the average rate-of-change during that interval, we propose a new specification to describe longitudinal processes. In addition to obtaining the individual change-related parameters and other parameters related to specific research questions, the new specification allows for unequally-space study waves and individual measurement occasions around each wave. Third, we derive the model-based interval-specific change and change-from-baseline, two common measures to evaluate change over time. We evaluate the proposed specification through a simulation study and a real-world data analysis. We also provide OpenMx and Mplus 8 code for each model with the novel specification."
2201.00325,Energy exchanges between a two-dimensional front and internal wave modes,"['Subhajit Kar', 'Roy Barkan']",ARXIV,http://arxiv.org/pdf/2201.00325v2,2022-01-02T09:23:22Z,2022-06-16T20:31:55Z,['10.48550/arXiv.2201.00325'],"Fronts and near-inertial waves are energetic motions in the upper ocean that can interact and provide a route for kinetic energy (KE) dissipation of balanced oceanic flows. A quasilinear model is developed to study the KE exchanges between a two-dimensional geostrophically-balanced front undergoing strain-induced semigeostrophic frontogenesis and internal wave (IW) vertical modes. The quasilinear model is solved numerically for variable imposed strain magnitudes, initial IW vertical modes, and for both minimum frequency (near-inertial, NI) and high-frequency IWs. The front-IW KE exchanges are quantified separately during two frontogenetic stages -- an exponential sharpening stage that is characterized by a low Rossby number and is driven by the imposed geostrophic strain, followed by a superexponential sharpening stage that is characterized by an order-one Rossby number and is driven by the convergence of the ageostrophic secondary circulation. It is demonstrated that high-frequency IWs quickly escape the frontal zone and are very efficient at extracting KE from the imposed geostrophic strain field through the deformation shear production (DSP) mechanism. Part of the extracted KE is then converted to wave potential energy. Minimum frequency IWs remain locked to the frontal zone and therefore exchange energy with the ageostrophic frontal circulation. During the exponential stage, IWs extract KE from the geostrophic strain through DSP and transfer it to the frontal secondary circulation via the ageostrophic shear production (AGSP) mechanism. During the superexponential stage a newly identified mechanism, convergence production (CP), which is directly linked to the convergent secondary circulation, plays an important role in the NIW KE budget."
2201.00279,Influence of moments of inertia on transverse wobbling mode in odd-mass nuclei,"['Hui Zhang', 'Bin Qi', 'Xu Dong Wang', 'Hui Jia', 'Shou Yu Wang']",ARXIV,http://arxiv.org/pdf/2201.00279v2,2022-01-02T02:51:08Z,2022-04-01T05:29:49Z,"['10.48550/arXiv.2201.00279', '10.1103/PhysRevC.105.034339']","The reported transverse wobbling band in odd-mass $^{105}$Pd has been reinvestigated by the triaxial particle rotor model. Employing different parameter sets of moment of inertia (MOI), several calculated results could be in good agreement with the experimental data, which show distinct modes of rotational excitation, respectively. These modes are sensitive to the ratio between the MOI at intermediate and short axis. With the increase of this ratio, a wobble about the short axis of the total angular momentum is gradually changed to a wobble about the intermediate axis. In addition, it is exhibited that precession and tunneling are two aspects of the quantum wobbling motion. The tunneling aspect dominates in the yrare states of $^{105}$Pd. The present results in $^{105}$Pd show the complexity of the transverse wobbling mode."
2201.00161,On income inequality and population size,"['Thitithep Sitthiyot', 'Kanyarat Holasut']",ARXIV,http://arxiv.org/pdf/2201.00161v1,2022-01-01T10:37:34Z,2022-01-01T10:37:34Z,"['10.48550/arXiv.2201.00161', '10.14456/tresp.2016.8']","The pursuit of having an appropriate level of income inequality should be viewed as one of the biggest challenges facing academic scholars as well as policy makers. Unfortunately, research on this issue is currently lacking. This study is the first to introduce the theoretical concept of targeted level of income inequality for a given size of population. By employing the World Bank's data on population size and Gini coefficient from sixty-nine countries in 2012, this study finds that the relationship between Gini coefficient and natural logarithm of population size is nonlinear in the form of a second-degree polynomial function. The estimated results using regression analysis show that the majority of countries in the sample have Gini coefficients either too high or too low compared to their appropriate values. These findings could be used as a guideline for policy makers before designing and implementing public policies in order to achieve the targeted level of income inequality."
2201.00473,Determination of $\textrm{GL}(3)$ cusp forms by central values of quadratic twisted $L$-functions,"['Shenghao Hua', 'Bingrong Huang']",ARXIV,http://arxiv.org/pdf/2201.00473v3,2022-01-03T04:56:17Z,2022-07-05T13:36:48Z,['10.48550/arXiv.2201.00473'],"Let $\phi$ and $\phi'$ be two $\textrm{GL}(3)$ Hecke--Maass cusp forms. In this paper, we prove that $\phi=\phi'\textrm{ or }\widetilde{\phi'}$ if there exists a nonzero constant $\kappa$ such that $$L(\frac{1}{2},\phi\otimes \chi_{8d})=\kappa L(\frac{1}{2},\phi'\otimes \chi_{8d})$$ for all positive odd square-free positive $d$. Here $\widetilde{\phi'}$ is dual form of $\phi'$ and $\chi_{8d}$ is the quadratic character $(\frac{8d}{\cdot})$. To prove this, we obtain asymptotic formulas for twisted first moment of central values of quadratic twisted $L$-functions on $\textrm{GL}(3)$, which will have many other applications."
2201.00386,Mathematical Insights in the Pioneering Educational Project FSTF,['Enzo Bonacci'],ARXIV,http://arxiv.org/pdf/2201.00386v2,2022-01-02T18:03:10Z,2022-01-16T08:46:26Z,['10.48550/arXiv.2201.00386'],"During their pre-university year, six brilliant and motivated students joined the educational project ""From Soccerene to Fullerene"" (acronym FSTF) proposed by five teachers from the Departments of Physical Education and of Mathematics and Physics at the Scientific High School ""G.B. Grassi"" in Latina (Italy). The pupils investigated the fullerene buckyball (C60) also known as soccerene for its football-shaped structure (truncated icosahedron). From plastic sheets they cut twelve pentagons and twenty hexagons, with a calculated edge, sewing them together on a polystyrene sphere as faces of a soccer ball; they repeated the same operation twice, making two almost identical soccer-like balls. That multidisciplinary experience started on March 2013 and ended on June 2013. It was satisfactorily discussed in the 2013 school-leaving examination and raised a great interest both in the 100th national conference of the Italian Physical Society (Pisa, 2014) and in the ATINER's 9th annual international conference EMS (Athens, 2015). Now we briefly illustrate the FSTS, focusing on its mathematical features."
2201.00460,Hadronic three-body D decays mediated by scalar resonances,"['Hai-Yang Cheng', 'Cheng-Wei Chiang', 'Zhi-Qing Zhang']",ARXIV,http://arxiv.org/pdf/2201.00460v2,2022-01-03T03:12:35Z,2022-01-28T08:09:18Z,"['10.48550/arXiv.2201.00460', '10.1103/PhysRevD.105.033006']","We study the quasi-two-body $D\to SP$ decays and the three-body $D$ decays proceeding through intermediate scalar resonances, where $S$ and $P$ denote scalar and pseudoscalar mesons, respectively. Our main results are: (i) Certain external and internal $W$-emission diagrams with the emitted meson being a scalar meson are na{\""i}vely expected to vanish, but they actually receive contributions from vertex and hard spectator-scattering corrections beyond the factorization approximation. (ii) For light scalars with masses below or close to 1~GeV, it is more sensible to study three-body decays directly and compare with experiment as the two-body branching fractions are either unavailable or subject to large finite-width effects of the scalar meson. (iii) We consider the two-quark (scheme I) and four-quark (scheme II) descriptions of the light scalar mesons, and find the latter generally in better agreement with experiment. This is in line with recent BESIII measurements of semileptonic charm decays that prefer the tetraquark description of light scalars produced in charmed meson decays. (iv) The topological amplitude approach fails here as the $D\to SP$ decay branching fractions cannot be reliably inferred from the measurements of three-body decays, mainly because the decay rates cannot be factorized into the topological amplitude squared and the phase space factor. (v) The predicted rates for $D^0\to f_0 P, a_0 P$ are generally smaller than experimental data by one order of magnitude, presumably implying the significance of $W$-exchange amplitudes. (vi) The $W$-annihilation amplitude is found to be very sizable in the $SP$ sector with $|A/T|_{SP}\sim 1/2$, contrary to its suppression in the $PP$ sector with $|A/T|_{PP}\sim 0.18$."
2201.00453,The bipartite Turan number and spectral extremum for linear forests,"['Ming-Zhu Chen', 'Ning Wang', 'Long-Tu Yuan', 'Xiao-Dong Zhang']",ARXIV,http://arxiv.org/pdf/2201.00453v1,2022-01-03T02:16:05Z,2022-01-03T02:16:05Z,['10.48550/arXiv.2201.00453'],"The bipartite Tur\'{a}n number of a graph $H$, denoted by $ex(m,n; H)$, is the maximum number of edges in any bipartite graph $G=(X,Y; E)$ with $|X|=m$ and $|Y|=n$ which does not contain $H$ as a subgraph. In this paper, we determined $ex(m,n; F_{\ell})$ for arbitrary $\ell$ and appropriately large $n$ with comparing to $m$ and $\ell$, where $F_\ell$ is a linear forest which consists of $\ell$ vertex disjoint paths. Moreover, the extremal graphs have been characterized. Furthermore, these results are used to obtain the maximum spectral radius of bipartite graphs which does not contain $F_{\ell}$ as a subgraph and characterize all extremal graphs which attain the maximum spectral radius."
2201.00493,Beauville-Voisin filtrations on zero cycles of moduli space of stable sheaves on K3 surfaces,"['Zhiyuan Li', 'Ruxuan Zhang']",ARXIV,http://arxiv.org/pdf/2201.00493v2,2022-01-03T06:27:06Z,2022-01-07T05:12:38Z,['10.48550/arXiv.2201.00493'],"The Beauville-Voisin conjecture predicts the existence of a filtration on projective hyper-K\""ahler manifolds opposite to the conjecture Bloch-Beilinson filtration, called the Beauivlle-Voisin filtration. Voisin has introduced a filtration on zero cycles of an arbitrary projective hyper-K\""ahler manifold. On moduli space of stable objects of a projective K3 surface, there are other candidates constructed by Shen-Yin-Zhao, Barros-Flapan-Marian-Silversmith and more recently by Vial from different point of views. According to the work of Vial, all of them are proved to be equivalent except Voisin's filtration. In this paper, we show that Voisin's filtration is the same as the other filtrations. As an application, we prove a conjecture in Barros-Flapan-Marian-Silversmith's paper."
2201.00337,Riemannian Nearest-Regularized Subspace Classification for Polarimetric SAR images,"['Junfei Shi', 'Haiyan Jin']",ARXIV,http://arxiv.org/pdf/2201.00337v1,2022-01-02T11:21:59Z,2022-01-02T11:21:59Z,"['10.48550/arXiv.2201.00337', '10.1109/LGRS.2022.3224556']","As a representation learning method, nearest regularized subspace(NRS) algorithm is an effective tool to obtain both accuracy and speed for PolSAR image classification. However, existing NRS methods use the polarimetric feature vector but the PolSAR original covariance matrix(known as Hermitian positive definite(HPD)matrix) as the input. Without considering the matrix structure, existing NRS-based methods cannot learn correlation among channels. How to utilize the original covariance matrix to NRS method is a key problem. To address this limit, a Riemannian NRS method is proposed, which consider the HPD matrices endow in the Riemannian space. Firstly, to utilize the PolSAR original data, a Riemannian NRS method(RNRS) is proposed by constructing HPD dictionary and HPD distance metric. Secondly, a new Tikhonov regularization term is designed to reduce the differences within the same class. Finally, the optimal method is developed and the first-order derivation is inferred. During the experimental test, only T matrix is used in the proposed method, while multiple of features are utilized for compared methods. Experimental results demonstrate the proposed method can outperform the state-of-art algorithms even using less features."
2201.00458,Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark,"['Parnian Afshar', 'Arash Mohammadi', 'Konstantinos N. Plataniotis', 'Keyvan Farahani', 'Justin Kirby', 'Anastasia Oikonomou', 'Amir Asif', 'Leonard Wee', 'Andre Dekker', 'Xin Wu', 'Mohammad Ariful Haque', 'Shahruk Hossain', 'Md. Kamrul Hasan', 'Uday Kamal', 'Winston Hsu', 'Jhih-Yuan Lin', 'M. Sohel Rahman', 'Nabil Ibtehaz', 'Sh. M. Amir Foisol', 'Kin-Man Lam', 'Zhong Guang', 'Runze Zhang', 'Sumohana S. Channappayya', 'Shashank Gupta', 'Chander Dev']",ARXIV,http://arxiv.org/pdf/2201.00458v1,2022-01-03T03:06:38Z,2022-01-03T03:06:38Z,['10.48550/arXiv.2201.00458'],"Lung cancer is one of the deadliest cancers, and in part its effective diagnosis and treatment depend on the accurate delineation of the tumor. Human-centered segmentation, which is currently the most common approach, is subject to inter-observer variability, and is also time-consuming, considering the fact that only experts are capable of providing annotations. Automatic and semi-automatic tumor segmentation methods have recently shown promising results. However, as different researchers have validated their algorithms using various datasets and performance metrics, reliably evaluating these methods is still an open challenge. The goal of the Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark created through 2018 IEEE Video and Image Processing (VIP) Cup competition, is to provide a unique dataset and pre-defined metrics, so that different researchers can develop and evaluate their methods in a unified fashion. The 2018 VIP Cup started with a global engagement from 42 countries to access the competition data. At the registration stage, there were 129 members clustered into 28 teams from 10 countries, out of which 9 teams made it to the final stage and 6 teams successfully completed all the required tasks. In a nutshell, all the algorithms proposed during the competition, are based on deep learning models combined with a false positive reduction technique. Methods developed by the three finalists show promising results in tumor segmentation, however, more effort should be put into reducing the false positive rate. This competition manuscript presents an overview of the VIP-Cup challenge, along with the proposed algorithms and results."
2201.00116,Enhanced ultraviolet absorption in BN monolayers caused by tunable buckling,"['Nzar Rauf Abdullah', 'Botan Jawdat Abdullah', 'Chi-Shung Tang', 'Vidar Gudmundsson']",ARXIV,http://arxiv.org/pdf/2201.00116v1,2022-01-01T05:08:29Z,2022-01-01T05:08:29Z,['10.48550/arXiv.2201.00116'],"The optical properties of a hexagonal Boron Nitride (BN) monolayer across the UV spectrum are studied by tuning its planar buckling. The strong $\sigma\text{-}\sigma$ bond through sp$^2$ hybridization of a flat BN monolayer can be changed to a stronger $\sigma\text{-}\pi$ bond through sp$^3$ hybridization by increasing the planar buckling. This gives rise to the $s$- and $p$-orbital contributions to form a density of states around the Fermi energy, and these states dislocate to a lower energy in the presence of an increased planar buckling. Consequently, the wide band gap of a flat BN monolayer is reduced to a smaller band gap in a buckled BN monolayer enhancing its optical activity in the Deep-UV region. The optical properties such as the dielectric function, the reflectivity, the absorption, and the optical conductivity spectra are investigated. It is shown that the absorption rate can be enhanced by $(12\text{-}15)\%$ for intermediate values of planar buckling in the Deep-UV region, and $(15\text{-}20)\%$ at higher values of planar buckling in the near-UV region. Furthermore, the optical conductivity is enhanced by increased planar buckling in both the visible and the Deep-UV regions depending on the direction of the polarization of the incoming light. Our results may be useful for optoelectronic BN monolayer devices in the UV range including UV spectroscopy, deep-UV communications, and UV photodetectors."
2201.00258,The Parametric Cost Function Approximation: A new approach for multistage stochastic programming,"['Warren B Powell', 'Saeed Ghadimi']",ARXIV,http://arxiv.org/pdf/2201.00258v1,2022-01-01T23:25:09Z,2022-01-01T23:25:09Z,['10.48550/arXiv.2201.00258'],"The most common approaches for solving multistage stochastic programming problems in the research literature have been to either use value functions (""dynamic programming"") or scenario trees (""stochastic programming"") to approximate the impact of a decision now on the future. By contrast, common industry practice is to use a deterministic approximation of the future which is easier to understand and solve, but which is criticized for ignoring uncertainty. We show that a parameterized version of a deterministic optimization model can be an effective way of handling uncertainty without the complexity of either stochastic programming or dynamic programming. We present the idea of a parameterized deterministic optimization model, and in particular a deterministic lookahead model, as a powerful strategy for many complex stochastic decision problems. This approach can handle complex, high-dimensional state variables, and avoids the usual approximations associated with scenario trees or value function approximations. Instead, it introduces the offline challenge of designing and tuning the parameterization. We illustrate the idea by using a series of application settings, and demonstrate its use in a nonstationary energy storage problem with rolling forecasts."
2201.00490,Learning with Latent Structures in Natural Language Processing: A Survey,['Zhaofeng Wu'],ARXIV,http://arxiv.org/pdf/2201.00490v2,2022-01-03T06:16:17Z,2022-01-11T04:36:37Z,['10.48550/arXiv.2201.00490'],"While end-to-end learning with fully differentiable models has enabled tremendous success in natural language process (NLP) and machine learning, there have been significant recent interests in learning with latent discrete structures to incorporate better inductive biases for improved end-task performance and better interpretability. This paradigm, however, is not straightforwardly amenable to the mainstream gradient-based optimization methods. This work surveys three main families of methods to learn such models: surrogate gradients, continuous relaxation, and marginal likelihood maximization via sampling. We conclude with a review of applications of these methods and an inspection of the learned latent structure that they induce."
2201.00122,A Relaxed Energy Function Based Analog Neural Network Approach to Target Localization in Distributed MIMO Radar,"['Xiaoyu Zhao', 'Jun Li', 'Qinghua Guo']",ARXIV,http://arxiv.org/pdf/2201.00122v2,2022-01-01T05:21:29Z,2022-10-19T08:55:15Z,['10.48550/arXiv.2201.00122'],"Analog neural networks are highly effective to solve some optimization problems, and they have been used for target localization in distributed multiple-input multiple-output (MIMO) radar. In this work, we design a new relaxed energy function based neural network (RNFNN) for target localization in distributed MIMO radar. We start with the maximum likelihood (ML) target localization with a complicated objective function, which can be transformed to a tractable one with equality constraints by introducing some auxiliary variables. Different from the existing Lagrangian programming neural network (LPNN) methods, we further relax the optimization problem formulated for target localization, so that the Lagrangian multiplier terms are no longer needed, leading to a relaxed energy function with better convexity. Based on the relaxed energy function, a RNFNN is implemented with much simpler structure and faster convergence speed. Furthermore, the RNFNN method is extended to localization in the presence of transmitter and receiver location errors. It is shown that the performance of the proposed localization approach achieves the Cram\'er-Rao lower bound (CRLB) within a wider range of signal-to-noise ratios (SNRs). Extensive comparisons with the state-of-the-art approaches are provided, which demonstrate the advantages of the proposed approach in terms of performance improvement and computational complexity (or convergence speed)."
2201.00125,"Feichtinger Conjectures, $R_\varepsilon$-Conjectures and Weaver's Conjectures for Banach spaces",['K. Mahesh Krishna'],ARXIV,http://arxiv.org/pdf/2201.00125v1,2022-01-01T05:52:51Z,2022-01-01T05:52:51Z,['10.48550/arXiv.2201.00125'],"Motivated from two decades old famous Feichtinger conjectures for frames, $R_\varepsilon$-conjecture and Weaver's conjecture for Hilbert spaces (and their solution by Marcus, Spielman, and Srivastava), we formulate Feichtinger conjectures for p-approximate Schauder frames, $R_\varepsilon$-conjecture, Weaver's conjectures and Akemann-Weaver conjectures for Banach spaces. We also formulate conjectures on p-approximate Schauder frames based on the results of Casazza for frames for Hilbert spaces. We state conjectures and problems for p-approximate Schauder frames based on fundamental inequality for frames for Hilbert spaces and scaling problem for Hilbert space frames. Based on Kothe-Lorch theorem for Riesz bases for Hilbert spaces, we formulate a problem for p-approximate Riesz bases for Banach spaces. We formulate dynamical sampling problem for p-approximate Schauder frames for Banach spaces. We ask phase retrieval problem and norm retrieval problem for p-approximate Schauder frames for Banach spaces. We also formulate discretization problem for continuous p-approximate Schauder frames."
2201.00185,Extremal total distance of graphs of given radius I,['Stijn Cambie'],ARXIV,http://arxiv.org/pdf/2201.00185v2,2022-01-01T13:09:25Z,2022-04-18T11:17:38Z,"['10.48550/arXiv.2201.00185', '10.1002/jgt.22644']","In 1984, Plesn\'{i}k determined the minimum total distance for given order and diameter and characterized the extremal graphs and digraphs. We prove the analog for given order and radius, when the order is sufficiently large compared to the radius. This confirms asymptotically a conjecture of Chen et al. We also state an analog of the conjecture of Chen et al for digraphs and prove it for sufficiently large order."
2201.00319,Modular Welch Bounds with Applications,['K. Mahesh Krishna'],ARXIV,http://arxiv.org/pdf/2201.00319v1,2022-01-02T08:45:38Z,2022-01-02T08:45:38Z,['10.48550/arXiv.2201.00319'],"We prove the following two results. \begin{enumerate} \item Let $\mathcal{A}$ be a unital commutative C*-algebra and $\mathcal{A}^d$ be the standard Hilbert C*-module over $\mathcal{A}$. Let $n\geq d$. If $\{\tau_j\}_{j=1}^n$ is any collection of vectors in $\mathcal{A}^d$ such that $\langle \tau_j, \tau_j \rangle =1$, $\forall 1\leq j \leq n$, then \begin{align*} \max _{1\leq j,k \leq n, j\neq k}\|\langle \tau_j, \tau_k\rangle ||^{2m}\geq \frac{1}{n-1}\left[\frac{n}{{d+m-1\choose m}}-1\right], \quad \forall m \in \mathbb{N}. \end{align*} \item Let $\mathcal{A}$ be a $\sigma$-finite commutative W*-algebra or a commutative AW*-algebra and $\mathcal{E}$ be a rank d Hilbert C*-module over $\mathcal{A}$. Let $n\geq d$. If $\{\tau_j\}_{j=1}^n$ is any collection of vectors in $\mathcal{E}$ such that $\langle \tau_j, \tau_j \rangle =1$, $\forall 1\leq j \leq n$, then \begin{align*} \max _{1\leq j,k \leq n, j\neq k}\|\langle \tau_j, \tau_k\rangle ||^{2m}\geq \frac{1}{n-1}\left[\frac{n}{{d+m-1\choose m}}-1\right], \quad \forall m \in \mathbb{N}. \end{align*} \end{enumerate} Results (1) and (2) reduce to the famous result of Welch [\textit{IEEE Transactions on Information Theory, 1974}] obtained 48 years ago. We introduce the notions of modular frame potential, modular equiangular frames and modular Grassmannian frames. We formulate Zauner's conjecture for Hilbert C*-modules."
2201.00332,Parameterizing and inverting analytic mappings with unit Jacobian,['Timur Sadykov'],ARXIV,http://arxiv.org/pdf/2201.00332v1,2022-01-02T10:43:32Z,2022-01-02T10:43:32Z,['10.48550/arXiv.2201.00332'],"Let $x=(x_1,\ldots,x_n)\in {\rm \bf C}^n$ be a vector of complex variables, denote by $A=(a_{jk})$ a square matrix of size $n\geq 2,$ and let $\varphi\in\mathcal{O}(\Omega)$ be an analytic function defined in a nonempty domain $\Omega\subset {\rm \bf C}.$ We investigate the family of mappings $$ f=(f_1,\ldots,f_n):{\rm \bf C}^n\rightarrow {\rm \bf C}^n, \quad f[A,\varphi](x):=x+\varphi(Ax) $$ with the coordinates $$ f_j : x \mapsto x_j + \varphi\left(\sum\limits_{k=1}^n a_{jk}x_k\right), \quad j=1,\ldots,n $$ whose Jacobian is identically equal to a nonzero constant for any $x$ such that all of $f_j$ are well-defined. Let $U$ be a square matrix such that the Jacobian of the mapping $f[U,\varphi](x)$ is a nonzero constant for any $x$ and moreover for any analytic function $\varphi\in\mathcal{O}(\Omega).$ We show that any such matrix $U$ is uniquely defined, up to a suitable permutation similarity of matrices, by a partition of the dimension $n$ into a sum of $m$ positive integers together with a permutation on $m$ elements. For any $d=2,3,\ldots$ we construct $n$-parametric family of square matrices $H(s), s\in {\rm \bf C}^n$ such that for any matrix $U$ as above the mapping $x+\left((U\odot H(s))x\right)^d$ defined by the Hadamard product $U\odot H(s)$ has unit Jacobian. We prove any such mapping to be polynomially invertible and provide an explicit recursive formula for its inverse."
2201.00303,"Changing Computer-Usage Behaviours: What Users Want, Use, and Experience","['Mina Khan', 'Zeel Patel', 'Kathryn Wantlin', 'Elena Glassman', 'Pattie Maes']",ARXIV,http://arxiv.org/pdf/2201.00303v1,2022-01-02T06:28:18Z,2022-01-02T06:28:18Z,"['10.48550/arXiv.2201.00303', '10.1145/3429360.3468180']","Technology based screentime, the time an individual spends engaging with their computer or cell phone, has increased exponentially over the past decade, but perhaps most alarmingly amidst the COVID-19 pandemic. Although many software based interventions exist to reduce screentime, users report a variety of issues relating to the timing of the intervention, the strictness of the tool, and its ability to encourage organic, long-term habit formation. We develop guidelines for the design of behaviour intervention software by conducting a survey to investigate three research questions and further inform the mechanisms of computer-related behaviour change applications. RQ1: What do people want to change and why/how? RQ2: What applications do people use or have used, why do they work or not, and what additional support is desired? RQ3: What are helpful/unhelpful computer breaks and why? Our survey had 68 participants and three key findings. First, time management is a primary concern, but emotional and physical side-effects are equally important. Second, site blockers, self-trackers, and timers are commonly used, but they are ineffective as they are easy-to-ignore and not personalized. Third, away-from-computer breaks, especially involving physical activity, are helpful, whereas on-screen breaks are unhelpful, especially when they are long, because they are not refreshing. We recommend personalized and closed-loop computer-usage behaviour change support and especially encouraging off-the-computer screentime breaks."
2201.00410,Thresholds and more bands of A.C. spectrum for the Molchanov--Vainberg Schrödinger operator with a more general long range condition,['Marc-Adrien Mandich'],ARXIV,http://arxiv.org/pdf/2201.00410v1,2022-01-02T20:06:29Z,2022-01-02T20:06:29Z,['10.48550/arXiv.2201.00410'],"The existence of absolutely continuous (a.c.) spectrum for the discrete Molchanov-Vainberg Schr\""odinger operator $D+V$ on $\ell^2(\mathbb{Z}^d)$, in dimensions $d\geq 2$, is further investigated for potentials $V$ satisfying the long range condition $n_i(V-\tau_i ^{\kappa}V)(n) = O(\ln^{-q}(|n|))$ for some $q>2$, $\kappa \in \mathbb{N}$ even, and all $1 \leq i \leq d$, as $|n| \to \infty$. $\tau_i ^{\kappa} V$ is the potential shifted by $\kappa$ units on the $i^{\text{th}}$ coordinate. In this article \textit{finite} linear combinations of conjugate operators are constructed. These lead to more bands of a.c.\ spectrum being found. However, the new bands of a.c. spectrum are justified mainly by graphical evidence because the coefficients of the linear combinations are obtained by numerical polynomial interpolation. At the same time, an infinitely countable set of thresholds is rigorously identified (these will be defined exactly in the article). We conjecture that the spectrum of $D+V$ in dimension 2 is void of singular continuous spectrum, and that consecutive thresholds constitute endpoints of a band of a.c. spectrum."
2201.00353,Anisotropic versions of the Brezis-Van Schaftingen-Yung approach at $s=1$ and $s=0$,"['Qingsong Gu', 'Qingzhong Huang']",ARXIV,http://arxiv.org/pdf/2201.00353v1,2022-01-02T13:06:27Z,2022-01-02T13:06:27Z,['10.48550/arXiv.2201.00353'],"In 2014, Ludwig showed the limiting behavior of the anisotropic Gagliardo $s$-seminorm of a function $f$ as $s\rightarrow 1^-$ and $s\rightarrow0^+$, which extend the results due to Bourgain-Brezis-Mironescu(BBM) and Maz'ya-Shaposhnikova(MS) respectively. Recently, Brezis, Van Schaftingen and Yung provided a different approach by replacing the strong $L^p$ norm in the Gagliardo $s$-seminorm by the weak $L^p$ quasinorm. They characterized the case for $s=1$ that complements the BBM formula. The corresponding MS formula for $s=0$ was later established by Yung and the first author. In this paper, we follow the approach of Brezis-Van Schaftingen-Yung and show the anisotropic versions of $s=1$ and $s=0$. Our result generalizes the work by Brezis, Van Schaftingen, Yung and the first author and complements the work by Ludwig."
2201.00119,Limiting Spectral Distribution of High-dimensional Hayashi-Yoshida Estimator of Integrated Covariance Matrix,"['Arnab Chakrabarti', 'Rituparna Sen']",ARXIV,http://arxiv.org/pdf/2201.00119v1,2022-01-01T05:17:39Z,2022-01-01T05:17:39Z,['10.48550/arXiv.2201.00119'],"In this paper, the estimation of the Integrated Covariance matrix from high-frequency data, for high dimensional stock price process, is considered. The Hayashi-Yoshida covolatility estimator is an improvement over Realized covolatility for asynchronous data and works well in low dimensions. However it becomes inconsistent and unreliable in the high dimensional situation. We study the bulk spectrum of this matrix and establish its connection to the spectrum of the true covariance matrix in the limiting case where the dimension goes to infinity. The results are illustrated with simulation studies in finite, but high, dimensional cases. An application to real data with tick-by-tick data on 50 stocks is presented."
2201.00315,Energy evolution of the overlap functions: increasing ratio of $σ_{el}(s)/σ_{tot}(s)$ and black ring emergence,"['S. M. Troshin', 'N. E. Tyurin']",ARXIV,http://arxiv.org/pdf/2201.00315v3,2022-01-02T07:43:24Z,2022-09-06T07:49:59Z,"['10.48550/arXiv.2201.00315', '10.1088/1361-6471/ac8f60']",We analyse the two possible options of the energy dependency of the elastic and inelastic overlap functions. These correspond to saturation of the black disk limit (BEL effect) and to the unitarity saturation (REL effect) at $s\to\infty$. Relation of the REL effect to increase of the ratio $\sigma_{el}(s)/\sigma_{tot}(s)$ and emergence of black ring picture at the LHC is underlined.
2201.00274,COVID Lessons: Was there any way to reduce the negative effect of COVID-19 on the United States economy?,['Mohammadreza Mahmoudi'],ARXIV,http://arxiv.org/pdf/2201.00274v1,2022-01-02T02:25:34Z,2022-01-02T02:25:34Z,['10.48550/arXiv.2201.00274'],"This paper aims to study the economic impact of COVID-19. To do that, in the first step, I showed that the adjusted SEQIER model, which is a generalization form of SEIR model, is a good fit to the real COVID-induced daily death data in a way that it could capture the nonlinearities of the data very well. Then, I used this model with extra parameters to evaluate the economic effect of COVID-19 through job market. The results show that there was a simple strategy that US government could implemented in order to reduce the negative effect of COVID-19. Because of that the answer to the paper's title is yes. If lockdown policies consider the heterogenous characteristics of population and impose more restrictions on old people and control the interactions between them and the rest of population the devastating impact of COVID-19 on people lives and US economy reduced dramatically. Specifically, based on this paper's results, this strategy could reduce the death rate and GDP loss of the United States 0.03 percent and 2 percent respectively. By comparing these results with actual data which show death rate and GDP loss 0.1 percent and 3.5 percent respectively, we could figure out that death rate reduction is 0.07 percent which means for the same percent of GDP loss executing optimal targeted policy could save 2/3 lives. Approximately, 378,000 persons dead because of COVID-19 during 2020, hence reducing death rate to 0.03 percent means saving around 280,000 lives, which is huge."
2201.00136,Zero-shot Commonsense Question Answering with Cloze Translation and Consistency Optimization,"['Zi-Yi Dou', 'Nanyun Peng']",ARXIV,http://arxiv.org/pdf/2201.00136v1,2022-01-01T07:12:49Z,2022-01-01T07:12:49Z,['10.48550/arXiv.2201.00136'],"Commonsense question answering (CQA) aims to test if models can answer questions regarding commonsense knowledge that everyone knows. Prior works that incorporate external knowledge bases have shown promising results, but knowledge bases are expensive to construct and are often limited to a fixed set of relations. In this paper, we instead focus on better utilizing the \textit{implicit knowledge} stored in pre-trained language models. While researchers have found that the knowledge embedded in pre-trained language models can be extracted by having them fill in the blanks of carefully designed prompts for relation extraction and text classification, it remains unclear if we can adopt this paradigm in CQA where the inputs and outputs take much more flexible forms. To this end, we investigate four translation methods that can translate natural questions into cloze-style sentences to better solicit commonsense knowledge from language models, including a syntactic-based model, an unsupervised neural model, and two supervised neural models. In addition, to combine the different translation methods, we propose to encourage consistency among model predictions on different translated questions with unlabeled data. We demonstrate the effectiveness of our methods on three CQA datasets in zero-shot settings. We show that our methods are complementary to a knowledge base improved model, and combining them can lead to state-of-the-art zero-shot performance. Analyses also reveal distinct characteristics of the different cloze translation methods and provide insights on why combining them can lead to great improvements."
2201.00497,Criteria for Starlikeness Using Schwarzian Derivatives,"['Asha Sebastian', 'V. Ravichandran']",ARXIV,http://arxiv.org/pdf/2201.00497v1,2022-01-03T06:49:38Z,2022-01-03T06:49:38Z,['10.48550/arXiv.2201.00497'],"For a normalised analytic function f defined on the open unit disk in the complex plane, we determine several sufficient conditions for starlikeness in terms of the quotients Q_{ST}:=zf'(z)/f(z), Q_{CV}:=1+zf""(z)/f'(z) and the Schwarzian derivative Q_{SD}:=z^2((f""(z)/f'(z))'-(f""(z)/f'(z))^2/2)$. These conditions were obtained by using the admissibility criteria of starlikeness in the theory of second order differential subordination."
2201.00498,Variational Inverting Network for Statistical Inverse Problems of Partial Differential Equations,"['Junxiong Jia', 'Yanni Wu', 'Peijun Li', 'Deyu Meng']",ARXIV,http://arxiv.org/pdf/2201.00498v2,2022-01-03T06:56:52Z,2023-07-31T08:16:24Z,['10.48550/arXiv.2201.00498'],"To quantify uncertainties in inverse problems of partial differential equations (PDEs), we formulate them into statistical inference problems using Bayes' formula. Recently, well-justified infinite-dimensional Bayesian analysis methods have been developed to construct dimension-independent algorithms. However, there are three challenges for these infinite-dimensional Bayesian methods: prior measures usually act as regularizers and are not able to incorporate prior information efficiently; complex noises, such as more practical non-i.i.d. distributed noises, are rarely considered; and time-consuming forward PDE solvers are needed to estimate posterior statistical quantities. To address these issues, an infinite-dimensional inference framework has been proposed based on the infinite-dimensional variational inference method and deep generative models. Specifically, by introducing some measure equivalence assumptions, we derive the evidence lower bound in the infinite-dimensional setting and provide possible parametric strategies that yield a general inference framework called the Variational Inverting Network (VINet). This inference framework can encode prior and noise information from learning examples. In addition, relying on the power of deep neural networks, the posterior mean and variance can be efficiently and explicitly generated in the inference stage. In numerical experiments, we design specific network structures that yield a computable VINet from the general inference framework. Numerical examples of linear inverse problems of an elliptic equation and the Helmholtz equation are presented to illustrate the effectiveness of the proposed inference framework."
2201.00171,Multi-view Subspace Adaptive Learning via Autoencoder and Attention,"['Jian-wei Liu', 'Hao-jie Xie', 'Run-kun Lu', 'Xiong-lin Luo']",ARXIV,http://arxiv.org/pdf/2201.00171v1,2022-01-01T11:31:52Z,2022-01-01T11:31:52Z,['10.48550/arXiv.2201.00171'],"Multi-view learning can cover all features of data samples more comprehensively, so multi-view learning has attracted widespread attention. Traditional subspace clustering methods, such as sparse subspace clustering (SSC) and low-ranking subspace clustering (LRSC), cluster the affinity matrix for a single view, thus ignoring the problem of fusion between views. In our article, we propose a new Multiview Subspace Adaptive Learning based on Attention and Autoencoder (MSALAA). This method combines a deep autoencoder and a method for aligning the self-representations of various views in Multi-view Low-Rank Sparse Subspace Clustering (MLRSSC), which can not only increase the capability to non-linearity fitting, but also can meets the principles of consistency and complementarity of multi-view learning. We empirically observe significant improvement over existing baseline methods on six real-life datasets."
2201.00307,Reflectionless wave propagation on shallow water with variable bathymetry and current. II,"['Semyon M. Churilov', 'Yury A. Stepanyants']",ARXIV,http://arxiv.org/pdf/2201.00307v1,2022-01-02T06:39:34Z,2022-01-02T06:39:34Z,"['10.48550/arXiv.2201.00307', '10.1017/jfm.2022.208']","We show that in the linear approximation there are three classes of reflectionless wave propagation on a surface of shallow water in the channel with spatially varying depth, width, and current speed. Two of these classes have been described in our previous paper (Churilov & Stepanyants, 2022), and the third one was discovered recently and is described here. The general analysis of the problem shows that within the approach used in both our papers, these three classes, apparently, exhaust all possible cases of exact solutions of the problem considered. We show that the reflectionless flow can be global at certain conditions, i.e. it can exist on the entire x-axis. There are also reflectionless flows which exist only on the limited intervals of the x-axis."
2201.00143,Large deviations principle for stochastic delay differential equations with super-linearly growing coefficients,"['Diancong Jin', 'Ziheng Chen', 'Tau Zhou']",ARXIV,http://arxiv.org/pdf/2201.00143v1,2022-01-01T08:02:39Z,2022-01-01T08:02:39Z,['10.48550/arXiv.2201.00143'],"We utilize the weak convergence method to establish the Freidlin--Wentzell large deviations principle (LDP) for stochastic delay differential equations (SDDEs) with super-linearly growing coefficients, which covers a large class of cases with non-globally Lipschitz coefficients. The key ingredient in our proof is the uniform moment estimate of the controlled equation, where we handle the super-linear growth of the coefficients by an iterative argument. Our results allow both the drift and diffusion coefficients of the considered equations to super-linearly grow not only with respect to the delay variable but also to the state variable. This work extends the existing results which develop the LDPs for SDDEs with super-linearly growing coefficients only with respect to the delay variable."
2201.00466,RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image Restoration on A New Clinical Benchmark,"['Zhuo Deng', 'Yuanhao Cai', 'Lu Chen', 'Zheng Gong', 'Qiqi Bao', 'Xue Yao', 'Dong Fang', 'Shaochong Zhang', 'Lan Ma']",ARXIV,http://arxiv.org/pdf/2201.00466v2,2022-01-03T03:56:58Z,2022-08-03T11:54:27Z,['10.48550/arXiv.2201.00466'],"Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image restoration is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image restoration problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications. The dataset, code, and models are publicly available at https://github.com/dengzhuo-AI/Real-Fundus"
2201.00333,OPE of line defects in 5d $E_n$ SCFT,['Jihwan Oh'],ARXIV,http://arxiv.org/pdf/2201.00333v1,2022-01-02T10:48:10Z,2022-01-02T10:48:10Z,"['10.48550/arXiv.2201.00333', '10.1007/JHEP03(2022)178']","5d ray index is the 5d superconformal index in the presence of a ray-like defect. An elementary ray defect flows to a fundamental Wilson ray in IR gauge theory. In 5d $\mathcal{N}=1$ superconformal field theory(SCFT) with $E_n$ global symmetry, we compute the ray index associated with an adjoint Wilson ray. We show that the operators that appear in the index are non-trivially charged under the center of the global symmetry $E_n$. The charge under the center being twice compared with the center charge carried by the elementary ray operator indicates a non-trivial OPE between the ray-like defects in the UV SCFT."
2201.00209,Cobordism invariants for knots with two indices,['Vassily Olegovich Manturov'],ARXIV,http://arxiv.org/pdf/2201.00209v1,2022-01-01T15:28:27Z,2022-01-01T15:28:27Z,['10.48550/arXiv.2201.00209'],We construct an invariant of virtual knots which is a sliceness obstruction and sensitive to the $\Delta$-move. This invariants works if $\Z_{2}\oplus \Z_{2}$-index of chords is present.
2201.00344,"A Bound on the Minimal Field Size of LRCs, and Cyclic MR Codes That Attain It","['Han Cai', 'Moshe Schwartz']",ARXIV,http://arxiv.org/pdf/2201.00344v2,2022-01-02T12:07:23Z,2022-08-22T14:44:49Z,['10.48550/arXiv.2201.00344'],"We prove a new lower bound on the field size of locally repairable codes (LRCs). Additionally, we construct maximally recoverable (MR) codes which are cyclic. While a known construction for MR codes has the same parameters, it produces non-cyclic codes. Furthermore, we prove both necessary conditions and sufficient conditions that specify when the known non-cyclic MR codes may be permuted to become cyclic, thus proving our construction produces cyclic MR codes with new parameters. Furthermore, using our new bound on the field size, we show that the new cyclic MR codes have optimal field size in certain cases. Other known LRCs are also shown to have optimal field size in certain cases."
2201.00112,SurfGen: Adversarial 3D Shape Synthesis with Explicit Surface Discriminators,"['Andrew Luo', 'Tianqin Li', 'Wen-Hao Zhang', 'Tai Sing Lee']",ARXIV,http://arxiv.org/pdf/2201.00112v1,2022-01-01T04:44:42Z,2022-01-01T04:44:42Z,['10.48550/arXiv.2201.00112'],"Recent advances in deep generative models have led to immense progress in 3D shape synthesis. While existing models are able to synthesize shapes represented as voxels, point-clouds, or implicit functions, these methods only indirectly enforce the plausibility of the final 3D shape surface. Here we present a 3D shape synthesis framework (SurfGen) that directly applies adversarial training to the object surface. Our approach uses a differentiable spherical projection layer to capture and represent the explicit zero isosurface of an implicit 3D generator as functions defined on the unit sphere. By processing the spherical representation of 3D object surfaces with a spherical CNN in an adversarial setting, our generator can better learn the statistics of natural shape surfaces. We evaluate our model on large-scale shape datasets, and demonstrate that the end-to-end trained model is capable of generating high fidelity 3D shapes with diverse topology."
2201.00109,On a family of infinite series with reciprocal Catalan numbers,"['Kunle Adegoke', 'Robert Frontczak', 'Taras Goy']",ARXIV,http://arxiv.org/pdf/2201.00109v2,2022-01-01T04:12:58Z,2022-01-05T22:51:31Z,['10.48550/arXiv.2201.00109'],"We study a certain family of infinite series with reciprocal Catalan numbers. We first evaluate two special candidates of the family in closed form, where we also present some Catalan-Fibonacci relations. Then we focus on the general properties of the family and prove explicit formulas, including two types of integral representations."
2201.00451,Graphics processing unit implementation of the F-statistic for continuous gravitational wave searches,"['Liam Dunn', 'Patrick Clearwater', 'Andrew Melatos', 'Karl Wette']",ARXIV,http://arxiv.org/pdf/2201.00451v1,2022-01-03T02:11:46Z,2022-01-03T02:11:46Z,"['10.48550/arXiv.2201.00451', '10.1088/1361-6382/ac4616']","The $\mathcal{F}$-statistic is a detection statistic used widely in searches for continuous gravitational waves with terrestrial, long-baseline interferometers. A new implementation of the $\mathcal{F}$-statistic is presented which accelerates the existing ""resampling"" algorithm using graphics processing units (GPUs). The new implementation runs between 10 and 100 times faster than the existing implementation on central processing units without sacrificing numerical accuracy. The utility of the GPU implementation is demonstrated on a pilot narrowband search for four newly discovered millisecond pulsars in the globular cluster Omega Centauri using data from the second Laser Interferometer Gravitational-Wave Observatory observing run. The computational cost is $17.2$ GPU-hours using the new implementation, compared to 1092 core-hours with the existing implementation."
2201.00372,Parameter estimation of stochastic differential equation driven by small fractional noise,"['Shohei Nakajima', 'Yasutaka Shimizu']",ARXIV,http://arxiv.org/pdf/2201.00372v1,2022-01-02T16:00:36Z,2022-01-02T16:00:36Z,['10.48550/arXiv.2201.00372'],"We study the problem of parametric estimation for continuously observed stochastic processes driven by additive small fractional Brownian motion with Hurst index 0<H<1/2 and 1/2<H<1. Under some assumptions on the drift coefficient, we obtain the asymptotic normality and moment convergence of maximum likelihood estimator of the drift parameter ."
2201.00329,A Systematic Literature Review on Persuasive Technology at the Workplace,['Kilian Wenker'],ARXIV,http://arxiv.org/pdf/2201.00329v1,2022-01-02T10:07:38Z,2022-01-02T10:07:38Z,"['10.48550/arXiv.2201.00329', '10.1016/j.patter.2022.100545']","Employees face decisions every day - in the absence of supervision. The outcome of these decisions can be influenced by digital workplace design through the power of persuasive technology. This paper provides a structured literature review based on recent research on persuasive technology in the workplace. It examines the design and use of persuasive systems from a variety of disciplinary perspectives and theories. The reviewed studies were categorized into the research streams of technology design, user-centered research, and gamification. The purpose of the studies is categorized using a modified definition of the persuasive systems design model. A number of experimental studies show that alignment of the employee's behavior with the employer's agenda can be achieved. A robust finding is the key role of interactivity in granting employees a subjective experience of rapid and meaningful feedback when using the interface."
2201.00289,Nonvolatile Electric-Field Control of Inversion Symmetry,"['Lucas Caretta', 'Yu-Tsun Shao', 'Jia Yu', 'Antonio B. Mei', 'Bastien F. Grosso', 'Cheng Dai', 'Piush Behera', 'Daehun Lee', 'Margaret McCarter', 'Eric Parsonnet', 'Harikrishnan K. P.', 'Fei Xue', 'Ed Barnard', 'Steffen Ganschow', 'Archana Raja', 'Lane W. Martin', 'Long-Qing Chen', 'Manfred Fiebig', 'Keji Lai', 'Nicola A. Spaldin', 'David A. Muller', 'Darrell G. Schlom', 'Ramamoorthy Ramesh']",ARXIV,http://arxiv.org/pdf/2201.00289v1,2022-01-02T05:02:04Z,2022-01-02T05:02:04Z,['10.48550/arXiv.2201.00289'],"In condensed-matter systems, competition between ground states at phase boundaries can lead to significant changes in material properties under external stimuli, particularly when these ground states have different crystal symmetries. A key scientific and technological challenge is to stabilize and control coexistence of symmetry-distinct phases with external stimuli. Using BiFeO3 (BFO) layers confined between layers of the dielectric TbScO3 as a model system, we stabilize the mixed-phase coexistence of centrosymmetric and non-centrosymmetric BFO phases with antipolar, insulating and polar, semiconducting behavior, respectively at room temperature. Application of in-plane electric (polar) fields can both remove and introduce centrosymmetry from the system resulting in reversible, nonvolatile interconversion between the two phases. This interconversion between the centrosymmetric insulating and non-centrosymmetric semiconducting phases coincides with simultaneous changes in the non-linear optical response of over three orders of magnitude, a change in resistivity of over five orders of magnitude, and a change in the polar order. Our work establishes a materials platform allowing for novel cross-functional devices which take advantage of changes in optical, electrical, and ferroic responses."
2201.00343,Leader-Follower Synchronization of a Network of Boundary-Controlled Parabolic Equations With In-Domain Coupling,"['Abbas Kabalan', 'Francesco Ferrante', 'Giacomo Casadei', 'Andrea Cristofaro', 'Christophe Prieur']",ARXIV,http://arxiv.org/pdf/2201.00343v1,2022-01-02T12:07:04Z,2022-01-02T12:07:04Z,"['10.48550/arXiv.2201.00343', '10.1109/LCSYS.2021.3136097']","In this letter, we study the leader-synchronization problem for a class of partial differential equations with boundary control and in-domain coupling. We describe the problem in an abstract formulation and we specialize it to a network of parabolic partial differential equations. We consider a setting in which a subset of the followers is connected to the leader through a boundary control, while interconnections among the followers are enforced by distributed in-domain couplings. Sufficient conditions in the form of matrix inequalities for the selection of the control parameters enforcing exponential synchronization are given. Numerical simulations illustrate and corroborate the theoretical findings."
2201.00101,Analytical Shaping Method for Low-Thrust Rendezvous Trajectory Using Cubic Spline Functions,"['Di Wu', 'Tongxin Zhang', 'Yuan Zhong', 'Fanghua Jiang', 'Junfeng Li']",ARXIV,http://arxiv.org/pdf/2201.00101v1,2022-01-01T03:02:53Z,2022-01-01T03:02:53Z,"['10.48550/arXiv.2201.00101', '10.1016/j.actaastro.2022.01.019']","Preliminary mission design requires an efficient and accurate approximation to the low-thrust rendezvous trajectories, which might be generally three-dimensional and involve multiple revolutions. In this paper, a new shaping method using cubic spline functions is developed for the analytical approximation, which shows advantages in the optimality and computational efficiency. The rendezvous constraints on the boundary states and transfer time are all satisfied analytically, under the assumption that the boundary conditions and segment numbers of cubic spline functions are designated in advance. Two specific shapes are then formulated according to whether they have free optimization parameters. The shape without free parameters provides an efficient and robust estimation, while the other one allows a subsequent optimization for the satisfaction of additional constraints such as the constraint on the thrust magnitude. Applications of the proposed method in combination with the particle swarm optimization algorithm are discussed through two typical interplanetary rendezvous missions, that is, an inclined multi-revolution trajectory from the Earth to asteroid Dionysus and a multi-rendezvous trajectory of sample return. Simulation examples show that the proposed method is superior to existing methods in terms of providing good estimation for the global search and generating suitable initial guess for the subsequent trajectory optimization."
2201.00365,Establishing Strong Baselines for TripClick Health Retrieval,"['Sebastian Hofstätter', 'Sophia Althammer', 'Mete Sertkan', 'Allan Hanbury']",ARXIV,http://arxiv.org/pdf/2201.00365v1,2022-01-02T15:03:19Z,2022-01-02T15:03:19Z,['10.48550/arXiv.2201.00365'],"We present strong Transformer-based re-ranking and dense retrieval baselines for the recently released TripClick health ad-hoc retrieval collection. We improve the - originally too noisy - training data with a simple negative sampling policy. We achieve large gains over BM25 in the re-ranking task of TripClick, which were not achieved with the original baselines. Furthermore, we study the impact of different domain-specific pre-trained models on TripClick. Finally, we show that dense retrieval outperforms BM25 by considerable margins, even with simple training procedures."
2201.00397,Dispersion of Free-Falling Saliva Droplets by Two-Dimensional Vortical Flows,"['Orr Avni', 'Yuval Dagan']",ARXIV,http://arxiv.org/pdf/2201.00397v2,2022-01-02T19:29:51Z,2022-12-25T11:09:12Z,"['10.48550/arXiv.2201.00397', '10.1007/s00162-022-00633-y']","The dispersion of respiratory saliva droplets by indoor wake structures may enhance the transmission of various infectious diseases, as the wake spreads virus-laden droplets across the room. Thus, this study analyses the interaction between vortical wake structures and exhaled multi-component saliva droplets. A self-propelling analytically-described dipolar vortex is chosen as a model wake flow, passing through a cloud of micron-sized evaporating saliva droplets. The droplets' spatial location, velocity, diameter, and temperature are traced and coupled to their local flow field. For the first time, the wake structure decay is incorporated and analyzed, which is proved essential for accurately predicting the settling distances of the dispersed droplets. The model also considers the non-volatile saliva components, adequately capturing the essence of droplet-aerosol transition and predicting the equilibrium diameter of the residual aerosols. Our analytic model reveals non-intuitive interactions between wake flows, droplet relaxation time, gravity, and transport phenomena. We reveal that given the right conditions, a virus-laden saliva droplet might translate to distances two orders of magnitude larger than the carrier-flow characteristic size. Moreover, accounting for the non-volatile contents inside the droplet may lead to fundamentally different dispersion and settling behavior compared to non-evaporating particles or pure water droplets. Ergo, we suggest that the implementation of more complex evaporation models might be critical in high-fidelity simulations aspiring to assess the spread of airborne respiratory droplets."
2201.00128,Systolic Inequalities for Compact Quotients of Carnot Groups with Popp's Volume,['Kenshiro Tashiro'],ARXIV,http://arxiv.org/pdf/2201.00128v4,2022-01-01T06:30:29Z,2022-08-02T05:21:45Z,"['10.48550/arXiv.2201.00128', '10.3842/SIGMA.2022.058']","In this paper, we give a systolic inequality for a quotient space of a Carnot group $\Gamma\backslash G$ with Popp's volume. Namely we show the existence of a positive constant $C$ such that the systole of $\Gamma\backslash G$ is less than ${\rm Cvol}(\Gamma\backslash G)^{\frac{1}{Q}}$, where $Q$ is the Hausdorff dimension. Moreover, the constant depends only on the dimension of the grading of the Lie algebra $\mathfrak{g}=\bigoplus V_i$. To prove this fact, the scalar product on $G$ introduced in the definition of Popp's volume plays a key role."
2201.00402,A General Framework for Evaluating Robustness of Combinatorial Optimization Solvers on Graphs,"['Han Lu', 'Zenan Li', 'Runzhong Wang', 'Qibing Ren', 'Junchi Yan', 'Xiaokang Yang']",ARXIV,http://arxiv.org/pdf/2201.00402v2,2021-12-28T15:10:15Z,2022-06-04T11:55:48Z,['10.48550/arXiv.2201.00402'],"Solving combinatorial optimization (CO) on graphs is among the fundamental tasks for upper-stream applications in data mining, machine learning and operations research. Despite the inherent NP-hard challenge for CO, heuristics, branch-and-bound, learning-based solvers are developed to tackle CO problems as accurately as possible given limited time budgets. However, a practical metric for the sensitivity of CO solvers remains largely unexplored. Existing theoretical metrics require the optimal solution which is infeasible, and the gradient-based adversarial attack metric from deep learning is not compatible with non-learning solvers that are usually non-differentiable. In this paper, we develop the first practically feasible robustness metric for general combinatorial optimization solvers. We develop a no worse optimal cost guarantee thus do not require optimal solutions, and we tackle the non-differentiable challenge by resorting to black-box adversarial attack methods. Extensive experiments are conducted on 14 unique combinations of solvers and CO problems, and we demonstrate that the performance of state-of-the-art solvers like Gurobi can degenerate by over 20% under the given time limit bound on the hard instances discovered by our robustness metric, raising concerns about the robustness of combinatorial optimization solvers."
2201.00239,SporeAgent: Reinforced Scene-level Plausibility for Object Pose Refinement,"['Dominik Bauer', 'Timothy Patten', 'Markus Vincze']",ARXIV,http://arxiv.org/pdf/2201.00239v1,2022-01-01T20:26:19Z,2022-01-01T20:26:19Z,['10.48550/arXiv.2201.00239'],"Observational noise, inaccurate segmentation and ambiguity due to symmetry and occlusion lead to inaccurate object pose estimates. While depth- and RGB-based pose refinement approaches increase the accuracy of the resulting pose estimates, they are susceptible to ambiguity in the observation as they consider visual alignment. We propose to leverage the fact that we often observe static, rigid scenes. Thus, the objects therein need to be under physically plausible poses. We show that considering plausibility reduces ambiguity and, in consequence, allows poses to be more accurately predicted in cluttered environments. To this end, we extend a recent RL-based registration approach towards iterative refinement of object poses. Experiments on the LINEMOD and YCB-VIDEO datasets demonstrate the state-of-the-art performance of our depth-based refinement approach."
2201.00210,Ferroelectricity in $\mathrm{HfO_2}$ from a chemical perspective,"['Jun-Hui Yuan', 'Ge-Qi Mao', 'Kan-Hao Xue', 'Na Bai', 'Chengxu Wang', 'Yan Cheng', 'Hangbing Lyu', 'Huajun Sun', 'Xingsheng Wang', 'Xiangshui Miao']",ARXIV,http://arxiv.org/pdf/2201.00210v1,2022-01-01T15:32:14Z,2022-01-01T15:32:14Z,['10.48550/arXiv.2201.00210'],"Ferroelectricity observed in thin film $\mathrm{HfO_2}$, either doped with Si, Al, etc. or in the $\mathrm{Hf_{0.5}Zr_{0.5}O_2}$ form, has gained great technical significance. However, the soft mode theory faces a difficulty in explaining the origin of such ferroelectricity. In this work, we propose that the 7 cation coordination number of $\mathrm{HfO_2/ZrO_2}$ lies at the heart of this ferroelectricity, which stems from the proper ionic radii of Hf/Zr compared with O. Among the numerous compounds with non-centrosymmetric nature, e.g., $mm2$ point group, $\mathrm{HfO_2}$ and $\mathrm{ZrO_2}$ are special in that they are close to the border of 7 and 8 cation coordination, such that the 8-coordination tetragonal intermediate phase could greatly reduce the switching barrier. Other 7-coordination candidates, including $\mathrm{SrI_2}$, TaON, YSBr and YOF are also studied in comparison to $\mathrm{HfO_2}$/$\mathrm{ZrO_2}$, and six switching paths are analyzed in detail for the $Pca2_1$ phase. A rule of preferred switching path in terms of ionic radii ratio and coordination number has been established. We also show the possible route from ferroelectric $Pca2_1$ phase to monoclinic $P2_1/c$ phase in $\mathrm{HfO_2}$, which is relevant to the fatigue phenomenon."
2201.00200,Local heating due to convective overshooting and the solar modelling problem,"['Baraffe I', 'Constantino T', 'Clarke J', 'Le Saux A', 'Goffrey T', 'Guillet T', 'Pratt J', 'Vlaykov D. G']",ARXIV,http://arxiv.org/pdf/2201.00200v1,2022-01-01T14:52:28Z,2022-01-01T14:52:28Z,"['10.48550/arXiv.2201.00200', '10.1051/0004-6361/202142666']","Recent hydrodynamical simulations of convection in a solar-like model suggest that penetrative convective flows at the boundary of the convective envelope modify the thermal background in the overshooting layer. Based on these results, we implement in one-dimensional stellar evolution codes a simple prescription to modify the temperature gradient below the convective boundary of a solar model. This simple prescription qualitatively reproduces the behaviour found in the hydrodynamical simulations, namely a local heating and smoothing of the temperature gradient below the convective boundary. We show that introducing local heating in the overshooting layer can reduce the sound-speed discrepancy usually reported between solar models and the structure of the Sun inferred from helioseismology. It also affects key quantities in the convective envelope, such as the density, the entropy, and the speed of sound. These effects could help reduce the discrepancies between solar models and observed constraints based on seismic inversions of the Ledoux discriminant. Since mixing due to overshooting and local heating are the result of the same convective penetration process, the goal of this work is to invite solar modellers to consider both processes for a more consistent approach."
2201.00201,The period-age relation of long-period variables,"['Michele Trabucchi', 'Nami Mowlavi']",ARXIV,http://arxiv.org/pdf/2201.00201v2,2022-01-01T14:56:31Z,2022-01-17T15:43:28Z,"['10.48550/arXiv.2201.00201', '10.1051/0004-6361/202142853']","Pieces of empirical evidence suggest the existence of a period-age relation for long-period variables (LPVs). Yet, this property has hardly been studied on theoretical grounds thus far. We aim to examine the period-age relation using the results from recent nonlinear pulsation calculations. We combined isochrone models with theoretical periods to simulate the distribution of fundamental mode LPV pulsators, which include Miras, in the period-age plane, and we compared it with observations of LPVs in Galactic and Magellanic Clouds' clusters. In agreement with observations, models predict that the fundamental mode period decreases with increasing age because of the dominant role of mass in shaping stellar structure and evolution. At a given age, the period distribution shows a non-negligible width and is skewed toward short periods, except for young C-rich stars. As a result, the period-age relations of O-rich and C-rich models are predicted to have different slopes. We derived best-fit relations describing age and initial mass as a function of the fundamental mode period for both O- and C-rich models. The study confirms the power of the period-age relations to study populations of LPVs of specific types, either O-rich or C-rich, on statistical grounds. In doing so, it is recommended not to limit a study to Miras, which would make it prone to selection biases, but rather to include semi-regular variables that pulsate predominantly in the fundamental mode. The use of the relations to study individual LPVs, on the other hand, requires more care given the scatter in the period distribution predicted at any given age."
2201.00188,Entropically secure encryption with faster key expansion,"['Mehmet Huseyin Temel', 'Boris Skoric']",ARXIV,http://arxiv.org/pdf/2201.00188v4,2022-01-01T13:29:56Z,2022-10-23T06:44:41Z,['10.48550/arXiv.2201.00188'],"Entropically secure encryption is a way to encrypt a large plaintext with a small key and still have information-theoretic security, thus in a certain sense circumventing Shannon's result that perfect encryption requires the key to be at least as long as the entropy of the plaintext. Entropically secure encryption is not perfect, and it works only if a lower bound is known on the entropy of the plaintext. The typical implementation is to expand the short key to the size of the plaintext, e.g. by multiplication with a public random string, and then use one-time pad encryption. This works in the classical as well as the quantum setting. In this paper, we introduce a new key expansion method that is faster than existing ones. We prove that it achieves the same security. The speed gain is most notable when the key length is a sizeable fraction of the message length. In particular, a factor of 2 is gained in the case of approximate randomization of quantum states."
2201.00472,Clustering-based Partitioning for Large Web Graphs,"['Deyu Kong', 'Xike Xie', 'Zhuoxu Zhang']",ARXIV,http://arxiv.org/pdf/2201.00472v1,2022-01-03T04:46:31Z,2022-01-03T04:46:31Z,['10.48550/arXiv.2201.00472'],"Graph partitioning plays a vital role in distributedlarge-scale web graph analytics, such as pagerank and labelpropagation. The quality and scalability of partitioning strategyhave a strong impact on such communication- and computation-intensive applications, since it drives the communication costand the workload balance among distributed computing nodes.Recently, the streaming model shows promise in optimizing graphpartitioning. However, existing streaming partitioning strategieseither lack of adequate quality or fall short in scaling with alarge number of partitions.In this work, we explore the property of web graph clusteringand propose a novel restreaming algorithm for vertex-cut parti-tioning. We investigate a series of techniques, which are pipelinedas three steps, streaming clustering, cluster partitioning, andpartition transformation. More, these techniques can be adaptedto a parallel mechanism for further acceleration of partitioning.Experiments on real datasets and real systems show that ouralgorithm outperforms state-of-the-art vertex-cut partitioningmethods in large-scale web graph processing. Surprisingly, theruntime cost of our method can be an order of magnitude lowerthan that of one-pass streaming partitioning algorithms, whenthe number of partitions is large."
2201.00450,On randomized sketching algorithms and the Tracy-Widom law,"['Daniel Ahfock', 'William J. Astle', 'Sylvia Richardson']",ARXIV,http://arxiv.org/pdf/2201.00450v1,2022-01-03T02:11:45Z,2022-01-03T02:11:45Z,['10.48550/arXiv.2201.00450'],"There is an increasing body of work exploring the integration of random projection into algorithms for numerical linear algebra. The primary motivation is to reduce the overall computational cost of processing large datasets. A suitably chosen random projection can be used to embed the original dataset in a lower-dimensional space such that key properties of the original dataset are retained. These algorithms are often referred to as sketching algorithms, as the projected dataset can be used as a compressed representation of the full dataset. We show that random matrix theory, in particular the Tracy-Widom law, is useful for describing the operating characteristics of sketching algorithms in the tall-data regime when $n \gg d$. Asymptotic large sample results are of particular interest as this is the regime where sketching is most useful for data compression. In particular, we develop asymptotic approximations for the success rate in generating random subspace embeddings and the convergence probability of iterative sketching algorithms. We test a number of sketching algorithms on real large high-dimensional datasets and find that the asymptotic expressions give accurate predictions of the empirical performance."
2201.00147,High-dimensional Bayesian Optimization Algorithm with Recurrent Neural Network for Disease Control Models in Time Series,"['Yuyang Chen', 'Kaiming Bi', 'Chih-Hang J. Wu', 'David Ben-Arieh', 'Ashesh Sinha']",ARXIV,http://arxiv.org/pdf/2201.00147v1,2022-01-01T08:40:17Z,2022-01-01T08:40:17Z,['10.48550/arXiv.2201.00147'],"Bayesian Optimization algorithm has become a promising approach for nonlinear global optimization problems and many machine learning applications. Over the past few years, improvements and enhancements have been brought forward and they have shown some promising results in solving the complex dynamic problems, systems of ordinary differential equations where the objective functions are computationally expensive to evaluate. Besides, the straightforward implementation of the Bayesian Optimization algorithm performs well merely for optimization problems with 10-20 dimensions. The study presented in this paper proposes a new high dimensional Bayesian Optimization algorithm combining Recurrent neural networks, which is expected to predict the optimal solution for the global optimization problems with high dimensional or time series decision models. The proposed RNN-BO algorithm can solve the optimal control problems in the lower dimension space and then learn from the historical data using the recurrent neural network to learn the historical optimal solution data and predict the optimal control strategy for any new initial system value setting. In addition, accurately and quickly providing the optimal control strategy is essential to effectively and efficiently control the epidemic spread while minimizing the associated financial costs. Therefore, to verify the effectiveness of the proposed algorithm, computational experiments are carried out on a deterministic SEIR epidemic model and a stochastic SIS optimal control model. Finally, we also discuss the impacts of different numbers of the RNN layers and training epochs on the trade-off between solution quality and related computational efforts."
2201.00439,Salient Object Detection by LTP Texture Characterization on Opposing Color Pairs under SLICO Superpixel Constraint,"['Didier Ndayikengurukiye', 'Max Mignotte']",ARXIV,http://arxiv.org/pdf/2201.00439v1,2022-01-03T00:03:50Z,2022-01-03T00:03:50Z,"['10.48550/arXiv.2201.00439', '10.3390/jimaging8040110']","The effortless detection of salient objects by humans has been the subject of research in several fields, including computer vision as it has many applications. However, salient object detection remains a challenge for many computer models dealing with color and textured images. Herein, we propose a novel and efficient strategy, through a simple model, almost without internal parameters, which generates a robust saliency map for a natural image. This strategy consists of integrating color information into local textural patterns to characterize a color micro-texture. Most models in the literature that use the color and texture features treat them separately. In our case, it is the simple, yet powerful LTP (Local Ternary Patterns) texture descriptor applied to opposing color pairs of a color space that allows us to achieve this end. Each color micro-texture is represented by vector whose components are from a superpixel obtained by SLICO (Simple Linear Iterative Clustering with zero parameter) algorithm which is simple, fast and exhibits state-of-the-art boundary adherence. The degree of dissimilarity between each pair of color micro-texture is computed by the FastMap method, a fast version of MDS (Multi-dimensional Scaling), that considers the color micro-textures non-linearity while preserving their distances. These degrees of dissimilarity give us an intermediate saliency map for each RGB, HSL, LUV and CMY color spaces. The final saliency map is their combination to take advantage of the strength of each of them. The MAE (Mean Absolute Error) and F$_{\beta}$ measures of our saliency maps, on the complex ECSSD dataset show that our model is both simple and efficient, outperforming several state-of-the-art models."
2201.00311,Rough analysis of computation trees,['Mikhail Moshkov'],ARXIV,http://arxiv.org/pdf/2201.00311v1,2022-01-02T07:04:27Z,2022-01-02T07:04:27Z,['10.48550/arXiv.2201.00311'],"This paper deals with computation trees over an arbitrary structure consisting of a set along with collections of functions and predicates that are defined on it. It is devoted to the comparative analysis of three parameters of problems with $n$ input variables over this structure: the complexity of a problem description, the minimum complexity of a computation tree solving this problem deterministically, and the minimum complexity of a computation tree solving this problem nondeterministically. Rough classification of relationships among these parameters is considered and all possible seven types of these relations are enumerated. The changes of relation types with the growth of the number $n$ of input variables are studied."
2201.00234,Asymptotic Experiments with Data Structures: Bipartite Graph Matchings and Covers,"['Eason Li', 'Franc Brglez']",ARXIV,http://arxiv.org/pdf/2201.00234v1,2022-01-01T19:32:22Z,2022-01-01T19:32:22Z,['10.48550/arXiv.2201.00234'],"We consider instances of bipartite graphs and a number of asymptotic performance experiments in three projects: (1) top movie lists, given databases of movies and viewers, (2) maximum matchings, and (3) minimum set covers. Experiments are designed to measure the asymptotic runtime performance of abstract data types (ADTs) in three programming languages: Java, R, and C++. The outcomes of these experiments may be surprising. In project (1), the best ADT in R consistently outperforms all ADTs in public domain Java libraries, including the library from Google. The largest movie list has $2^{20}$ titles. In project (2), the Ford-Fulkerson algorithm implementation in R significantly outperforms Java. The hardest instance has 88452 rows and 729 columns. In project (3), a stochastic version of a greedy algorithm in R can significantly outperform a state-of-the-art stochastic solver in C++ on instances with $num\_rows \ge 300$ and $num\_columns \ge 3000$."
2201.00475,CaFT: Clustering and Filter on Tokens of Transformer for Weakly Supervised Object Localization,['Ming Li'],ARXIV,http://arxiv.org/pdf/2201.00475v1,2022-01-03T05:02:25Z,2022-01-03T05:02:25Z,['10.48550/arXiv.2201.00475'],"Weakly supervised object localization (WSOL) is a challenging task to localize the object by only category labels. However, there is contradiction between classification and localization because accurate classification network tends to pay attention to discriminative region of objects rather than the entirety. We propose this discrimination is caused by handcraft threshold choosing in CAM-based methods. Therefore, we propose Clustering and Filter of Tokens (CaFT) with Vision Transformer (ViT) backbone to solve this problem in another way. CaFT first sends the patch tokens of the image split to ViT and cluster the output tokens to generate initial mask of the object. Secondly, CaFT considers the initial mask as pseudo labels to train a shallow convolution head (Attention Filter, AtF) following backbone to directly extract the mask from tokens. Then, CaFT splits the image into parts, outputs masks respectively and merges them into one refined mask. Finally, a new AtF is trained on the refined masks and used to predict the box of object. Experiments verify that CaFT outperforms previous work and achieves 97.55\% and 69.86\% localization accuracy with ground-truth class on CUB-200 and ImageNet-1K respectively. CaFT provides a fresh way to think about the WSOL task."
2201.00465,Band structure of organic-ion-intercalated (EMIM)$_x$FeSe superconductor,"['L. V. Begunovich', 'M. M. Korshunov']",ARXIV,http://arxiv.org/pdf/2201.00465v2,2022-01-03T03:54:35Z,2022-03-25T17:13:04Z,"['10.48550/arXiv.2201.00465', '10.3390/ma15051856']","The band structure and the Fermi surface of the recently discovered superconductor (EMIM)$_x$FeSe are studied within the density functional theory in the generalized gradient approximation. We show that the bands near the Fermi level are formed primarily by Fe-$d$ orbitals. Although there is no direct contribution of EMIM orbitals to the near-Fermi level states, the presence of organic cations leads to a shift of the chemical potential. It results in the appearance of small electron pockets in the quasi-two-dimensional Fermi surface of (EMIM)$_x$FeSe."
2201.00110,The structure of pointwise recurrent expansive homeomorphisms,"['Enhui Shi', 'Hui Xu', 'Ziqi Yu']",ARXIV,http://arxiv.org/pdf/2201.00110v1,2022-01-01T04:39:01Z,2022-01-01T04:39:01Z,['10.48550/arXiv.2201.00110'],"Let $X$ be a compact metric space and let $f:X\rightarrow X$ be a homeomorphism on $X$. We show that if $f$ is both pointwise recurrent and expansive, then the dynamical system $(X, f)$ is topologically conjugate to a subshift of some symbolic system. Moreover, if $f$ is pointwise positively recurrent, then the subshift is semisimple; a counterexample is given to show the necessity of positive recurrence to ensure the semisimilicity."
2201.00230,Recover the spectrum of covariance matrix: a non-asymptotic iterative method,"['Juntao Duan', 'Ionel Popescu', 'Heinrich Matzinger']",ARXIV,http://arxiv.org/pdf/2201.00230v1,2022-01-01T18:44:31Z,2022-01-01T18:44:31Z,['10.48550/arXiv.2201.00230'],"It is well known the sample covariance has a consistent bias in the spectrum, for example spectrum of Wishart matrix follows the Marchenko-Pastur law. We in this work introduce an iterative algorithm 'Concent' that actively eliminate this bias and recover the true spectrum for small and moderate dimensions."
2201.00196,"Isostatic Modelling, Vertical Motion Rate Variation and Potential Detection of Past-Landslide in the Volcanic Island of Tahiti",['Julien Gargani'],ARXIV,http://arxiv.org/pdf/2201.00196v1,2022-01-01T14:43:34Z,2022-01-01T14:43:34Z,['10.48550/arXiv.2201.00196'],"Intraplate volcanic islands are often considered as stable relief with constant vertical motion and used for relative sea-level curves reconstruction. This study shows that large landslides cause non-negligible isostatic adjustment. The vertical motion that occurred after landslide is quantified using a modelling approach. We show that a giant landslide caused a coastline uplift of 80-110 m for an elastic thickness of 15 km < $T_e$ < 20 km in Tahiti. Theoretical cases also reveal that a coastal motion of 1 m occurred for a landslide involving a displaced volume of 0.2 $km^3$ and influence relative sea-level reconstruction. In Tahiti, a change in the subsidence rate of 0.1 mm/yr (from 0.25 mm/yr to 0.15 mm/yr) occurred during the last 6 kyr and could be explained by a landslide involving a minimum volume of 0.2 $km^3$, $6 \pm 1$ kyr ago."
2201.00217,Deep Nonparametric Estimation of Operators between Infinite Dimensional Spaces,"['Hao Liu', 'Haizhao Yang', 'Minshuo Chen', 'Tuo Zhao', 'Wenjing Liao']",ARXIV,http://arxiv.org/pdf/2201.00217v1,2022-01-01T16:33:44Z,2022-01-01T16:33:44Z,['10.48550/arXiv.2201.00217'],"Learning operators between infinitely dimensional spaces is an important learning task arising in wide applications in machine learning, imaging science, mathematical modeling and simulations, etc. This paper studies the nonparametric estimation of Lipschitz operators using deep neural networks. Non-asymptotic upper bounds are derived for the generalization error of the empirical risk minimizer over a properly chosen network class. Under the assumption that the target operator exhibits a low dimensional structure, our error bounds decay as the training sample size increases, with an attractive fast rate depending on the intrinsic dimension in our estimation. Our assumptions cover most scenarios in real applications and our results give rise to fast rates by exploiting low dimensional structures of data in operator estimation. We also investigate the influence of network structures (e.g., network width, depth, and sparsity) on the generalization error of the neural network estimator and propose a general suggestion on the choice of network structures to maximize the learning efficiency quantitatively."
2201.00369,Gravitational-wave Emission from a Primordial Black Hole Inspiraling inside a Compact Star: a Novel Probe for Dense Matter Equation of State,"['Ze-Cheng Zou', 'Yong-Feng Huang']",ARXIV,http://arxiv.org/pdf/2201.00369v4,2022-01-02T15:42:22Z,2023-03-09T08:47:12Z,"['10.48550/arXiv.2201.00369', '10.3847/2041-8213/ac5ea6']","Primordial black holes of planetary masses captured by compact stars are widely studied to constrain their composition fraction of dark matter. Such a capture may lead to an inspiral process and be detected through gravitational wave signals. In this Letter, we study the post-capture inspiral process by considering two different kinds of compact stars, i.e., strange stars and neutron stars. The dynamical equations are numerically solved and the gravitational wave emission is calculated. It is found that the Advanced LIGO can detect the inspiraling of a $10^{-5}$ solar mass primordial black hole at a distance of 10 kpc, while a Jovian-mass case can even be detected at megaparsecs. Promisingly, the next generation gravitational wave detectors can detect the cases of $10^{-5}$ solar mass primordial black holes up to ${\sim}1$ Mpc, and can detect Jovian-mass cases at several hundred megaparsecs. Moreover, the kilohertz gravitational wave signal shows significant differences for strange stars and neutron stars, potentially making it a novel probe to the dense matter equation of state."
2201.00172,"First-principles insights into the mechanical, optoelectronic, thermophysical, and lattice dynamical properties of binary topological semimetal BaGa2","['M. I. Naher', 'S. H. Naqib']",ARXIV,http://arxiv.org/pdf/2201.00172v1,2022-01-01T11:48:06Z,2022-01-01T11:48:06Z,['10.48550/arXiv.2201.00172'],"In the present study we have investigated the structural properties, electronic band dispersion, elastic constants, acoustic behavior, phonon spectrum, optical properties, and a number of thermophysical parameters of binary topological semimetal BaGa2 in details via first-principles calculations using the density functional theory (DFT) based formalisms. The electronic band structure and density of states calculations with spin orbit coupling reveal semimetallic nature with clear topological signature. The minimum thermal conductivities and anisotropies of the compound are calculated. The elastic constants, phonon dispersion calculations show that the compound under study is both mechanically and dynamically stable. Comprehensive study of elastic constants and moduli shows that BaGa2 possesses fairly isotropic mechanical properties, reasonably good machinability, low Debye temperature and melting point. The chemical bonding in BaG2 is interpreted via the electronic energy density of states, electron density distribution, elastic properties and Mulliken bond population analysis. The compound possesses both ionic and covalent bondings. The reflectivity spectra show strong anisotropy with respect to polarization of the incident electric field in the visible to mid-ultraviolet regions. High reflectivity over wide spectral range makes BaGa2 suitable as a reflecting material. BaGa2 is also an efficient absorber of ultraviolet radiation. Furthermore, the refractive index is quite high in the infrared to visible range. All the energy dependent optical parameters show metallic features and are in complete accord with the underlying bulk electronic density of states calculations. Most of the results presented in this study are novel and should serve as useful reference for future study."
2201.00181,The complementary Betz Theory,['Adriano Pellegri'],ARXIV,http://arxiv.org/pdf/2201.00181v1,2022-01-01T12:43:38Z,2022-01-01T12:43:38Z,['10.48550/arXiv.2201.00181'],"A classical derivation of Betz's law is first presented along with some insights. The extended Betz's theory is deduced for a rotor with axis orthogonal to the direction of an ideal fluid in uniform motion. The conceptual design used to demonstrate the generality of the aerodynamic aspects of energy conversion - starting from a suggestive approach to the classical theory and a geometric explanation of Betz's law - is defined by imposing compliance with the minimum requirements that a turbine must have to approximate the ideal efficiency of 16/27. The discovery of the role of the Betz's angles has permitted demonstrating the theory in a more general context, extending it from a flat, two-dimensional, representation to a deeper, three-dimensional, understanding of the problem. The ensuing result, in particular the possibility of obtaining constant yield and maximum efficiency through a finite topology of the actuator cylinder, implies in principle feasibility with a real turbine with axis perpendicular to the wind direction."
2201.00495,"let (rec) insertion without Effects, Lights or Magic","['Oleg Kiselyov', 'Jeremy Yallop']",ARXIV,http://arxiv.org/pdf/2201.00495v1,2022-01-03T06:32:39Z,2022-01-03T06:32:39Z,['10.48550/arXiv.2201.00495'],"Let insertion in program generation is producing code with definitions (let-statements). Although definitions precede uses in generated code, during code generation `uses' come first: we might not even know a definition is needed until we encounter a reoccurring expression. Definitions are thus generated `in hindsight', which explains why this process is difficult to understand and implement -- even more so for parameterized, recursive and mutually recursive definitions. We have earlier presented an interface for let(rec) insertion -- i.e. for generating (mutually recursive) definitions. We demonstrated its expressiveness and applications, but not its implementation, which relied on effects and compiler magic. We now show how one can understand let insertion, and hence implement it in plain OCaml. We give the first denotational semantics of let(rec)-insertion, which does not rely on any effects at all. The formalization has guided the implementation of let(rec) insertion in the current version of MetaOCaml."
2201.00236,Operator Deep Q-Learning: Zero-Shot Reward Transferring in Reinforcement Learning,"['Ziyang Tang', 'Yihao Feng', 'Qiang Liu']",ARXIV,http://arxiv.org/pdf/2201.00236v1,2022-01-01T19:52:38Z,2022-01-01T19:52:38Z,['10.48550/arXiv.2201.00236'],"Reinforcement learning (RL) has drawn increasing interests in recent years due to its tremendous success in various applications. However, standard RL algorithms can only be applied for single reward function, and cannot adapt to an unseen reward function quickly. In this paper, we advocate a general operator view of reinforcement learning, which enables us to directly approximate the operator that maps from reward function to value function. The benefit of learning the operator is that we can incorporate any new reward function as input and attain its corresponding value function in a zero-shot manner. To approximate this special type of operator, we design a number of novel operator neural network architectures based on its theoretical properties. Our design of operator networks outperform the existing methods and the standard design of general purpose operator network, and we demonstrate the benefit of our operator deep Q-learning framework in several tasks including reward transferring for offline policy evaluation (OPE) and reward transferring for offline policy optimization in a range of tasks."
2201.00489,Measure-Theoretically Mixing Subshifts with Low Complexity,"['Darren Creutz', 'Ronnie Pavlov', 'Shaun Rodock']",ARXIV,http://arxiv.org/pdf/2201.00489v3,2022-01-03T06:03:56Z,2022-04-14T18:33:11Z,['10.48550/arXiv.2201.00489'],"We introduce a class of rank-one transformations, which we call extremely elevated staircase transformations. We prove that they are measure-theoretically mixing and, for any $f : \mathbb{N} \to \mathbb{N}$ with $f(n)/n$ increasing and $\sum 1/f(n) < \infty$, that there exists an extremely elevated staircase with word complexity $p(n) = o(f(n))$. This improves the previously lowest known complexity for mixing subshifts, resolving a conjecture of Ferenczi."
2201.00231,An automatized Identity and Access Management system for IoT combining Self-Sovereign Identity and smart contracts,"['Montassar Naghmouchi', 'Hella Kaffel', 'Maryline Laurent']",ARXIV,http://arxiv.org/pdf/2201.00231v1,2022-01-01T18:46:08Z,2022-01-01T18:46:08Z,['10.48550/arXiv.2201.00231'],"Nowadays, open standards for self-sovereign identity and access management enable portable solutions that are following the requirements of IoT systems. This paper proposes a blockchain-based identity and access management system for IoT -- specifically smart vehicles -- as an example of use-case, showing two interoperable blockchains, Ethereum and Hyperledger Indy, and a self-sovereign identity model."
2201.00184,Secure Information Flow Typing in LUSTRE,"['Sanjiva Prasad', 'R. Madhukar Yerraguntla', 'Subodh Sharma']",ARXIV,http://arxiv.org/pdf/2201.00184v1,2022-01-01T13:07:06Z,2022-01-01T13:07:06Z,['10.48550/arXiv.2201.00184'],"Synchronous reactive data flow is a paradigm that provides a high-level abstract programming model for embedded and cyber-physical systems, including the locally synchronous components of IoT systems. Security in such systems is severely compromised due to low-level programming, ill-defined interfaces and inattention to security classification of data. By incorporating a Denning-style lattice-based secure information flow framework into a synchronous reactive data flow language, we provide a framework in which correct-and-secure-by-construction implementations for such systems may be specified and derived. In particular, we propose an extension of the Lustre programming framework with a security type system. The novelty of our type system lies in a symbolic formulation of constraints over security type variables, in particular the treatment of node calls, which allows us to reason about secure flow with respect to any security class lattice. The main theorem is the soundness of our type system with respect to the co-inductive operational semantics of Lustre, which we prove by showing that well-typed programs exhibit non-interference. Rather than tackle the full language, we first prove the non-interference result for a well-behaved sub-language called ""Normalised Lustre"" (NLustre), for which our type system is far simpler. We then show that Bourke et al.'s semantics-preserving ""normalisation"" transformations from Lustre to NLustre are security-preserving as well. This preservation of security types by the normalisation transformations is a property akin to ""subject reduction"" but at the level of compiler transformations. The main result that well-security-typed Lustre programs are non-interfering follows from a reduction to our earlier result of non-interference for NLustre via the semantics-preservation (of Bourke et al.) and type preservation results."
2201.00261,ARPIST: Provably Accurate and Stable Numerical Integration over Spherical Triangles,"['Yipeng Li', 'Xiangmin Jiao']",ARXIV,http://arxiv.org/pdf/2201.00261v2,2022-01-01T23:30:54Z,2022-06-07T15:52:42Z,['10.48550/arXiv.2201.00261'],"Numerical integration on spheres, including the computation of the areas of spherical triangles, is a core computation in geomathematics. The commonly used techniques sometimes suffer from instabilities and significant loss of accuracy. We describe a new algorithm, called ARPIST, for accurate and stable integration of functions on spherical triangles. ARPIST is based on an easy-to-implement transformation to the spherical triangle from its corresponding linear triangle via radial projection to achieve high accuracy and efficiency. More importantly, ARPIST overcomes potential instabilities in computing the Jacobian of the transformation, even for poorly shaped triangles that may occur at poles in regular longitude-latitude meshes, by avoiding potential catastrophic rounding errors. We compare our proposed technique with L'Huilier's Theorem for computing the area of spherical triangles, and also compare it with the recently developed LSQST method (J. Beckmann, H.N. Mhaskar, and J. Prestin, GEM - Int. J. Geomath., 5:143-162, 2014) and a radial-basis-function-based technique (J. A. Reeger and B. Fornberg, Stud. Appl. Math., 137:174-188, 2015) for integration of smooth functions on spherical triangulations. Our results show that ARPIST enables superior accuracy and stability over previous methods while being orders of magnitude faster and significantly easier to implement."
2201.00486,Using Non-Stationary Bandits for Learning in Repeated Cournot Games with Non-Stationary Demand,"['Kshitija Taywade', 'Brent Harrison', 'Judy Goldsmith']",ARXIV,http://arxiv.org/pdf/2201.00486v1,2022-01-03T05:51:47Z,2022-01-03T05:51:47Z,['10.48550/arXiv.2201.00486'],"Many past attempts at modeling repeated Cournot games assume that demand is stationary. This does not align with real-world scenarios in which market demands can evolve over a product's lifetime for a myriad of reasons. In this paper, we model repeated Cournot games with non-stationary demand such that firms/agents face separate instances of non-stationary multi-armed bandit problem. The set of arms/actions that an agent can choose from represents discrete production quantities; here, the action space is ordered. Agents are independent and autonomous, and cannot observe anything from the environment; they can only see their own rewards after taking an action, and only work towards maximizing these rewards. We propose a novel algorithm 'Adaptive with Weighted Exploration (AWE) $\epsilon$-greedy' which is remotely based on the well-known $\epsilon$-greedy approach. This algorithm detects and quantifies changes in rewards due to varying market demand and varies learning rate and exploration rate in proportion to the degree of changes in demand, thus enabling agents to better identify new optimal actions. For efficient exploration, it also deploys a mechanism for weighing actions that takes advantage of the ordered action space. We use simulations to study the emergence of various equilibria in the market. In addition, we study the scalability of our approach in terms number of total agents in the system and the size of action space. We consider both symmetric and asymmetric firms in our models. We found that using our proposed method, agents are able to swiftly change their course of action according to the changes in demand, and they also engage in collusive behavior in many simulations."
2201.00266,Cloaked near-field probe for non-invasive near-field optical microscopy,"['Felipe Bernal Arango', 'Filippo Alpeggiani', 'Donato Conteduca', 'Aron Opheij', 'Aobo Chen', 'Mohamed I. Abdelrahman', 'Thomas Krauss', 'Andrea Alu', 'Francesco Monticone', 'L. Kuipers']",ARXIV,http://arxiv.org/pdf/2201.00266v1,2022-01-02T00:28:50Z,2022-01-02T00:28:50Z,['10.48550/arXiv.2201.00266'],"Near-field scanning optical microscopy is a powerful technique for imaging below the diffraction limit, which has been extensively used in bio-medical imaging and nanophotonics. However, when the electromagnetic fields under measurement are strongly confined, they can be heavily perturbed by the presence of the near-field probe itself. Here, taking inspiration from scattering-cancellation invisibility cloaks, Huygens-Kerker scatterers, and cloaked sensors, we design and fabricate a cloaked near-field probe. We show that, by suitably nanostructuring the probe, its electric and magnetic polarizabilities can be controlled and balanced. As a result, probe-induced perturbations can be largely suppressed, effectively cloaking the near-field probe without preventing its ability to measure. We experimentally demonstrate the cloaking effect by comparing the interaction of conventional and nanostructured probes with a representative nanophotonic structure, namely, a 1D photonic-crystal cavity. Our results show that, by engineering the structure of the probe, one can systematically control its back-action on the resonant fields of the sample and decrease the perturbation by >70% with most of our modified probes, and by up to one order of magnitude for the best probe, at probe-sample distances of 100 nm. Our work paves the way for non-invasive near-field optical microscopy of classical and quantum nano-systems."
2201.00240,Partial symmetries of iterated plethysms,"['Álvaro Gutiérrez', 'Mercedes H. Rosas']",ARXIV,http://arxiv.org/pdf/2201.00240v2,2022-01-01T20:27:46Z,2023-05-30T10:02:49Z,"['10.48550/arXiv.2201.00240', '10.1007/s00026-023-00652-4']","This work highlights the existence of partial symmetries in large families of iterated plethystic coefficients. The plethystic coefficients involved come from the expansion in the Schur basis of iterated plethysms of Schur functions indexed by one-row partitions. The partial symmetries are described in terms of an involution on partitions, the flip involution, that generalizes the ubiquitous $\omega$ involution. Schur-positive symmetric functions possessing this partial symmetry are termed flip-symmetric. The operation of taking plethysm with $s_\lambda$ preserves flip-symmetry, provided that $\lambda$ is a partition of two. Explicit formulas for the iterated plethysms $s_2\circ s_b\circ s_a$ and $s_c\circ s_2\circ s_a$, with $a,$ $b,$ and $c$ $\ge$ $2$ allow us to show that these two families of iterated plethysms are flip-symmetric. The article concludes with some observations, remarks, and open questions on the unimodality and asymptotic normality of certain flip-symmetric sequences of iterated plethystic coefficients."
2201.00370,Decoding Nonbinary LDPC Codes via Proximal-ADMM Approach (include convergence proofs),"['Yongchao Wang', 'Jing Bai']",ARXIV,http://arxiv.org/pdf/2201.00370v1,2022-01-02T15:59:18Z,2022-01-02T15:59:18Z,['10.48550/arXiv.2201.00370'],"In this paper, we focus on decoding nonbinary low-density parity-check (LDPC) codes in Galois fields of characteristic two via the proximal alternating direction method of multipliers (proximal-ADMM). By exploiting Flanagan/Constant-Weighting embedding techniques and the decomposition technique based on three-variables parity-check equations, two efficient proximal-ADMM decoders for nonbinary LDPC codes are proposed. We show that both of them are theoretically guaranteed convergent to some stationary point of the decoding model and either of their computational complexities in each proximal-ADMM iteration scales linearly with LDPC code's length and the size of the considered Galois field. Moreover, the decoder based on the Constant-Weight embedding technique satisfies the favorable property of codeword symmetry. Simulation results demonstrate their effectiveness in comparison with state-of-the-art LDPC decoders."
2201.00484,Secure Spectrum and Resource Sharing for 5G Networks using a Blockchain-based Decentralized Trusted Computing Platform,"['Hisham A. Kholidy', 'Mohammad A. Rahman', 'Andrew Karam', 'Zahid Akhtar']",ARXIV,http://arxiv.org/pdf/2201.00484v1,2022-01-03T05:40:17Z,2022-01-03T05:40:17Z,['10.48550/arXiv.2201.00484'],"The 5G network would fuel next-gen, bandwidth-heavy technologies such as automation, IoT, and AI on the factory floor. It will improve efficiency by powering AR overlays in workflows, as well as ensure safer practices and reduce the number of defects through predictive analytics and real-time detection of damage. The Dynamic Spectrum Sharing (DSS) in 5G networks will permit 5G NR and 4G LTE to coexist and will provide cost-effective and efficient solutions that enable a smooth transition from 4G to 5G. However, this increases the attack surface in the 5G networks. To the best of our knowledge, none of the current works introduces a real-time secure spectrum-sharing mechanism for 5G networks to defend spectrum resources and applications. This paper aims to propose a Blockchain-based Decentralized Trusted Computing Platform (BTCP) to self-protect large-scale 5G spectrum resources against cyberattacks in a timely, dynamic, and accurate way. Furthermore, the platform provides a decentralized, trusted, and non-repudiating platform to enable secure spectrum sharing and data exchange between the 5G spectrum resources"
2201.00485,Freeway to Memory Level Parallelism in Slice-Out-of-Order Cores,"['Rakesh Kumar', 'Mehdi Alipour', 'David Black-Schaffer']",ARXIV,http://arxiv.org/pdf/2201.00485v1,2022-01-03T05:46:31Z,2022-01-03T05:46:31Z,['10.48550/arXiv.2201.00485'],"Exploiting memory level parallelism (MLP) is crucial to hide long memory and last level cache access latencies. While out-of-order (OoO) cores, and techniques building on them, are effective at exploiting MLP, they deliver poor energy efficiency due to their complex and energy-hungry hardware. This work revisits slice-out-of-order (sOoO) cores as an energy efficient alternative for MLP exploitation. sOoO cores achieve energy efficiency by constructing and executing \textit{slices} of MLP generating instructions out-of-order only with respect to the rest of instructions; the slices and the remaining instructions, by themselves, execute in-order. However, we observe that existing sOoO cores miss significant MLP opportunities due to their dependence-oblivious in-order slice execution, which causes dependent slices to frequently block MLP generation. To boost MLP generation, we introduce Freeway, a sOoO core based on a new dependence-aware slice execution policy that tracks dependent slices and keeps them from blocking subsequent independent slices and MLP extraction. The proposed core incurs minimal area and power overheads, yet approaches the MLP benefits of fully OoO cores. Our evaluation shows that Freeway delivers 12% better performance than the state-of-the-art sOoO core and is within 7% of the MLP limits of full OoO execution."
2201.00288,Community Search: A Meta-Learning Approach,"['Shuheng Fang', 'Kangfei Zhao', 'Guanghua Li', 'Jeffery Xu Yu']",ARXIV,http://arxiv.org/pdf/2201.00288v3,2022-01-02T04:29:02Z,2023-10-08T09:15:58Z,['10.48550/arXiv.2201.00288'],"Community Search (CS) is one of the fundamental graph analysis tasks, which is a building block of various real applications. Given any query nodes, CS aims to find cohesive subgraphs that query nodes belong to. Recently, a large number of CS algorithms are designed. These algorithms adopt predefined subgraph patterns to model the communities, which cannot find ground-truth communities that do not have such pre-defined patterns in real-world graphs. Thereby, machine learning (ML) and deep learning (DL) based approaches are proposed to capture flexible community structures by learning from ground-truth communities in a data-driven fashion. These approaches rely on sufficient training data to provide enough generalization for ML models, however, the ground-truth cannot be comprehensively collected beforehand. In this paper, we study ML/DL-based approaches for CS, under the circumstance of small training data. Instead of directly fitting the small data, we extract prior knowledge which is shared across multiple CS tasks via learning a meta model. Each CS task is a graph with several queries that possess corresponding partial ground-truth. The meta model can be swiftly adapted to a task to be predicted by feeding a few task-specific training data. We find that trivially applying multiple classical metalearning algorithms to CS suffers from problems regarding prediction effectiveness, generalization capability and efficiency. To address such problems, we propose a novel meta-learning based framework, Conditional Graph Neural Process (CGNP), to fulfill the prior extraction and adaptation procedure. A meta CGNP model is a task-common node embedding function for clustering, learned by metric-based graph learning, which fully exploits the characteristics of CS. We compare CGNP with CS algorithms and ML baselines on real graphs with ground-truth communities."
2201.00124,Bird Species Classification And Acoustic Features Selection Based on Distributed Neural Network with Two Stage Windowing of Short-Term Features,['Nahian Ibn Hasan'],ARXIV,http://arxiv.org/pdf/2201.00124v1,2022-01-01T05:42:20Z,2022-01-01T05:42:20Z,['10.48550/arXiv.2201.00124'],"Identification of bird species from audio records is one of the challenging tasks due to the existence of multiple species in the same recording, noise in the background, and long-term recording. Besides, choosing a proper acoustic feature from audio recording for bird species classification is another problem. In this paper, a hybrid method is represented comprising both traditional signal processing and a deep learning-based approach to classify bird species from audio recordings of diverse sources and types. Besides, a detailed study with 34 different features helps to select the proper feature set for classification and analysis in real-time applications. Moreover, the proposed deep neural network uses both acoustic and temporal feature learning. The proposed method starts with detecting voice activity from the raw signal, followed by extracting short-term features from the processed recording using 50 ms (with 25ms overlapping) time windows. Later, the short-term features are reshaped using second stage (non-overlapping) windowing to be trained through a distributed 2D Convolutional Neural Network (CNN) that forwards the output features to a Long and Short Term Memory (LSTM) Network. Then a final dense layer classifies the bird species. For the 10 class classifier, the highest accuracy achieved was 90.45\% for a feature set consisting of 13 Mel Frequency Cepstral Coefficients (MFCCs) and 12 Chroma Vectors. The corresponding specificity and AUC scores are 98.94\% and 94.09\%, respectively."
2201.00297,AutoDisk: Automated Diffraction Processing and Strain Mapping in 4D-STEM,"['Sihan Wang', 'Tim Eldred', 'Jacob Smith', 'Wenpei Gao']",ARXIV,http://arxiv.org/pdf/2201.00297v1,2022-01-02T05:33:14Z,2022-01-02T05:33:14Z,['10.48550/arXiv.2201.00297'],"Development in lattice strain mapping using four-dimensional scanning transmission electron microscopy (4D-STEM) method now offers improved precision and feasibility. However, automatic and accurate diffraction analysis is still challenging due to noise and the complexity of intensity in diffraction patterns. In this work, we demonstrate an approach, employing the blob detection on cross-correlated diffraction patterns followed by lattice fitting algorithm, to automate the processing of four-dimensional data, including identifying and locating disks, and extracting local lattice parameters without prior knowledge about the material. The approach is both tested using simulated diffraction patterns and applied on experimental data acquired from a Pd@Pt core-shell nanoparticle. Our method shows robustness against various sample thicknesses and high noise, capability to handle complex patterns, and picometer-scale accuracy in strain measurement, making it a promising tool for high-throughput 4D-STEM data processing."
2201.00407,Aprendizaje de los números complejos usando diferentes sistemas de cálculo simbólico y un sistema de evaluación en línea en formación inicial de profesores,"['Jorge Gaona', 'Silvia López', 'Elizabeth Montoya Delgadillo']",ARXIV,http://arxiv.org/pdf/2201.00407v1,2022-01-02T19:51:45Z,2022-01-02T19:51:45Z,['10.48550/arXiv.2201.00407'],"En este art\'iculo se estudi\'o el trabajo matem\'atico personal de 15 profesores en formaci\'on inicial, en primer a\~no de una universidad p\'ublica en Chile, a partir de dos tareas sobre n\'umeros complejos. Estas tareas se plantearon en un CAA (Moodlle - Wiris) y se propuso resolverlas utilizando distintos CAS, como GeoGebra, Symbolab, Photomath y Wolfram Alpha entre otros. Se observaron dificultades y potencialidades en el trabajo matem\'atico de los estudiantes. En las dificultades, se observ\'o que los estudiantes ten\'ian problemas para interpretar la informaci\'on de los CAS y del feedback del CAA debido a que los conocimientos matem\'aticos previos no eran lo suficientemente solidos para hacerlo. En las potencialidades, se observ\'o que distintas caracter\'isticas de la tarea, junto con la articulaci\'on de dos o m\'as artefactos permiti\'o a los estudiantes darle significado a los objetos matem\'aticos involucrados. In this article we studied the personal mathematical work of 15 teachers in initial training, in the first year of a public university in Chile, based on two tasks on complex numbers. These tasks were presented in a CAA (Moodlle - Wiris) and it was proposed to solve them using different CAS, such as GeoGebra, Symbolab, Photomath and Wolfram Alpha, among others. Difficulties and potentialities were observed in the mathematical work of the students. In the difficulties, it was observed that the students had problems interpreting the information from the CAS and the AAC feedback because their previous mathematical knowledge was not solid enough to do so. In the potentialities, it was observed that different characteristics of the task, together with the articulation of two or more artifacts allowed students to give meaning to the mathematical objects involved."
2201.00447,Distinction and quadratic base change for regular supercuspidal representations,['Chuijia Wang'],ARXIV,http://arxiv.org/pdf/2201.00447v1,2022-01-03T01:20:32Z,2022-01-03T01:20:32Z,['10.48550/arXiv.2201.00447'],"In this article, we study Prasad's conjecture for regular supercuspidal representations based on the machinery developed by Hakim and Murnaghan to study distinguished representations, and the fundamental work of Kaletha on parameterization of regular supercuspidal representations. For regular supercuspidal representations, we give some new interpretations of the numerical quantities appearing in Prasad's formula, and reduce the proof to the case of tori. The proof of Prasad's conjecture then reduces to a comparison of various quadratic characters appearing naturally in the above process. We also have some new observations on these characters and study the relation between them in detail. For some particular examples, we show the coincidence of these characters, which gives a new purely local proof of Prasad's conjecture for regular supercuspidal representations of these groups. We also prove Prasad's conjecture for regular supercuspidal representations of G(E), when E/F is unramified and G is a general quasi-split reductive group."
2201.00229,Understanding Energy Efficiency and Interference Tolerance in Millimeter Wave Receivers,"['Panagiotis Skrimponis', 'Seongjoon Kang', 'Abbas Khalili', 'Wonho Lee', 'Navid Hosseinzadeh', 'Marco Mezzavilla', 'Elza Erkip', 'Mark J. W. Rodwell', 'James F. Buckwalter', 'Sundeep Rangan']",ARXIV,http://arxiv.org/pdf/2201.00229v1,2022-01-01T18:43:40Z,2022-01-01T18:43:40Z,['10.48550/arXiv.2201.00229'],"Power consumption is a key challenge in millimeter wave (mmWave) receiver front-ends, due to the need to support high dimensional antenna arrays at wide bandwidths. Recently, there has been considerable work in developing low-power front-ends, often based on low-resolution ADCs and low-power mixers. A critical but less studied consequence of such designs is the relatively low-dynamic range which in turn exposes the receiver to adjacent carrier interference and blockers. This paper provides a general mathematical framework for analyzing the performance of mmWave front-ends in the presence of out-of-band interference. The goal is to elucidate the fundamental trade-off of power consumption, interference tolerance and in-band performance. The analysis is combined with detailed network simulations in cellular systems with multiple carriers, as well as detailed circuit simulations of key components at 140 GHz. The analysis reveals critical bottlenecks for low-power interference robustness and suggests designs enhancements for use in practical systems."
2201.00334,Primal-Dual Method for Optimization Problems with Changing Constraints,['Igor Konnov'],ARXIV,http://arxiv.org/pdf/2201.00334v1,2022-01-02T11:09:37Z,2022-01-02T11:09:37Z,['10.48550/arXiv.2201.00334'],We propose a modified primal-dual method for general convex optimization problems with changing constraints. We obtain properties of Lagrangian saddle points for these problems which enable us to establish convergence of the proposed method. We describe specializations of the proposed approach to multi-agent optimization problems under changing communication topology and to feasibility problems.
2201.00222,Multi-fidelity Bayesian experimental design to quantify extreme-event statistics,"['Xianliang Gong', 'Yulin Pan']",ARXIV,http://arxiv.org/pdf/2201.00222v1,2022-01-01T17:55:01Z,2022-01-01T17:55:01Z,['10.48550/arXiv.2201.00222'],"In this work, we develop a multi-fidelity Bayesian experimental design framework to efficiently quantify the extreme-event statistics of an input-to-response (ItR) system with given input probability and expensive function evaluations. The key idea here is to leverage low-fidelity samples whose responses can be computed with a cost of a certain fraction of that for high-fidelity samples, in an optimized configuration to reduce the total computational cost. To accomplish this goal, we employ a multi-fidelity Gaussian process as the surrogate model of the ItR function, and develop a new acquisition based on which the optimized next sample can be selected in terms of its location in the sample space and the fidelity level. In addition, we develop an inexpensive analytical evaluation of the acquisition and its derivative, avoiding numerical integrations that are prohibitive for high-dimensional problems. The new method is tested in a bi-fidelity context for a series of synthetic problems with varying dimensions, low-fidelity model accuracy and computational costs. Comparing with the single-fidelity method and the bi-fidelity method with a pre-defined fidelity hierarchy, our method consistently shows the best (or among the best) performance for all the test cases. Finally, we demonstrate the superiority of our method in solving an engineering problem of estimating the extreme ship motion statistics in irregular waves, using computational fluid dynamics (CFD) with two different grid resolutions as the high and low fidelity models."
2201.00468,A General Framework for Treatment Effect Estimation in Semi-Supervised and High Dimensional Settings,"['Abhishek Chakrabortty', 'Guorong Dai', 'Eric Tchetgen Tchetgen']",ARXIV,http://arxiv.org/pdf/2201.00468v2,2022-01-03T04:12:44Z,2022-01-24T10:52:09Z,['10.48550/arXiv.2201.00468'],"In this article, we aim to provide a general and complete understanding of semi-supervised (SS) causal inference for treatment effects. Specifically, we consider two such estimands: (a) the average treatment effect and (b) the quantile treatment effect, as prototype cases, in an SS setting, characterized by two available data sets: (i) a labeled data set of size $n$, providing observations for a response and a set of high dimensional covariates, as well as a binary treatment indicator; and (ii) an unlabeled data set of size $N$, much larger than $n$, but without the response observed. Using these two data sets, we develop a family of SS estimators which are ensured to be: (1) more robust and (2) more efficient than their supervised counterparts based on the labeled data set only. Beyond the 'standard' double robustness results (in terms of consistency) that can be achieved by supervised methods as well, we further establish root-n consistency and asymptotic normality of our SS estimators whenever the propensity score in the model is correctly specified, without requiring specific forms of the nuisance functions involved. Such an improvement of robustness arises from the use of the massive unlabeled data, so it is generally not attainable in a purely supervised setting. In addition, our estimators are shown to be semi-parametrically efficient as long as all the nuisance functions are correctly specified. Moreover, as an illustration of the nuisance estimators, we consider inverse-probability-weighting type kernel smoothing estimators involving unknown covariate transformation mechanisms, and establish in high dimensional scenarios novel results on their uniform convergence rates, which should be of independent interest. Numerical results on both simulated and real data validate the advantage of our methods over their supervised counterparts with respect to both robustness and efficiency."
2201.00444,Dynamical Stability of the Power Law K-essence Dark Energy Model with a New Interaction,"['Qile Zhang', 'Wei Fang', 'Chenggang Shu']",ARXIV,http://arxiv.org/pdf/2201.00444v2,2022-01-03T00:57:13Z,2022-01-20T12:58:21Z,['10.48550/arXiv.2201.00444'],"We investigate the cosmological evolution of the power law K-essence dark energy (DE) model $F(X)= -\sqrt{X} + X$ with a new interaction $Q = \alpha\rho _m\rho _{\phi }H^{-1}$ in FRWL spacetime. The evolution behavior of dark energy under this interaction is analyzed by using dynamical systems method, and ten critical points are obtained. Among those critical points, a new stable point, which we called Scaling-like dark energy(DE) solution, is very important and interesting. The cosmological meaning of this attractor is different from the Scaling solution and dark energy dominated solution. For some value of model parameters, the universe will evolve to the attractor solution with the dark energy density parameter $\Omega_{\phi}=0.682946$ and the the equation of state $w_{\phi}=-0.99$, which can be in good agreement with the observed data, and alleviate the Coincidence Problem."
2201.00237,Understanding Public Opinion on Using Hydroxychloroquine for COVID-19 Treatment via Social Media,"['Thuy T. Do', 'Du Nguyen', 'Anh Le', 'Anh Nguyen', 'Dong Nguyen', 'Nga Hoang', 'Uyen Le', 'Tuan Tran']",ARXIV,http://arxiv.org/pdf/2201.00237v1,2022-01-01T20:10:48Z,2022-01-01T20:10:48Z,['10.48550/arXiv.2201.00237'],"Hydroxychloroquine (HCQ) is used to prevent or treat malaria caused by mosquito bites. Recently, the drug has been suggested to treat COVID-19, but that has not been supported by scientific evidence. The information regarding the drug efficacy has flooded social networks, posting potential threats to the community by perverting their perceptions of the drug efficacy. This paper studies the reactions of social network users on the recommendation of using HCQ for COVID-19 treatment by analyzing the reaction patterns and sentiment of the tweets. We collected 164,016 tweets from February to December 2020 and used a text mining approach to identify social reaction patterns and opinion change over time. Our descriptive analysis identified an irregularity of the users' reaction patterns associated tightly with the social and news feeds on the development of HCQ and COVID-19 treatment. The study linked the tweets and Google search frequencies to reveal the viewpoints of local communities on the use of HCQ for COVID-19 treatment across different states. Further, our tweet sentiment analysis reveals that public opinion changed significantly over time regarding the recommendation of using HCQ for COVID-19 treatment. The data showed that high support in the early dates but it significantly declined in October. Finally, using the manual classification of 4,850 tweets by humans as our benchmark, our sentiment analysis showed that the Google Cloud Natural Language algorithm outperformed the Valence Aware Dictionary and sEntiment Reasoner in classifying tweets, especially in the sarcastic tweet group."
2201.00401,Investigating the Longitudinal Development of EAS with Ultra High Energies,"['Abbas Rahi Raham', 'A. A. Al-Rubaiee', 'Majida H. Al-Kubaisy']",ARXIV,http://arxiv.org/pdf/2201.00401v1,2021-12-16T20:54:41Z,2021-12-16T20:54:41Z,"['10.48550/arXiv.2201.00401', '10.1088/1742-6596/1484/1/012024']",The simulation of the extensive air showers was performed by investigating the longitudinal development parameters (N and Xmax) by using AIRES system version 19.04.0. The simulation was performed at the energy range (10^18-10^20 eV) for different primary particles (such as primary proton and iron nuclei) and different zenith angles. The longitudinal development curves of EAS are fitted using Gaussian function that gave a new parameters for different primary particles and different zenith angles at the energy range (10^18-10^20 eV).
2201.00320,Computational fluid dynamic simulation of hull reservoir wave energy device,"['V A U De Alwis', 'A P K De Silva', 'S D G S P Gunawardane', 'Young-Ho Lee']",ARXIV,http://arxiv.org/pdf/2201.00320v2,2022-01-02T08:55:59Z,2022-01-09T04:28:18Z,"['10.48550/arXiv.2201.00320', '10.1088/1742-6596/2217/1/012041']","This paper presents a Computational Fluid Dynamics (CFD) analysis of a wave energy device called the Hull Reservoir Wave Energy Converter (HRWEC). The device consists of a floating hull and a flap connected to the shaft of power take-off system (PTO), which is integral to the hull structure. It is unique due to its ability to convert wave energy by utilizing the pitch motion of the hull and rotating flap due to the internal water movement in the hull. Due to the complexity of the internal fluid dynamics, a CFD-based analysis was considered most appropriate. The CFD investigation of the dynamics of the device was done under regular wave conditions by using the ANSYS-AQWA and ANSYS FLUENT. Relative pitch angle variation, the hydrodynamic coefficients, which determine the degree of power extraction, were obtained from simulated results. A simulation was designed exhibiting complete system dynamics for different configurations varying on internal water height. Excellent convergence was observed,and an optimum configuration was identified. It is expected to validate the simulation results through experiments in the foreseeable future."
2201.00469,Feedback-efficient Active Preference Learning for Socially Aware Robot Navigation,"['Ruiqi Wang', 'Weizheng Wang', 'Byung-Cheol Min']",ARXIV,http://arxiv.org/pdf/2201.00469v4,2022-01-03T04:21:51Z,2022-07-31T19:21:07Z,['10.48550/arXiv.2201.00469'],"Socially aware robot navigation, where a robot is required to optimize its trajectory to maintain comfortable and compliant spatial interactions with humans in addition to reaching its goal without collisions, is a fundamental yet challenging task in the context of human-robot interaction. While existing learning-based methods have achieved better performance than the preceding model-based ones, they still have drawbacks: reinforcement learning depends on the handcrafted reward that is unlikely to effectively quantify broad social compliance, and can lead to reward exploitation problems; meanwhile, inverse reinforcement learning suffers from the need for expensive human demonstrations. In this paper, we propose a feedback-efficient active preference learning approach, FAPL, that distills human comfort and expectation into a reward model to guide the robot agent to explore latent aspects of social compliance. We further introduce hybrid experience learning to improve the efficiency of human feedback and samples, and evaluate benefits of robot behaviors learned from FAPL through extensive simulation experiments and a user study (N=10) employing a physical robot to navigate with human subjects in real-world scenarios. Source code and experiment videos for this work are available at:https://sites.google.com/view/san-fapl."
2201.00159,Quasilinear logarithmic Choquard equations with exponential growth in $\mathbb{R}^N$,"['Claudia Bucur', 'Daniele Cassani', 'Cristina Tarsi']",ARXIV,http://arxiv.org/pdf/2201.00159v1,2022-01-01T10:33:11Z,2022-01-01T10:33:11Z,['10.48550/arXiv.2201.00159'],"We consider the $N$-Laplacian Schr\""odinger equation strongly coupled with higher order fractional Poisson's equations. When the order of the Riesz potential $\alpha$ is equal to the Euclidean dimension $N$, and thus it is a logarithm, the system turns out to be equivalent to a nonlocal Choquard type equation. On the one hand, the natural function space setting in which the Schr\""odinger energy is well defined is the Sobolev limiting space $W^{1,N}(\mathbb{R}^N)$, where the maximal nonlinear growth is of exponential type. On the other hand, in order to have the nonlocal energy well defined and prove the existence of finite energy solutions, we introduce a suitable $log$-weighted variant of the Pohozaev-Trudinger inequality which provides a proper functional framework where we use variational methods."
2201.00404,MHATC: Autism Spectrum Disorder identification utilizing multi-head attention encoder along with temporal consolidation modules,"['Ranjeet Ranjan Jha', 'Abhishek Bhardwaj', 'Devin Garg', 'Arnav Bhavsar', 'Aditya Nigam']",ARXIV,http://arxiv.org/pdf/2201.00404v1,2021-12-27T07:50:16Z,2021-12-27T07:50:16Z,['10.48550/arXiv.2201.00404'],"Resting-state fMRI is commonly used for diagnosing Autism Spectrum Disorder (ASD) by using network-based functional connectivity. It has been shown that ASD is associated with brain regions and their inter-connections. However, discriminating based on connectivity patterns among imaging data of the control population and that of ASD patients' brains is a non-trivial task. In order to tackle said classification task, we propose a novel deep learning architecture (MHATC) consisting of multi-head attention and temporal consolidation modules for classifying an individual as a patient of ASD. The devised architecture results from an in-depth analysis of the limitations of current deep neural network solutions for similar applications. Our approach is not only robust but computationally efficient, which can allow its adoption in a variety of other research and clinical settings."
2201.00166,Design of the ELIMAIA ion collection system,"['F. Schillaci', 'G. A. P. Cirrone', 'G. Cuttone', 'M. Maggiore', 'L. Ando', 'A. Amato', 'M. Costa', 'G. Gallo', 'G. Korn', 'G. Larosa', 'R. Leanza', 'R. Manna', 'D. Margarone', 'G. Milluzzo', 'S. Pulvirenti', 'F. Romano', 'S. Salamone', 'M. Sedita', 'V. Scuderia', 'A. Tramontana']",ARXIV,http://arxiv.org/pdf/2201.00166v1,2022-01-01T10:56:42Z,2022-01-01T10:56:42Z,"['10.48550/arXiv.2201.00166', '10.1088/1748-0221/10/12/T12001']","A system of permanent magnet quadrupoles (PMQs) is going to be realized by INFNLNS to be used as a collection system for the injection of laser driven ion beams up to 60 AMeV in an energy selector based on four resistive dipoles. This system is the first element of the ELIMED (ELI-Beamlines MEDical and Multidisciplinary applications) beam transport, dosimetry and irradiation line that will be developed by INFN-LNS (It) and installed at the ELI-Beamlines facility in Prague (Cz). ELIMED will be the first users open transport beam-line where a controlled laser-driven ion beam will be used for multidisciplinary researches. The definition of well specified characteristics, both in terms of performances and field quality, of the magnetic lenses is crucial for the system realization, for the accurate study of the beam dynamics and for the proper matching with the magnetic selection system which will be designed in the next months. Here, we report the design of the collection system and the adopted solutions in order to realize a robust system form the magnetic point of view. Moreover, the first preliminary transport simulations are also described."
2201.00385,Quasiprobability fluctuation theorem behind the spread of quantum information,"['Kun Zhang', 'Jin Wang']",ARXIV,http://arxiv.org/pdf/2201.00385v2,2022-01-02T17:45:50Z,2022-02-15T18:33:45Z,['10.48550/arXiv.2201.00385'],"Information spreads in time evolution. For example, correlations dissipate when the correlated system locally couples to a third party, such as the environment. This simple but important fact is known as the quantum data-processing inequality. Here we theoretically reveal the quantum fluctuation theorem behind the quantum informational inequality. The fluctuation theorem quantitatively predicts the statistics of such process. To fully capture the quantum nature, the fluctuation theorem established here is extended to the quasiprobability regime. We also experimentally apply a interference-based method to measure the amplitudes composing the quasiprobability and verify our established fluctuation theorem on the IBM quantum computers."
2201.00403,Increasing the Efficiency of Photovoltaic Systems by Using Maximum Power Point Tracking (MPPT),"['Alireza Tofigh Rihani', 'Majid Ghandchi']",ARXIV,http://arxiv.org/pdf/2201.00403v1,2021-12-18T09:21:42Z,2021-12-18T09:21:42Z,['10.48550/arXiv.2201.00403'],"Using Photovoltaic systems is gradually expanded by increasing energy demand. Abundance and availability of this energy, has turned to one of the most important sources of renewable energy. Unfortunately, photovoltaic systems have two big problems: first, those have very low energy conversion efficiency (in act between 12 and 42 percent under certain circumstances). Second, the power produced by the solar cell depends on nonlinear conditions such as solar radiation, temperature and charge feature. According to this, received power maximum of photovoltaic cells depends on different non-linear variables, it is necessary to be continuously traced, as maximum received power of the cell (by controller). In this research, the increasing efficiency of photovoltaic systems has been investigated by using Maximum Power Point Tracking (MPPT) in two different modes contained connected to the Grid and disconnected from the grid with simulation by MATLAB software. The obtained results showed that the proposed technique is able to improve the current, voltage and power output of photovoltaic cells."
2201.00138,Joint Vehicle Tracking and RSU Selection for V2I Communications with Extended Kalman Filter,"['Jiho Song', 'Seong-Hwan Hyun', 'Jong-Ho Lee', 'Jeongsik Choi', 'Seong-Cheol Kim']",ARXIV,http://arxiv.org/pdf/2201.00138v2,2022-01-01T07:15:44Z,2022-02-11T02:12:52Z,['10.48550/arXiv.2201.00138'],"We develop joint vehicle tracking and road side unit (RSU) selection algorithms suitable for vehicle-to-infrastructure (V2I) communications. We first design an analytical framework for evaluating vehicle tracking systems based on the extended Kalman filter. A simple, yet effective, metric that quantifies the vehicle tracking performance is derived in terms of the angular derivative of a dominant spatial frequency. Second, an RSU selection algorithm is proposed to select a proper RSU that enhances the vehicle tracking performance. A joint vehicle tracking algorithm is also developed to maximize the tracking performance by considering sounding samples at multiple RSUs while minimizing the amount of sample exchange. The numerical results verify that the proposed vehicle tracking algorithms give better performance than conventional signal-to-noise ratio-based tracking systems."
2201.00380,Hamiltonian Dynamics of a spaceship in Alcubierre and Gödel metrics: Recursion operators and underlying master symmetries,"['Mahouton Norbert Hounkonnou', 'Mahougnon Justin Landalidji', 'Melanija Mitrovíc']",ARXIV,http://arxiv.org/pdf/2201.00380v1,2022-01-02T17:15:44Z,2022-01-02T17:15:44Z,['10.48550/arXiv.2201.00380'],"We study the Hamiltonian dynamics of a spaceship in the background of Alcubierre and G\""odel metrics. We derive the Hamiltonian vector fields governing the system evolution, construct and discuss related recursion operators generating the constants of motion. Besides, we characterize relevant master symmetries."
2201.00440,Resonance-enhanced spectral funneling in Fabry-Perot resonators with a temporal boundary mirror,"['Kanghee Lee', 'Junho Park', 'Seojoo Lee', 'Soojeong Baek', 'Jagang Park', 'Fabian Rotermund', 'Bumki Min']",ARXIV,http://arxiv.org/pdf/2201.00440v1,2022-01-03T00:41:12Z,2022-01-03T00:41:12Z,['10.48550/arXiv.2201.00440'],"A temporal boundary refers to a specific time at which the properties of an optical medium are abruptly changed. When light interacts with the temporal boundary, its spectral content can be redistributed due to the breaking of continuous time-translational symmetry of the medium where light resides. In this work, we use this principle to demonstrate, at terahertz (THz) frequencies, the resonance-enhanced spectral funneling of light coupled to a Fabry-Perot resonator with a temporal boundary mirror. To produce a temporal boundary effect, we abruptly increase the reflectance of a mirror constituting the Fabry-Perot resonator and, correspondingly, its quality factor in a step-like manner. The abrupt increase in the mirror reflectance leads to a trimming of the coupled THz pulse that causes the pulse to broaden in the spectral domain. Through this dynamic resonant process, the spectral contents of the input THz pulse are redistributed into the modal frequencies of the high-Q Fabry-Perot resonator formed after the temporal boundary. An energy conversion efficiency of up to 33% was recorded for funneling into the fundamental mode with a Fabry-Perot resonator exhibiting a sudden Q-factor change from 4.8 to 48. We anticipate that the proposed resonance-enhanced spectral funneling technique could be further utilized in the development of efficient mechanically tunable narrowband terahertz sources for diverse applications."
2201.00139,On the improved conditions for some primal-dual algorithms,"['Yao Li', 'Ming Yan']",ARXIV,http://arxiv.org/pdf/2201.00139v1,2022-01-01T07:34:56Z,2022-01-01T07:34:56Z,['10.48550/arXiv.2201.00139'],"The convex minimization of $f(\mathbf{x})+g(\mathbf{x})+h(\mathbf{A}\mathbf{x})$ over $\mathbb{R}^n$ with differentiable $f$ and linear operator $\mathbf{A}: \mathbb{R}^n\rightarrow \mathbb{R}^m$, has been well-studied in the literature. By considering the primal-dual optimality of the problem, many algorithms are proposed from different perspectives such as monotone operator scheme and fixed point theory. In this paper, we start with a base algorithm to reveal the connection between several algorithms such as AFBA, PD3O and Chambolle-Pock. Then, we prove its convergence under a relaxed assumption associated with the linear operator and characterize the general constraint on primal and dual stepsizes. The result improves the upper bound of stepsizes of AFBA and indicates that Chambolle-Pock, as the special case of the base algorithm when $f=0$, can take the stepsize of the dual iteration up to $4/3$ of the previously proven one."
2201.00408,Optimal Vertex Connectivity Oracles,"['Seth Pettie', 'Thatchaphol Saranurak', 'Longhui Yin']",ARXIV,http://arxiv.org/pdf/2201.00408v1,2022-01-02T19:55:57Z,2022-01-02T19:55:57Z,['10.48550/arXiv.2201.00408'],"A $k$-vertex connectivity oracle for undirected $G$ is a data structure that, given $u,v\in V(G)$, reports $\min\{k,\kappa(u,v)\}$, where $\kappa(u,v)$ is the pairwise vertex connectivity between $u,v$. There are three main measures of efficiency: construction time, query time, and space. Prior work of Izsak and Nutov shows that a data structure of total size $\tilde{O}(kn)$ can even be encoded as a $\tilde{O}(k)$-bit labeling scheme so that vertex-connectivity queries can be answered in $\tilde{O}(k)$ time. The construction time is polynomial, but unspecified. In this paper we address the top three complexity measures: Space, Query Time, and Construction Time. We give an $\Omega(kn)$-bit lower bound on any vertex connectivity oracle. We construct an optimal-space connectivity oracle in max-flow time that answers queries in $O(\log n)$ time, independent of $k$."
2201.00267,On the Cross-dataset Generalization in License Plate Recognition,"['Rayson Laroca', 'Everton V. Cardoso', 'Diego R. Lucio', 'Valter Estevam', 'David Menotti']",ARXIV,http://arxiv.org/pdf/2201.00267v4,2022-01-02T00:56:09Z,2022-12-21T17:49:08Z,"['10.48550/arXiv.2201.00267', '10.5220/0010846800003124']","Automatic License Plate Recognition (ALPR) systems have shown remarkable performance on license plates (LPs) from multiple regions due to advances in deep learning and the increasing availability of datasets. The evaluation of deep ALPR systems is usually done within each dataset; therefore, it is questionable if such results are a reliable indicator of generalization ability. In this paper, we propose a traditional-split versus leave-one-dataset-out experimental setup to empirically assess the cross-dataset generalization of 12 Optical Character Recognition (OCR) models applied to LP recognition on nine publicly available datasets with a great variety in several aspects (e.g., acquisition settings, image resolution, and LP layouts). We also introduce a public dataset for end-to-end ALPR that is the first to contain images of vehicles with Mercosur LPs and the one with the highest number of motorcycle images. The experimental results shed light on the limitations of the traditional-split protocol for evaluating approaches in the ALPR context, as there are significant drops in performance for most datasets when training and testing the models in a leave-one-dataset-out fashion."
2201.00441,Crack patterns of drying dense bacterial suspensions,"['Xiaolei Ma', 'Zhengyang Liu', 'Wei Zeng', 'Tianyi Lin', 'Xin Tian', 'Xiang Cheng']",ARXIV,http://arxiv.org/pdf/2201.00441v2,2022-01-03T00:49:59Z,2022-06-19T19:49:51Z,"['10.48550/arXiv.2201.00441', '10.1039/D2SM00012A']","Drying of bacterial suspensions is frequently encountered in a plethora of natural and engineering processes. However, the evaporation-driven mechanical instabilities of dense consolidating bacterial suspensions have not been explored heretofore. Here, we report the formation of two different crack patterns of drying suspensions of \textit{Escherichia coli} (\textit{E. coli}) with distinct motile behaviors. Circular cracks are observed for wild-type \textit{E. coli} with active swimming, whereas spiral-like cracks form for immotile bacteria. Using the elastic fracture mechanics and the poroelastic theory, we show that the formation of the circular cracks is determined by the tensile nature of the radial drying stress once the cracks are initiated by the local order structure of bacteria due to their collective swimming. Our study demonstrates the link between the microscopic swimming behaviors of individual bacteria and the mechanical instabilities and macroscopic pattern formation of drying bacterial films. The results shed light on the dynamics of active matter in a drying process and provide useful information for understanding various biological processes associated with drying bacterial suspensions."
2201.00195,Challenges of sampling and how phylogenetic comparative methods help: With a case study of the Pama-Nyungan laminal contrast,"['Jayden L. Macklin-Cordes', 'Erich R. Round']",ARXIV,http://arxiv.org/pdf/2201.00195v1,2022-01-01T14:33:20Z,2022-01-01T14:33:20Z,['10.48550/arXiv.2201.00195'],"Phylogenetic comparative methods are new in our field and are shrouded, for most linguists, in at least a little mystery. Yet the path that led to their discovery in comparative biology is so similar to the methodological history of balanced sampling, that it is only an accident of history that they were not discovered by a typologist. Here we clarify the essential logic behind phylogenetic comparative methods and their fundamental relatedness to a deep intellectual tradition focussed on sampling. Then we introduce concepts, methods and tools which will enable typologists to use these methods in everyday typological research. The key commonality of phylogenetic comparative methods and balanced sampling is that they attempt to deal with statistical non-independence due to genealogy. Whereas sampling can never achieve independence and requires most comparative data to be discarded, phylogenetic comparative methods achieve independence while retaining and using all data. We discuss the essential notions of phylogenetic signal; uncertainty about trees; typological averages and proportions that are sensitive to genealogy; comparison across language families; and the effects of areality. Extensive supplementary materials illustrate computational tools for practical analysis and we illustrate the methods discussed with a typological case study of the laminal contrast in Pama-Nyungan."
2201.00446,Gradient Free Cooperative Seeking of a Moving Source,"['Elad Michael', 'Chris Manzie', 'Tony A. Wood', 'Daniel Zelazo', 'Iman Shames']",ARXIV,http://arxiv.org/pdf/2201.00446v2,2022-01-03T01:14:22Z,2022-06-30T06:30:56Z,['10.48550/arXiv.2201.00446'],"In this paper, we consider the optimisation of a time varying scalar field by a network of agents with no gradient information. We propose a composite control law, blending extremum seeking with formation control in order to converge to the extrema faster by minimising the gradient estimation error. By formalising the relationship between the formation and the gradient estimation error, we provide a novel analysis to prove the convergence of the network to a bounded neighbourhood of the field's time varying extrema. We assume the time-varying field satisfies the Polyak Lojasiewicz inequality and the gradient is Lipschitz continuous at each iteration. Numerical studies and comparisons are provided to support the theoretical results."
2201.00356,A deep learning approach to predict significant wave height using long short-term memory,"['Felipe C. Minuzzi', 'Leandro Farina']",ARXIV,http://arxiv.org/pdf/2201.00356v1,2022-01-02T13:21:43Z,2022-01-02T13:21:43Z,"['10.48550/arXiv.2201.00356', '10.1016/j.ocemod.2022.102151']","We present a framework for forecasting significant wave height on the Southwestern Atlantic Ocean using the long short-term memory algorithm (LSTM), trained with the ERA5 database available through Copernicus Climate Data Store (CDS) implemented by ECMWF (European Center for Medium Range Forecast) and also with buoy data. The predictions are made for seven different locations in the Brazilian coast, where buoy data are available, ranging from shallow to deep water. Experiments are conducted using exclusively historical series at the selected locations and the influence of other variables as inputs for training is investigated. The results shows that a data-driven methodology can be used as a surrogate to the computational expensive physical models, with the best accuracy near $95\%$, compared to reanalysis"
2201.00442,Singular Lie filtrations and weightings,"['Yiannis Loizides', 'Eckhard Meinrenken']",ARXIV,http://arxiv.org/pdf/2201.00442v1,2022-01-03T00:50:17Z,2022-01-03T00:50:17Z,['10.48550/arXiv.2201.00442'],"We study weightings (a.k.a. quasi-homogeneous structures) arising from manifolds with singular Lie filtrations. This generalizes constructions of Choi-Ponge, Van Erp-Yuncken, and Haj-Higson for (regular) Lie filtrations."
2201.00409,Global convergence of optimized adaptive importance samplers,['Ömer Deniz Akyildiz'],ARXIV,http://arxiv.org/pdf/2201.00409v1,2022-01-02T19:56:36Z,2022-01-02T19:56:36Z,['10.48550/arXiv.2201.00409'],"We analyze the optimized adaptive importance sampler (OAIS) for performing Monte Carlo integration with general proposals. We leverage a classical result which shows that the bias and the mean-squared error (MSE) of the importance sampling scales with the $\chi^2$-divergence between the target and the proposal and develop a scheme which performs global optimization of $\chi^2$-divergence. While it is known that this quantity is convex for exponential family proposals, the case of the general proposals has been an open problem. We close this gap by utilizing stochastic gradient Langevin dynamics (SGLD) and its underdamped counterpart for the global optimization of $\chi^2$-divergence and derive nonasymptotic bounds for the MSE by leveraging recent results from non-convex optimization literature. The resulting AIS schemes have explicit theoretical guarantees uniform in the number of iterations."
2201.00104,On product sets of arithmetic progressions,"['Max Wenqiang Xu', 'Yunkun Zhou']",ARXIV,http://arxiv.org/pdf/2201.00104v4,2022-01-01T03:26:00Z,2023-07-25T14:57:33Z,['10.48550/arXiv.2201.00104'],"We prove that the size of the product set of any finite arithmetic progression $\mathcal{A}\subset \mathbb{Z}$ satisfies \[|\mathcal A \cdot \mathcal A| \ge \frac{|\mathcal A|^2}{(\log |\mathcal A|)^{2\theta +o(1)} } ,\] where $2\theta=1-(1+\log\log 2)/(\log 2)$ is the constant appearing in the celebrated Erd\H{o}s multiplication table problem. This confirms a conjecture of Elekes and Ruzsa from about two decades ago. If instead $\mathcal{A}$ is relaxed to be a subset of a finite arithmetic progression in integers with positive constant density, we prove that \[|\mathcal A \cdot \mathcal A | \ge \frac{|\mathcal A|^{2}}{(\log |\mathcal A|)^{2\log 2- 1 + o(1)}}. \] This solves the typical case of another conjecture of Elekes and Ruzsa on the size of the product set of a set $\mathcal{A}$ whose sumset is of size $O(|\mathcal{A}|)$. Our bounds are sharp up to the $o(1)$ term in the exponents. We further prove asymmetric extensions of the above results."
2201.00342,"High Precision Computation of Riemann's Zeta Function by the Riemann-Siegel Formula, II",['Juan Arias de Reyna'],ARXIV,http://arxiv.org/pdf/2201.00342v1,2022-01-02T11:44:08Z,2022-01-02T11:44:08Z,['10.48550/arXiv.2201.00342'],"(This is only a first preliminary version, any suggestions about it will be welcome.) In this paper it is shown how to compute Riemann's zeta function $\zeta(s)$ (and Riemann-Siegel $Z(t)$) at any point $s\in\mathbf C$ with a prescribed error $\varepsilon$ applying the, Riemann-Siegel formula as described in my paper ""High Precision ... I"", Math of Comp. 80 (2011) 995--1009. This includes the study of how many terms to compute and to what precision to get the desired result. All possible errors are considered, even those inherent to the use of floating point representation of the numbers. The result has been used to implement the computation. The programs have been included in""mpmath"", a public library in Python for the computation of special functions. Hence they are included also in Sage."
2201.00362,Verification of some functional inequalities via polynomial optimization,['Giovanni Fantuzzi'],ARXIV,http://arxiv.org/pdf/2201.00362v1,2022-01-02T14:29:12Z,2022-01-02T14:29:12Z,['10.48550/arXiv.2201.00362'],"Motivated by the application of Lyapunov methods to partial differential equations (PDEs), we study functional inequalities of the form $f(I_1(u),\ldots,I_k(u))\geq 0$ where $f$ is a polynomial, $u$ is any function satisfying prescribed constraints, and $I_1(u),\ldots,I_k(u)$ are integral functionals whose integrands are polynomial in $u$, its derivatives, and the integration variable. We show that such functional inequalities can be strengthened into sufficient polynomial inequalities, which in principle can be checked via semidefinite programming using standard techniques for polynomial optimization. These sufficient conditions can be used also to optimize functionals with affine dependence on tunable parameters whilst ensuring their nonnegativity. Our approach relies on a measure-theoretic lifting of the original functional inequality, which extends both a recent moment relaxation strategy for PDE analysis and a dual approach to inequalities for integral functionals."
2201.00293,Algorithm-Level Confidentiality for Average Consensus on Time-Varying Directed Graphs,"['Huan Gao', 'Yongqiang Wang']",ARXIV,http://arxiv.org/pdf/2201.00293v2,2022-01-02T05:07:08Z,2022-01-05T06:53:13Z,['10.48550/arXiv.2201.00293'],"Average consensus plays a key role in distributed networks, with applications ranging from time synchronization, information fusion, load balancing, to decentralized control. Existing average consensus algorithms require individual agents to exchange explicit state values with their neighbors, which leads to the undesirable disclosure of sensitive information in the state. In this paper, we propose a novel average consensus algorithm for time-varying directed graphs that can protect the confidentiality of a participating agent against other participating agents. The algorithm injects randomness in interaction to obfuscate information on the algorithm-level and can ensure information-theoretic privacy without the assistance of any trusted third party or data aggregator. By leveraging the inherent robustness of consensus dynamics against random variations in interaction, our proposed algorithm can also guarantee the accuracy of average consensus. The algorithm is distinctly different from differential-privacy based average consensus approaches which enable confidentiality through compromising accuracy in obtained consensus value. Numerical simulations confirm the effectiveness and efficiency of our proposed approach."
2201.00215,On the Parity of the Generalized Frobenius Partition Functions $φ_k(n)$,"['George E. Andrews', 'James A. Sellers', 'Fares Soufan']",ARXIV,http://arxiv.org/pdf/2201.00215v1,2022-01-01T16:23:02Z,2022-01-01T16:23:02Z,['10.48550/arXiv.2201.00215'],"In his 1984 Memoir of the American Mathematical Society, George Andrews defined two families of functions, $\phi_k(n)$ and $c\phi_k(n),$ which enumerate two types of combinatorial objects which Andrews called generalized Frobenius partitions. As part of that Memoir, Andrews proved a number of Ramanujan--like congruences satisfied by specific functions within these two families. In the years that followed, numerous other authors proved similar results for these functions, often with a view towards a specific choice of the parameter $k.$ In this brief note, our goal is to identify an {\bf infinite} family of values of $k$ such that $\phi_k(n)$ is even for all $n$ in a specific arithmetic progression; in particular, our primary goal in this work is to prove that, for all positive integers $\ell,$ all primes $p\geq 5,$ and all values $r,$ $0 < r < p,$ such that $24r+1$ is a quadratic nonresidue modulo $p,$ $$ \phi_{p\ell-1}(pn+r) \equiv 0 \pmod{2} $$ for all $n\geq 0.$ Our proof of this result is truly elementary, relying on a lemma from Andrews' Memoir, classical $q$--series results, and elementary generating function manipulations. Such a result, which holds for infinitely many values of $k,$ is rare in the study of arithmetic properties satisfied by generalized Frobenius partitions, primarily because of the unwieldy nature of the generating functions in question."
2201.00326,Weighted one-level density of low-lying zeros of Dirichlet $L$-functions,"['Shingo Sugiyama', 'Ade Irma Suriajaya']",ARXIV,http://arxiv.org/pdf/2201.00326v2,2022-01-02T09:25:29Z,2022-07-24T14:01:06Z,"['10.48550/arXiv.2201.00326', '10.1007/s40993-022-00359-0']","In this paper, we compute the one-level density of low-lying zeros of Dirichlet $L$-functions in a family weighted by special values of Dirichlet $L$-functions at a fixed $s \in [1/2, 1)$. We verify both Fazzari's conjecture and the first author's conjecture on the weighted one-level density for our family of $L$-functions."
2201.00148,Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness,"['Hao Yang', 'Min Wang', 'Zhengfei Yu', 'Yun Zhou']",ARXIV,http://arxiv.org/pdf/2201.00148v1,2022-01-01T08:46:06Z,2022-01-01T08:46:06Z,['10.48550/arXiv.2201.00148'],"It is well-known that deep neural networks (DNNs) have shown remarkable success in many fields. However, when adding an imperceptible magnitude perturbation on the model input, the model performance might get rapid decrease. To address this issue, a randomness technique has been proposed recently, named Stochastic Neural Networks (SNNs). Specifically, SNNs inject randomness into the model to defend against unseen attacks and improve the adversarial robustness. However, existed studies on SNNs mainly focus on injecting fixed or learnable noises to model weights/activations. In this paper, we find that the existed SNNs performances are largely bottlenecked by the feature representation ability. Surprisingly, simply maximizing the variance per dimension of the feature distribution leads to a considerable boost beyond all previous methods, which we named maximize feature distribution variance stochastic neural network (MFDV-SNN). Extensive experiments on well-known white- and black-box attacks show that MFDV-SNN achieves a significant improvement over existing methods, which indicates that it is a simple but effective method to improve model robustness."
2201.00271,Transposed BiHom-Poisson algebras,"['Tianshui Ma', 'Bei Li']",ARXIV,http://arxiv.org/pdf/2201.00271v1,2022-01-02T02:05:31Z,2022-01-02T02:05:31Z,['10.48550/arXiv.2201.00271'],"In this paper, we introduce the concept of transposed BiHom-Poisson (abbr. TBP) algebras which can be constructed by the BiHom-Novikov-Poisson algebras. Several useful identities for TBP algebras are provided. We also prove that the tensor product of two (T)BP algebras are closed. The notions of BP 3-Lie algebras and TBP 3-Lie algebras are presented and TBP algebras can induce TBP 3-Lie algebras by two approaches. Finally, we give some examples for the TBP algebras of dimension 2."
2201.00268,Double algebraic genericity of universal harmonic functions on trees,['C. A. Konidas'],ARXIV,http://arxiv.org/pdf/2201.00268v1,2022-01-02T01:01:57Z,2022-01-02T01:01:57Z,['10.48550/arXiv.2201.00268'],It is well known that the set of universal functions on a tree contains a vector space except zero which is dense in the set of harmonic functions. In this paper we improve this result by proving that the set of universal functions on a tree contains two vector spaces except zero which are dense in the space of harmonic functions and intersect only at zero.
2201.00352,"Almost complex torus manifolds -- graphs, Hirzebruch genera, and problem of Petrie type",['Donghoon Jang'],ARXIV,http://arxiv.org/pdf/2201.00352v3,2022-01-02T12:54:10Z,2022-02-22T17:52:48Z,['10.48550/arXiv.2201.00352'],"Let a $k$-dimensional torus $T^k$ act on a $2n$-dimensional compact connected almost complex manifold $M$ with isolated fixed points. As for circle actions, we show that there exists a (directed labeled) multigraph that encodes weights at the fixed points of $M$. This includes the notion of a GKM graph as a special case that weights at each fixed point are pairwise linearly independent. If in addition $k=n$, i.e., $M$ is an almost complex torus manifold, the multigraph is a graph; it has no multiple edges. We show that the Hirzebruch $\chi_y$-genus $\chi_y(M)=\sum_{i=0}^n a_i(M) \cdot (-y)^i$ of an almost complex torus manifold $M$ satisfies $a_i(M) > 0$ for $0 \leq i \leq n$. In particular, the Todd genus of $M$ is positive and there are at least $n+1$ fixed points. Petrie's conjecture asserts that if a homotopy $\mathbb{CP}^n$ admits a non-trivial circle action, its Pontryagin class agrees with that of $\mathbb{CP}^n$. Petrie proved this conjecture if instead it admits a $T^n$-action. We prove that if a $2n$-dimensional almost complex torus manifold $M$ only shares the Euler number with the complex projective space $\mathbb{CP}^n$, an associated graph agrees with that of a linear $T^n$-action on $\mathbb{CP}^n$; consequently $M$ has the same weights at the fixed points, Chern numbers, equivariant cobordism class, Hirzebruch $\chi_y$-genus, Todd genus, and signature as $\mathbb{CP}^n$. If furthermore $M$ is equivariantly formal, the equivariant cohomology and the Chern classes of $M$ and $\mathbb{CP}^n$ also agree."
2201.00299,Improving Out-of-Distribution Robustness via Selective Augmentation,"['Huaxiu Yao', 'Yu Wang', 'Sai Li', 'Linjun Zhang', 'Weixin Liang', 'James Zou', 'Chelsea Finn']",ARXIV,http://arxiv.org/pdf/2201.00299v3,2022-01-02T05:58:33Z,2022-06-19T04:13:34Z,['10.48550/arXiv.2201.00299'],"Machine learning algorithms typically assume that training and test examples are drawn from the same distribution. However, distribution shift is a common problem in real-world applications and can cause models to perform dramatically worse at test time. In this paper, we specifically consider the problems of subpopulation shifts (e.g., imbalanced data) and domain shifts. While prior works often seek to explicitly regularize internal representations or predictors of the model to be domain invariant, we instead aim to learn invariant predictors without restricting the model's internal representations or predictors. This leads to a simple mixup-based technique which learns invariant predictors via selective augmentation called LISA. LISA selectively interpolates samples either with the same labels but different domains or with the same domain but different labels. Empirically, we study the effectiveness of LISA on nine benchmarks ranging from subpopulation shifts to domain shifts, and we find that LISA consistently outperforms other state-of-the-art methods and leads to more invariant predictors. We further analyze a linear setting and theoretically show how LISA leads to a smaller worst-group error."
2201.00135,Geometric Complexity Theory -- Lie Algebraic Methods for Projective Limits of Stable Points,"['Bharat Adsul', 'Milind Sohoni', 'K V Subrahmanyam']",ARXIV,http://arxiv.org/pdf/2201.00135v1,2022-01-01T07:06:48Z,2022-01-01T07:06:48Z,['10.48550/arXiv.2201.00135'],"Let $G$ be a connected reductive group acting on a complex vector space $V$ and projective space ${\mathbb P}V$. Let $x\in V$ and ${\cal H}\subseteq {\cal G}$ be the Lie algebra of its stabilizer. Our objective is to understand points $[y]$, and their stabilizers which occur in the vicinity of $[x]$. We construct an explicit ${\cal G}$-action on a suitable neighbourhood of $x$, which we call the local model at $x$. We show that Lie algebras of stabilizers of points in the vicinity of $x$ are parameterized by subspaces of ${\cal H}$. When ${\cal H}$ is reductive these are Lie subalgebras of ${\cal H}$. If the orbit of $x$ is closed this also follows from Luna's theorem. Our construction involves a map connected to the local curvature form at $x$. We apply the local model to forms, when the form $g$ is obtained from the form $f$ as the leading term of a one parameter family acting on $f$. We show that there is a flattening ${\cal K}_0$ of ${\cal K}$, the stabilizer of $f$ which sits as a subalgebra of ${\cal H}$, the stabilizer $g$. We specialize to the case of forms $f$ whose $SL(X)$-orbits are affine, and the orbit of $g$ is of co-dimension $1$. We show that (i) either ${\cal H}$ has a very simple structure, or (ii) conjugates of the elements of ${\cal K}$ also stabilize $g$ and the tangent of exit. Next, we apply this to the adjoint action. We show that for a general matrix $X$, the signatures of nilpotent matrices in its projective orbit closure (under conjugation) are determined by the multiplicity data of the spectrum of $X$. Finally, we formulate the path problem of finding paths with specific properties from $y$ to its limit points $x$ as an optimization problem using local differential geometry. Our study is motivated by Geometric Complexity Theory proposed by the second author and Ketan Mulmuley."
2201.00387,On the convex hull of convex quadratic optimization problems with indicators,"['Linchuan Wei', 'Alper Atamtürk', 'Andrés Gómez', 'Simge Küçükyavuz']",ARXIV,http://arxiv.org/pdf/2201.00387v2,2022-01-02T18:04:52Z,2022-11-27T19:41:09Z,['10.48550/arXiv.2201.00387'],"We consider the convex quadratic optimization problem with indicator variables and arbitrary constraints on the indicators. We show that a convex hull description of the associated mixed-integer set in an extended space with a quadratic number of additional variables consists of a single positive semidefinite constraint (explicitly stated) and linear constraints. In particular, convexification of this class of problems reduces to describing a polyhedral set in an extended formulation. While the vertex representation of this polyhedral set is exponential and an explicit linear inequality description may not be readily available in general, we derive a compact mixed-integer linear formulation whose solutions coincide with the vertices of the polyhedral set. We also give descriptions in the original space of variables: we provide a description based on an infinite number of conic-quadratic inequalities, which are ""finitely generated."" In particular, it is possible to characterize whether a given inequality is necessary to describe the convex hull. The new theory presented here unifies several previously established results, and paves the way toward utilizing polyhedral methods to analyze the convex hull of mixed-integer nonlinear sets."
2201.00199,The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling,"['Radostin Cholakov', 'Todor Kolev']",ARXIV,http://arxiv.org/pdf/2201.00199v1,2022-01-01T14:52:04Z,2022-01-01T14:52:04Z,['10.48550/arXiv.2201.00199'],"There is an increasing interest in the application of deep learning architectures to tabular data. One of the state-of-the-art solutions is TabTransformer which incorporates an attention mechanism to better track relationships between categorical features and then makes use of a standard MLP to output its final logits. In this paper we propose multiple modifications to the original TabTransformer performing better on binary classification tasks for three separate datasets with more than 1% AUROC gains. Inspired by gated MLP, linear projections are implemented in the MLP block and multiple activation functions are tested. We also evaluate the importance of specific hyper parameters during training."
2201.00257,Wigner type laws for structured random matrices,['Tapesh Yadav'],ARXIV,http://arxiv.org/pdf/2201.00257v1,2022-01-01T23:20:46Z,2022-01-01T23:20:46Z,['10.48550/arXiv.2201.00257'],"For a sufficiently nice 2 dimensional shape, we define its approximating matrix (or patterned matrix) as a random matrix with iid entries arranged according to a given pattern. For large approximating matrices, we observe that the eigenvalues roughly follow an underlying distribution. This phenomenon is similar to the classical observation on Wigner matrices. We prove that the moments of such matrices converge asymptotically as the size increases and equals to the integral of a combinatorially-defined function which counts certain paths on a finite grid. We also consider the case of several independent patterned matrices. Under a specific set of conditions, these matrices admit asymptotic freeness with respect to full-filled independent square random matrices. In our conclusion, we present several open problems."
2201.00255,"The solutions to single-variable polynomials, implemented and verified in Lean","['Nicholas Dyson', 'Benedikt Ahrens', 'Jacopo Emmenegger']",ARXIV,http://arxiv.org/pdf/2201.00255v1,2022-01-01T23:04:35Z,2022-01-01T23:04:35Z,['10.48550/arXiv.2201.00255'],"In this work, we describe our experience in learning the use of a computer proof assistant - specifically, Lean - from scratch, through proving formulae for the solutions of polynomial equations. Specifically, in this work we characterize the solutions of quadratic, cubic, and quartic polynomials over certain fields, specifically, fields with operations returning square and cubic roots of characteristic other than two or three. The purpose of this work is thus twofold. Firstly, it describes the learning experience of a starting Lean user, including a detailed comparison between our work in Lean and very closely related work in Coq. Secondly, our results represent a modest improvement over the aforementioned related work in Coq, which we hope will be of some scientific interest."
2201.00277,Service-Based Drone Delivery,"['Balsam Alkouz', 'Babar Shahzaad', 'Athman Bouguettaya']",ARXIV,http://arxiv.org/pdf/2201.00277v1,2022-01-02T02:34:10Z,2022-01-02T02:34:10Z,['10.48550/arXiv.2201.00277'],"Service delivery is set to experience a major paradigm shift with fast advances in drone technologies coupled with higher expectations from customers and increased competition. We propose a novel service-oriented approach to enable the ubiquitous delivery of packages in a drone-operated skyway network. We discuss the benefits, framework and architecture, contemporary approaches, open challenges and future visioned directions of service-based drone deliveries."
2201.00241,Batched Second-Order Adjoint Sensitivity for Reduced Space Methods,"['François Pacaud', 'Michel Schanen', 'Daniel Adrian Maldonado', 'Alexis Montoison', 'Valentin Churavy', 'Julian Samaroo', 'Mihai Anitescu']",ARXIV,http://arxiv.org/pdf/2201.00241v1,2022-01-01T20:53:09Z,2022-01-01T20:53:09Z,"['10.48550/arXiv.2201.00241', '10.1137/1.9781611977141.6']","This paper presents an efficient method for extracting the second-order sensitivities from a system of implicit nonlinear equations on upcoming graphical processing units (GPU) dominated computer systems. We design a custom automatic differentiation (AutoDiff) backend that targets highly parallel architectures by extracting the second-order information in batch. When the nonlinear equations are associated to a reduced space optimization problem, we leverage the parallel reverse-mode accumulation in a batched adjoint-adjoint algorithm to compute efficiently the reduced Hessian of the problem. We apply the method to extract the reduced Hessian associated to the balance equations of a power network, and show on the largest instances that a parallel GPU implementation is 30 times faster than a sequential CPU reference based on UMFPACK."
2201.00432,A Linear Algorithm for Computing Independence Polynomials of Trees,"['Ohr Kadrawi', 'Vadim E. Levit', 'Ron Yosef', 'Matan Mizrachi']",ARXIV,http://arxiv.org/pdf/2201.00432v1,2022-01-02T23:36:26Z,2022-01-02T23:36:26Z,['10.48550/arXiv.2201.00432'],"An independent set in a graph is a set of pairwise non-adjacent vertices. Let $\alpha(G)$ denote the cardinality of a maximum independent set in the graph $G = (V, E)$. Gutman and Harary defined the independence polynomial of $G$ \[ I(G;x) = \sum_{k=0}^{\alpha(G)}{s_k}x^{k}={s_0}+{s_1}x+{s_2}x^{2}+...+{s_{\alpha(G)}}x^{\alpha(G)}, \] where $s_k$ denotes the number of independent sets of cardinality $k$ in the graph $G$. A comprehensive survey on the subject is due to Levit and Mandrescu, where some recursive formulas are allowing to calculate the independence polynomial. A direct implementation of these recursions does not bring about an efficient algorithm. Yosef, Mizrachi, and Kadrawi developed an efficient way for computing the independence polynomials of trees with $n$ vertices, such that a database containing all of the independence polynomials of all the trees with up to $n-1$ vertices is required. This approach is not suitable for big trees, as an extensive database is needed. On the other hand, using dynamic programming, it is possible to develop an efficient algorithm that prevents repeated calculations. In summary, our dynamic programming algorithm runs over a tree in linear time and does not depend on a database."
2201.00244,Design of a rapid transit to Mars mission using laser-thermal propulsion,"['Emmanuel Duplay', 'Zhuo Fan Bao', 'Sebastian Rodriguez Rosero', 'Arnab Sinha', 'Andrew Higgins']",ARXIV,http://arxiv.org/pdf/2201.00244v1,2022-01-01T22:34:00Z,2022-01-01T22:34:00Z,"['10.48550/arXiv.2201.00244', '10.1016/j.actaastro.2021.11.032']","The application of directed energy to spacecraft mission design is explored using rapid transit to Mars as the design objective. An Earth-based laser array of unprecedented size (10~m diameter) and power (100~MW) is assumed to be enabled by ongoing developments in photonic laser technology. A phased-array laser of this size and incorporating atmospheric compensation would be able to deliver laser power to spacecraft in cislunar space, where the incident laser is focused into a hydrogen heating chamber via an inflatable reflector. The hydrogen propellant is then exhausted through a nozzle to realize specific impulses of 3000 s. The architecture is shown to be immediately reusable via a burn-back maneuver to return the propulsion unit while still within range of the Earth-based laser. The ability to tolerate much greater laser fluxes enables realizing the combination of high thrust and high specific impulse, making this approach favorable in comparison to laser-electric propulsion and occupying a parameter space similar to gas-core nuclear thermal rockets (without the requisite reactor). The heating chamber and its associated regenerative cooling and propellant handling systems are crucial elements of the design that receive special attention in this study. The astrodynamics and the extreme aerocapture maneuver required at Mars arrival after a 45-day transit are also analyzed in detail. The application of laser-thermal propulsion as an enabling technology for other rapid transit missions in the solar system and beyond is discussed."
2201.00218,On the Carbon Dioxide Capture by Quaternary Ammonium-Based and Phosphonium-Based Ionic Liquids. The Role of Steric Hindrances and Transition States,['Vitaly V. Chaban'],ARXIV,http://arxiv.org/pdf/2201.00218v1,2022-01-01T17:10:32Z,2022-01-01T17:10:32Z,['10.48550/arXiv.2201.00218'],Global warming is seen as a drastic environmental problem nowadays. Carbon dioxide (CO 2 ) concentration in the Earth's atmosphere is linked to the average temperature on the surface of the planet. Carbon capture and storage is an important technological endeavor aiming to improve the ecology. The present work investigates reaction paths that are responsible for CO 2 chemisorption by the ammonium- and phosphonium-based ionic liquids containing an aprotic heterocyclic anion 2-cyanopyrrolidine. We show that two moles of CO 2 per one mole of the gas scavenger can be theoretically fixed by such ionic liquids. Both the cation and anion participate in the chemisorption. The corresponding standard enthalpies are moderately negative. The barriers of all reactions involving the phosphonium-based cation are relatively small and favor practical applications of the considered sorbents. The performance of the ammonium-based cation is less favorable due to the inherent instability of the tetraalkylammonium ylide. The role is phosphonium ylide in the mechanism of the reaction is carefully characterized. The reported results foster a fundamental understanding of the outstanding CO 2 sorption performance of the quaternary ammonium and phosphonium-based 2-cyanopyrrolidines.
2201.00345,Robust Algorithmic Collusion,"['Nicolas Eschenbaum', 'Filip Mellgren', 'Philipp Zahn']",ARXIV,http://arxiv.org/pdf/2201.00345v2,2022-01-02T12:10:26Z,2022-01-05T09:47:28Z,['10.48550/arXiv.2201.00345'],"This paper develops a formal framework to assess policies of learning algorithms in economic games. We investigate whether reinforcement-learning agents with collusive pricing policies can successfully extrapolate collusive behavior from training to the market. We find that in testing environments collusion consistently breaks down. Instead, we observe static Nash play. We then show that restricting algorithms' strategy space can make algorithmic collusion robust, because it limits overfitting to rival strategies. Our findings suggest that policy-makers should focus on firm behavior aimed at coordinating algorithm design in order to make collusive policies robust."
2201.00249,The Channel Capacity of General Complex-Valued Load Modulation for Backscatter Communication,"['Gregor Dumphart', 'Johannes Sager', 'Armin Wittneben']",ARXIV,http://arxiv.org/pdf/2201.00249v2,2022-01-01T22:48:42Z,2022-01-14T16:13:37Z,"['10.48550/arXiv.2201.00249', '10.1109/WCNC51071.2022.9771646']","This paper studies achievable information rates of backscatter communication systems where the tag performs load modulation with a freely adaptable passive termination. We find that the complex phasor of the tag current is constrained to a disk and that the capacity problem can therefore be described with existing results on peak-power-limited quadrature channels. This allows us to state the channel capacity and the capacity-achieving distribution of the load impedance, which is described by non-concentric circles in the right half-plane. For the low-SNR case (SNR < 4.8 dB) we find that channel capacity is achieved by a purely reactive load with Cauchy-distributed reactance. The exposition is based on a system model that abstracts all relevant classes of backscatter communication systems, including RFID. To address practicality, we construct a symbol alphabet that allows for a near-capacity information rate of more than 6 bit per load-switching period at reasonably high SNR. We also find that the rate hardly decreases when typical value-range constraints are imposed on the load impedance."
2201.00348,Fundamental trade-off between the speed of light and the Fano factor of photon current in three-level lambda systems,"['Davinder Singh', 'Seogjoo J. Jang', 'Changbong Hyeon']",ARXIV,http://arxiv.org/pdf/2201.00348v6,2022-01-02T12:37:22Z,2023-01-18T00:41:32Z,"['10.48550/arXiv.2201.00348', '10.1088/1751-8121/acb029']","Electromagnetically induced slow-light medium is a promising system for quantum memory devices, but controlling its noise level remains a major challenge to overcome. This work considers the simplest model for such medium, comprised of three-level $\Lambda$-systems interacting with bosonic bath, and provides a new fundamental trade-off relation in light-matter interaction between the group velocity of light and the Fano factor of photon current due to radiative transitions. Considering the steady state limits of a newly derived Lindblad-type equation, we find that the Fano factor of the photon current maximizes to 3 at the minimal group velocity of light, which holds true universally regardless of detailed values of parameters characterizing the medium."
2201.00272,Thinking inside the box: A tutorial on grey-box Bayesian optimization,"['Raul Astudillo', 'Peter I. Frazier']",ARXIV,http://arxiv.org/pdf/2201.00272v1,2022-01-02T02:16:09Z,2022-01-02T02:16:09Z,['10.48550/arXiv.2201.00272'],"Bayesian optimization (BO) is a framework for global optimization of expensive-to-evaluate objective functions. Classical BO methods assume that the objective function is a black box. However, internal information about objective function computation is often available. For example, when optimizing a manufacturing line's throughput with simulation, we observe the number of parts waiting at each workstation, in addition to the overall throughput. Recent BO methods leverage such internal information to dramatically improve performance. We call these ""grey-box"" BO methods because they treat objective computation as partially observable and even modifiable, blending the black-box approach with so-called ""white-box"" first-principles knowledge of objective function computation. This tutorial describes these methods, focusing on BO of composite objective functions, where one can observe and selectively evaluate individual constituents that feed into the overall objective; and multi-fidelity BO, where one can evaluate cheaper approximations of the objective function by varying parameters of the evaluation oracle."
2201.00256,Algorithm and Circuit of Nesting Doubled Qubits,"['Artyom M. Grigoryan', 'Sos S. Agaian']",ARXIV,http://arxiv.org/pdf/2201.00256v2,2022-01-01T23:14:44Z,2022-01-07T18:27:15Z,['10.48550/arXiv.2201.00256'],"Copying the quantum states is contradictory to classical information processing since the fundamental difference between classical and quantum information is that while classical information can be copied perfectly, quantum information cannot. However, this statement does not rule out the risk of building a device that can reproduce a set of quantum states. This paper investigates the naturally arising question of how well or under what conditions one can copy and measure an arbitrary quantum superposition of states. The CNOT and XOR operation-based quantum circuit is presented that exhibits entanglement of states and allows for measuring the doubled qubits."
2201.00243,"Education dimensions of MGI: a question of multidisciplinarity, purpose, and equality",['Eva M. Campo'],ARXIV,http://arxiv.org/pdf/2201.00243v1,2022-01-01T22:05:27Z,2022-01-01T22:05:27Z,['10.48550/arXiv.2201.00243'],"This paper identifies the challenges associated with coordinating the development of new research methodologies and an accelerated pace of new discoveries in materials science with slower-evolving textbooks and curricula. The target audience is the undergraduate to post-graduate educational community, but implications for the K-12 pipeline are also considered. This paper proposes a lab-to-market classroom continuum with the theory-experiment-data intersection as the conceptual and content framework where the MGI is likely to unfold."
2201.00316,Symmetry analysis of magnetoelectric effects in perovskite-based multiferroics,"['Zukhra Gareeva', 'Anatoly Zvezdin', 'Konstantin Zvezdin', 'Xiang Ming Chen']",ARXIV,http://arxiv.org/pdf/2201.00316v1,2022-01-02T07:50:03Z,2022-01-02T07:50:03Z,"['10.48550/arXiv.2201.00316', '10.3390/ma15020574']","In this article, we perform the symmetry analysis of perovskite-based multiferroics: bismuth ferrite (BiFeO3)-like, orthochromites (RCrO3), and Ruddlesden-Popper perovskites (Ca3Mn2O7-like), being the typical representatives of multiferroics of the trigonal, rhombic, and tetragonal crystal families and explore the effect of crystallographic distortions on magnetoelectric properties. We determine the principal order parameters for each of the considered structures and obtain their invariant combinations consistent with the particular symmetry. This approach allowed us to analyze the features of the magnetoelectric effect observed during structural phase transitions in BixR1-xFeO3 compounds and show that the rare-earth sublattice gives an impact into the linear magnetoelectric effect allowed by the symmetry of the new structure. It is shown that the magnetoelectric properties of ortho-chromites are attributed to the couplings between the magnetic and electric dipole moments arising near Cr3+ ions due to distortions linked with rotations and deformations of the CrO6 octahedra. For the first time, such symmetry consideration was implemented in the analysis of the Ruddlesden-Popper structures, which demonstrates the possibility of realizing the magnetoelectric effect in the Ruddlesden-Popper phases containing magnetically active cations and allows to estimate conditions required for its optimization."
2201.00191,Revisiting Neuron Coverage Metrics and Quality of Deep Neural Networks,"['Zhou Yang', 'Jieke Shi', 'Muhammad Hilmi Asyrofi', 'David Lo']",ARXIV,http://arxiv.org/pdf/2201.00191v1,2022-01-01T13:55:10Z,2022-01-01T13:55:10Z,['10.48550/arXiv.2201.00191'],"Deep neural networks (DNN) have been widely applied in modern life, including critical domains like autonomous driving, making it essential to ensure the reliability and robustness of DNN-powered systems. As an analogy to code coverage metrics for testing conventional software, researchers have proposed neuron coverage metrics and coverage-driven methods to generate DNN test cases. However, Yan et al. doubt the usefulness of existing coverage criteria in DNN testing. They show that a coverage-driven method is less effective than a gradient-based method in terms of both uncovering defects and improving model robustness. In this paper, we conduct a replication study of the work by Yan et al. and extend the experiments for deeper analysis. A larger model and a dataset of higher resolution images are included to examine the generalizability of the results. We also extend the experiments with more test case generation techniques and adjust the process of improving model robustness to be closer to the practical life cycle of DNN development. Our experiment results confirm the conclusion from Yan et al. that coverage-driven methods are less effective than gradient-based methods. Yan et al. find that using gradient-based methods to retrain cannot repair defects uncovered by coverage-driven methods. They attribute this to the fact that the two types of methods use different perturbation strategies: gradient-based methods perform differentiable transformations while coverage-driven methods can perform additional non-differentiable transformations. We test several hypotheses and further show that even coverage-driven methods are constrained only to perform differentiable transformations, the uncovered defects still cannot be repaired by adversarial training with gradient-based methods. Thus, defensive strategies for coverage-driven methods should be further studied."
2201.00238,Evolutionary trend of SARS-CoV-2 inferred by the homopolymeric nucleotide repeats,['Changchuan Yin'],ARXIV,http://arxiv.org/pdf/2201.00238v1,2022-01-01T20:14:36Z,2022-01-01T20:14:36Z,['10.48550/arXiv.2201.00238'],"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is the causative agent of the current global COVID-19 pandemic, in which millions of lives have been lost. Understanding the zoonotic evolution of the coronavirus may provide insights for developing effective vaccines, monitoring the transmission trends, and preventing new zoonotic infections. Homopolymeric nucleotide repeats (HP), the most simple tandem repeats, are a ubiquitous feature of eukaryotic genomes. Yet the HP distributions and roles in coronavirus genome evolution are poorly investigated. In this study, we characterize the HP distributions and trends in the genomes of bat and human coronaviruses and SARS-CoV-2 variants. The results show that the SARS-CoV-2 genome is abundant in HPs, and has augmented HP contents during evolution. Especially, the disparity of HP poly-(A/T) and ploy-(C/G) of coronaviruses increases during the evolution in human hosts. The disparity of HP poly-(A/T) and ploy-(C/G) is correlated to host adaptation and the virulence level of the coronaviruses. Therefore, we propose that the HP disparity can be a quantitative measure for the zoonotic evolution levels of coronaviruses. Peculiarly, the HP disparity measure infers that SARS-CoV-2 Omicron variants have a high disparity of HP poly-(A/T) and ploy-(C/G), suggesting a high adaption to the human hosts."
2201.00115,Toward the Analysis of Graph Neural Networks,"['Thanh-Dat Nguyen', 'Thanh Le-Cong', 'ThanhVu H. Nguyen', 'Xuan-Bach D. Le', 'Quyet-Thang Huynh']",ARXIV,http://arxiv.org/pdf/2201.00115v1,2022-01-01T04:59:49Z,2022-01-01T04:59:49Z,['10.48550/arXiv.2201.00115'],"Graph Neural Networks (GNNs) have recently emerged as a robust framework for graph-structured data. They have been applied to many problems such as knowledge graph analysis, social networks recommendation, and even Covid19 detection and vaccine developments. However, unlike other deep neural networks such as Feed Forward Neural Networks (FFNNs), few analyses such as verification and property inferences exist, potentially due to dynamic behaviors of GNNs, which can take arbitrary graphs as input, whereas FFNNs which only take fixed size numerical vectors as inputs. This paper proposes an approach to analyze GNNs by converting them into FFNNs and reusing existing FFNNs analyses. We discuss various designs to ensure the scalability and accuracy of the conversions. We illustrate our method on a study case of node classification. We believe that our approach opens new research directions for understanding and analyzing GNNs."
2201.00399,"Comment on ""Water sources and kidney function: investigating chronic kidney disease of unknown etiology in a prospective study"", by P. Vlahos et al",['M. W. C. Dharma-wardana'],ARXIV,http://arxiv.org/pdf/2201.00399v3,2021-12-28T16:52:22Z,2022-01-17T01:43:38Z,['10.48550/arXiv.2201.00399'],"Vlahos et al., Ref. 1, NPJ Clean water. 4, 50 (2021) have reported the presence of pesticide contamination above safe levels in a ""single time-point analysis"" of well water in a region in Sri Lanka where chronic kidney disease of unknown etiology (CKDu) is endemic. They conclude ""that agrochemical use in paddy and other agricultural practices ... of the Green Revolution in Sri Lanka may now be contributing to ill health, rapid progression of disease, and mortality"". The authors also propose ""reducing ... agrochemical contaminants in Sri Lanka and other tropical countries to reduce ... CKDu"". These conclusions, based on what they call a ""single time-point analysis"", tantamount to an identification of the etiology of CKDu are unsupported by the evidence presented by Vlahos et al. They do not satisfy, say, even the simplest of Bradford-Hill criteria for causation. In particular, (i) similar but non-persistent pesticide excesses have been detected sporadically in most parts of the country including where there is no CKDu; (ii) the pesticides reported in (1) cause both hepatotoxicity and nephrotoxicity; the latter with glomerular damage while CKDu is associated with tubulo-interstitial damage where no hepatotoxic symptoms have been reported; (iii) the pesticides detected have short half-lives and are used over short periods during farming; so the one time-point analysis is inadequate and misleading; (iv) farming communities that use pesticides in the same way but remain essentially without CKDu are found to exist adjacent to communities with CKDu; (v) the CKDu prevalence seems to correlate with local geomorphology but without correlation to agriculture which is practiced in most parts of the country. ."
2201.00431,Instanton effects on chiral symmetry breaking and hadron spectroscopy,['Masayasu Hasegawa'],ARXIV,http://arxiv.org/pdf/2201.00431v1,2022-01-02T23:15:31Z,2022-01-02T23:15:31Z,['10.48550/arXiv.2201.00431'],"This project aims to give indications to find monopole and instanton effects in QCD on the observables by experiments. First, we add the monopole and anti-monopole to the QCD vacuum of the quenched SU(3) and calculate the physical observables using the eigenvalues and eigenvectors of the overlap Dirac operator that preserves the exact chiral symmetry. We have found that the additional monopole and anti-monopole make the long monopole loops are closely related to the quark confinement without changing the vacuum structure. Furthermore, we have confirmed that the additional monopole and anti-monopole create instantons and anti-instantons are closely associated with the chiral symmetry breaking. We have shown that the chiral condensate (minus value) decreases in direct proportion to the square root of the number density of the instantons and anti-instantons. The decay constants and masses of pion and kaon increase in direct proportion to the one-fourth root of the number density of the instantons and anti-instantons. This report estimates the eta meson mass using these outcomes as the input values, and the eta-prime meson mass is calculated in two ways: (i) Substituting the numerical results of the topological charge and pion decay constant to the Witten and Veneziano mass formula. (ii) Calculating the correlations of the disconnected (hairpin) graphs. The preliminary results of the eta-prime meson mass estimated in the quenched SU(3) are as follows. (i) m$_{\eta'}$ = 1.055(15)$\times10^{3}$ [MeV] (at the continuum limit). (ii) m$_{\eta'}$ = 1.04(2)$\times10^{3}$ [MeV] (at the chiral and continuum limits). Finally, we demonstrate that the eta-prime meson mass becomes heavy with increasing the number density of the instantons and anti-instantons."
2201.00391,On the independence number of random trees via tricolourations,['Etienne Bellin'],ARXIV,http://arxiv.org/pdf/2201.00391v2,2022-01-02T18:31:35Z,2022-01-10T15:28:04Z,['10.48550/arXiv.2201.00391'],"We are interested in the independence number of large random simply generated trees and related parameters, such as their matching number or the kernel dimension of their adjacency matrix. We express these quantities using a canonical tricolouration, which is a way to colour the vertices of a tree with three colours. As an application we obtain limit theorems in $L^p$ for the renormalised independence number in large simply generated trees (including large size-conditioned Bienaym\'e-Galton-Watson trees)."
2201.00260,A time-dependent switching mean-field game on networks motivated by optimal visiting problems,"['Fabio Bagagiolo', 'Luciano Marzufero']",ARXIV,http://arxiv.org/pdf/2201.00260v2,2022-01-01T23:27:04Z,2023-03-22T15:13:39Z,"['10.48550/arXiv.2201.00260', '10.3934/jdg.2022019']","Motivated by an optimal visiting problem, we study a switching mean-field game on a network, where both a decisional and a switching time-variable is at disposal of the agents for what concerns, respectively, the instant to decide and the instant to perform the switch. Every switch between the nodes of the network represents a switch from $0$ to $1$ of one component of the string $p = (p_1,\ldots, p_n)$ which, in the optimal visiting interpretation, gives information on the visited targets, being the targets labeled by $i=1,\ldots, n$. The goal is to reach the final string $(1, \ldots, 1)$ in the final time $T$, minimizing a switching cost also depending on the congestion on the nodes. We prove the existence of a suitable definition of an approximated $\varepsilon$-mean-field equilibrium and then address the passage to the limit when $\varepsilon$ goes to 0."
2201.00361,Resolvent-based tools for optimal estimation and control via the Wiener-Hopf formalism,"['Eduardo Martini', 'Junoh Jung', 'André V. G. Cavalieri', 'Peter Jordan', 'Aaron Towne']",ARXIV,http://arxiv.org/pdf/2201.00361v1,2022-01-02T14:17:13Z,2022-01-02T14:17:13Z,"['10.48550/arXiv.2201.00361', '10.1017/jfm.2022.102']","The application of control tools to complex flows frequently requires approximations, such as reduced-order models and/or simplified forcing assumptions, where these may be considered low-rank or defined in terms of simplified statistics (e.g. white noise). In this work, we propose a resolvent-based control methodology with causality imposed via a Wiener-Hopf formalism. Linear optimal causal estimation and control laws are obtained directly from full-rank, globally stable systems with arbitrary disturbance statistics, circumventing many drawbacks of alternative methods. We use efficient, matrix-free methods to construct the matrix Wiener-Hopf problem, and we implement a tailored method to solve the problem numerically. The approach naturally handles forcing terms with space-time colour; it allows inexpensive parametric investigation of sensor/actuator placement in scenarios where disturbances/targets are low rank; it is directly applicable to complex flows disturbed by high-rank forcing; it has lower cost in comparison to standard methods; it can be used in scenarios where an adjoint solver is not available; or it can be based exclusively on experimental data. The method is particularly well-suited for the control of amplifier flows, for which optimal control approaches are typically robust. Validation of the approach is performed using the linearized Ginzburg-Landau equation. Flow over a backward-facing step perturbed by high-rank forcing is then considered. Sensor and actuator placement are investigated for this case, and we show that while the flow response downstream of the step is dominated by the Kelvin-Helmholtz mechanism, it has a complex, high-rank receptivity to incoming upstream perturbations, requiring multiple sensors for control."
2201.00155,Adaptive Single Image Deblurring,"['Maitreya Suin', 'Kuldeep Purohit', 'A. N. Rajagopalan']",ARXIV,http://arxiv.org/pdf/2201.00155v1,2022-01-01T10:10:19Z,2022-01-01T10:10:19Z,['10.48550/arXiv.2201.00155'],"This paper tackles the problem of dynamic scene deblurring. Although end-to-end fully convolutional designs have recently advanced the state-of-the-art in non-uniform motion deblurring, their performance-complexity trade-off is still sub-optimal. Existing approaches achieve a large receptive field by a simple increment in the number of generic convolution layers, kernel-size, which comes with the burden of the increase in model size and inference speed. In this work, we propose an efficient pixel adaptive and feature attentive design for handling large blur variations within and across different images. We also propose an effective content-aware global-local filtering module that significantly improves the performance by considering not only the global dependencies of the pixel but also dynamically using the neighboring pixels. We use a patch hierarchical attentive architecture composed of the above module that implicitly discover the spatial variations in the blur present in the input image and in turn perform local and global modulation of intermediate features. Extensive qualitative and quantitative comparisons with prior art on deblurring benchmarks demonstrate the superiority of the proposed network."
2201.00499,Quantum electrodynamic effects on counter-streaming instabilities in the whole \textbf{k} space,['Antoine Bret'],ARXIV,http://arxiv.org/pdf/2201.00499v1,2022-01-03T07:02:47Z,2022-01-03T07:02:47Z,"['10.48550/arXiv.2201.00499', '10.1103/PhysRevE.105.015205']","In a recent work [Bret, EPL \textbf{135} (2021) 35001], quantum electrodynamic (QED) effects were evaluated for the two-stream instability. It pertains to the growth of perturbations with a wave vector oriented along the flow in a collisionless counter-streaming system. Here, the analysis is extended to every possible orientation of the wave vector. The previous result for the two-stream instability is recovered, and it is proved that even within the framework of a 3D analysis, this instability remains fundamentally 1D even when accounting for QED effects. The filamentation instability, found for wave vectors normal to the flow, is weakly affected by QED corrections. As in the classical case, its growth rate saturates at large $k_\perp$. The saturation value is found independent of QED corrections. Also, the smallest unstable $k_\perp$ is independent of QED corrections. Surprisingly, unstable modes found for oblique wave vectors do \emph{not} follow the same pattern. For some, QED corrections do reduce the growth rate. But for others, the same corrections increase the growth rate instead. The possibility for QED effects to play a role in un-magnetized systems is evaluated. Pair production resulting from gamma emission by particles oscillating in the exponentially growing fields, is not accounting for."
2201.00214,Temperature Analysis of Flaring (AR11283) and non-Flaring (AR12194) Coronal Loops,"['Narges Fathalian', 'Seyedeh Somayeh Hosseini Rad', 'Nasibeh Alipour', 'Hossein Safari']",ARXIV,http://arxiv.org/pdf/2201.00214v1,2022-01-01T16:14:57Z,2022-01-01T16:14:57Z,"['10.48550/arXiv.2201.00214', '10.1088/1674-4527/ac47ac']","Here, we study the temperature structure of flaring and non-flaring coronal loops, using extracted loops from images taken in six extreme ultraviolet (EUV) channels recorded by Atmospheric Imaging Assembly (AIA)/ Solar Dynamic Observatory (SDO). We use data for loops of X2.1-class-flaring active region (AR11283) during 22:10UT till 23:00UT, on 2011, September 6; and non-flaring active region (AR12194) during 08:00:00UT till 09:00:00UT on 2014, October 26. By using spatially-synthesized Gaussian DEM forward-fitting method, we calculate the peak temperatures for each strip of the loops. We apply the Lomb-Scargle method to compute the oscillations periods for the temperature series of each strip. The periods of the temperature oscillations for the flaring loops are ranged from 7 min to 28.4 min. These temperature oscillations show very close behavior to the slow-mode oscillation. We observe that the temperature oscillations in the flaring loops are started at least around 10 minutes before the transverse oscillations and continue for a long time duration even after the transverse oscillations are ended. The temperature amplitudes are increased at the flaring time (during 20 min) in the flaring loops. The periods of the temperatures obtained for the non-flaring loops are ranged from 8.5 min to 30 min, but their significances are less (below 0.5) in comparison with the flaring ones (near to one). Hence the detected temperature periods for the non-flaring loops' strips are less probable in comparison with the flaring ones, and maybe they are just fluctuations. Based on our confined observations, it seems that the flaring loops' periods show more diversity and their temperatures have wider ranges of variation than the non-flaring ones. More accurate commentary in this respect requires more extensive statistical research and broader observations."
2201.00216,The Pomeron -- A Bootstrap Story,['Chung-I Tan'],ARXIV,http://arxiv.org/pdf/2201.00216v1,2022-01-01T16:29:39Z,2022-01-01T16:29:39Z,['10.48550/arXiv.2201.00216'],"In a contribution to the volume {\it A Passion for Physics}, a collection of essays in honor of Geoffrey Chew's sixtieth birthday, I wrote, together with A. Capella, Uday Sukhatme, and Tran Thanh Van {\it The Pomeron Story.} This is a follow-up to that contribution. This sequel also serves as an opportunity to acknowledge my gratitude to Geoff as a PhD student under his tutelage."
2201.00295,Radio Pulsar Sub-Populations (II) : The Mysterious RRATs,"[' Abhishek', 'Namrata Malusare', 'Tanushree N', 'Gayathri Hegde', 'Sushan Konar']",ARXIV,http://arxiv.org/pdf/2201.00295v2,2022-01-02T05:27:33Z,2022-05-04T12:05:01Z,['10.48550/arXiv.2201.00295'],"Several conjectures have been put forward to explain the RRATs, the newest subclass of neutron stars, and their connections to other radio pulsars. This work discusses these conjectures in the context of the characteristic properties of the RRAT population. Contrary to expectations, it is seen that - a) the RRAT population is statistically un-correlated with the nulling pulsars, and b) the RRAT phenomenon is unlikely to be related to old age or death-line proximity. It is perhaps more likely that the special emission property of RRATs is a signature of them being later evolutionary phases of other types of neutron stars which may have resulted in restructuring of the magnetic fields."
2201.00182,On the representativeness of approximate solutions of discrete optimization problems with interval objective function,['Alexander Prolubnikov'],ARXIV,http://arxiv.org/pdf/2201.00182v2,2022-01-01T12:54:07Z,2022-06-18T12:10:43Z,['10.48550/arXiv.2201.00182'],"We consider discrete optimization problems with interval uncertatinty of objective function coefficients. The interval uncertainty models measurements errors. A pos\-sible optimal solution is a solution that is optimal for some possible values of the coefficients. Pro\-ba\-bi\-li\-ty of a possible solution is the probability to obtain such coefficients that the solution is optimal. Similarly we define the notion of a possible approximate solution with given accuracy and probability of the solution. A possible approximate solution is an approximate solution that is obtained for some possible values of the coefficients by some fixed approximate algorithm, e.g. by the greedy algorithm. Pro\-ba\-bi\-li\-ty of a such solution is the probability to obtain such coefficients that the algorithm produces the solution as its output. We consider optimal or approximate possible solution un\-re\-pre\-sen\-ta\-ti\-ve if its probability less than some boundary value. The mean approximate solution is a possible approximate solution for midpoints of the coefficients intervals. The solution may be treated as approximate solution for exact values of the coefficients. We show that the share of individual discrete optimization problems instances with unrepresentative mean approximate solution may be wide enough for rather small values of error and the boundary value. The same is true for any other possible approximate solution: all of them may be unrepresentative."
2201.00173,Nonlinear Anderson localized states at arbitrary disorder,"['Wencai Liu', 'W. -M. Wang']",ARXIV,http://arxiv.org/pdf/2201.00173v1,2022-01-01T11:49:27Z,2022-01-01T11:49:27Z,['10.48550/arXiv.2201.00173'],"It is classical, following Furstenberg's theorem on positive Lyapunov exponent for products of random SL$(2, \mathbb R)$ matrices, that the one dimensional random Schr\""odinger operator has Anderson localization at arbitrary disorder. This paper proves a nonlinear analogue, thereby establishing a KAM-type persistence result for a non-integrable system."
2201.00304,Informed Multi-context Entity Alignment,"['Kexuan Xin', 'Zequn Sun', 'Wen Hua', 'Wei Hu', 'Xiaofang Zhou']",ARXIV,http://arxiv.org/pdf/2201.00304v1,2022-01-02T06:29:30Z,2022-01-02T06:29:30Z,"['10.48550/arXiv.2201.00304', '10.1145/3488560.3498523']","Entity alignment is a crucial step in integrating knowledge graphs (KGs) from multiple sources. Previous attempts at entity alignment have explored different KG structures, such as neighborhood-based and path-based contexts, to learn entity embeddings, but they are limited in capturing the multi-context features. Moreover, most approaches directly utilize the embedding similarity to determine entity alignment without considering the global interaction among entities and relations. In this work, we propose an Informed Multi-context Entity Alignment (IMEA) model to address these issues. In particular, we introduce Transformer to flexibly capture the relation, path, and neighborhood contexts, and design holistic reasoning to estimate alignment probabilities based on both embedding similarity and the relation/entity functionality. The alignment evidence obtained from holistic reasoning is further injected back into the Transformer via the proposed soft label editing to inform embedding learning. Experimental results on several benchmark datasets demonstrate the superiority of our IMEA model compared with existing state-of-the-art entity alignment methods."
2201.00164,The differential role of verbal and visuospatial working memory in mathematics and reading,"['David Giofrè', 'Enrica Donolato', 'Irene C. Mammarella']",ARXIV,http://arxiv.org/pdf/2201.00164v1,2022-01-01T10:53:17Z,2022-01-01T10:53:17Z,"['10.48550/arXiv.2201.00164', '10.1016/j.tine.2018.07.001']","Objectives: Several studies have focused on the role of working memory (WM) in predicting mathematical and reading literacy. Alternative models of WM have been proposed and a modality-dependent model of WM, distinguishing between verbal and visuospatial WM modalities, has been advanced. In addition, the relationship between verbal and visuospatial WM and academic achievement has not been extensively and consistently studied, especially when it comes to distinguishing between mathematical and reading tasks. Method: In the present study, we tested a large group of middle school children in several measures of WM, and in mathematical and reading tasks. Results: Confirmatory factor analyses showed that verbal and visuospatial WM can be differentiated and that these factors have a different predictive power in explaining unique portions of variance in reading and mathematics. Conclusions: Our findings point to the importance of distinguishing between WM modalities in evaluating the relationship between mathematics and reading."
2201.00308,"DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents","['Kushagra Pandey', 'Avideep Mukherjee', 'Piyush Rai', 'Abhishek Kumar']",ARXIV,http://arxiv.org/pdf/2201.00308v3,2022-01-02T06:44:23Z,2022-11-29T07:18:50Z,['10.48550/arXiv.2201.00308'],"Diffusion probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, standard Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design novel conditional parameterizations for diffusion models. We show that the resulting model equips diffusion models with a low-dimensional VAE inferred latent code which can be used for downstream tasks like controllable synthesis. The proposed method also improves upon the speed vs quality tradeoff exhibited in standard unconditional DDPM/DDIM models (for instance, FID of 16.47 vs 34.36 using a standard DDIM on the CelebA-HQ-128 benchmark using T=10 reverse process steps) without having explicitly trained for such an objective. Furthermore, the proposed model exhibits synthesis quality comparable to state-of-the-art models on standard image synthesis benchmarks like CIFAR-10 and CelebA-64 while outperforming most existing VAE-based methods. Lastly, we show that the proposed method exhibits inherent generalization to different types of noise in the conditioning signal. For reproducibility, our source code is publicly available at https://github.com/kpandey008/DiffuseVAE."
2201.00158,"$PT$-symmetric non-Hermitian Hamiltonian and invariant operator in periodically driven $SU(1,1)$ system","['Yan Gu', 'Xue-Min Bai', 'Xiao-Lei Hao', 'J. -Q. Liang']",ARXIV,http://arxiv.org/pdf/2201.00158v1,2022-01-01T10:30:22Z,2022-01-01T10:30:22Z,['10.48550/arXiv.2201.00158'],"We study in this paper the time evolution of $PT$-symmetric non-Hermitian Hamiltonian consisting of periodically driven $SU(1,1)$ generators. A non-Hermitian invariant operator is adopted to solve the Schr\""{o}dinger equation, since the time-dependent Hamiltonian is no longer a conserved quantity. We propose a scheme to construct the non-Hermitian invariant with a $PT$-symmetric but non-unitary transformation operator. The eigenstates of invariant and its complex conjugate form a bi-orthogonal basis to formulate the exact solution. We obtain the non-adiabatic Berry phase, which reduces to the adiabatic one in the slow time-variation limit. A non-unitary time-evolution operator is found analytically. As an consequence of the non-unitarity the ket ($|\psi (t)\rangle $) and bra ($\langle \psi (t)|$) states are not normalized each other. While the inner product of two states can be evaluated with the help of a metric operator. It is shown explicitly that the model can be realized by a periodically driven oscillator."
2201.00213,Resilience and inequality growth monitoring after disaster using indicators based on energy production,['Julien Gargani'],ARXIV,http://arxiv.org/pdf/2201.00213v1,2022-01-01T15:42:14Z,2022-01-01T15:42:14Z,['10.48550/arXiv.2201.00213'],"The estimation of resilience and the determination of inequality growth after a disaster is often difficult. In this study, specific indicators were developed to analyze resilience, and the trajectories of resilience were compared. Energy production is relevant for describing variations in social and economic activities. This indicator was applied to a case study of a natural disaster, that is Hurricane Irma in 2017. The hurricane caused fatalities and destruction in the Caribbean islands of Saint Martin and Saint Barthelemy, which are two French overseas territories. Energy production after Hurricane Irma exhibited a significant decrease due to the destruction of the electricity network as well as perturbations in economic and social activities. The energy production restoration rate was higher in Saint Barthelemy than in Saint Martin. The electricity restoration rate after a disaster was almost constant. However, the energy production 18 months after Hurricane Irma was identical to that before Hurricane Irma in Saint Barthelemy; this was not the case in Saint Martin. During resilience, an increase in the gap between energy production in Saint Barthelemy and Saint Martin was observed. This study indicated that this gap represents an inequality growth between Saint Barthelemy (gross domestic product (GDP) of 40 000 euros/inhabitant) and Saint Martin (GDP of 16 600 euros/inhabitant). The indicators emphasized that inequality growth after natural disasters favors less vulnerable and more resilient territories. The number of inhabitants must be considered during indicator construction to avoid any bias."
2201.00336,Visilence: An Interactive Visualization Tool for Error Resilience Analysis,"['Shaolun Ruan', 'Yong Wang', 'Qiang Guan']",ARXIV,http://arxiv.org/pdf/2201.00336v1,2022-01-02T11:15:29Z,2022-01-02T11:15:29Z,['10.48550/arXiv.2201.00336'],"Soft errors have become one of the major concerns for HPC applications, as those errors can result in seriously corrupted outcomes, such as silent data corruptions (SDCs). Prior studies on error resilience have studied the robustness of HPC applications. However, it is still difficult for program developers to identify potential vulnerability to soft errors. In this paper, we present Visilence, a novel visualization tool to visually analyze error vulnerability based on the control-flow graph generated from HPC applications. Visilence efficiently visualizes the affected program states under injected errors and presents the visual analysis of the most vulnerable parts of an application. We demonstrate the effectiveness of Visilence through a case study."
2201.00220,Turath-150K: Image Database of Arab Heritage,"['Dani Kiyasseh', 'Rasheed El-Bouri']",ARXIV,http://arxiv.org/pdf/2201.00220v1,2022-01-01T17:36:25Z,2022-01-01T17:36:25Z,['10.48550/arXiv.2201.00220'],"Large-scale image databases remain largely biased towards objects and activities encountered in a select few cultures. This absence of culturally-diverse images, which we refer to as the hidden tail, limits the applicability of pre-trained neural networks and inadvertently excludes researchers from under-represented regions. To begin remedying this issue, we curate Turath-150K, a database of images of the Arab world that reflect objects, activities, and scenarios commonly found there. In the process, we introduce three benchmark databases, Turath Standard, Art, and UNESCO, specialised subsets of the Turath dataset. After demonstrating the limitations of existing networks pre-trained on ImageNet when deployed on such benchmarks, we train and evaluate several networks on the task of image classification. As a consequence of Turath, we hope to engage machine learning researchers in under-represented regions, and to inspire the release of additional culture-focused databases. The database can be accessed here: danikiyasseh.github.io/Turath."
2201.00434,TVNet: Temporal Voting Network for Action Localization,"['Hanyuan Wang', 'Dima Damen', 'Majid Mirmehdi', 'Toby Perrett']",ARXIV,http://arxiv.org/pdf/2201.00434v1,2022-01-02T23:46:18Z,2022-01-02T23:46:18Z,['10.48550/arXiv.2201.00434'],"We propose a Temporal Voting Network (TVNet) for action localization in untrimmed videos. This incorporates a novel Voting Evidence Module to locate temporal boundaries, more accurately, where temporal contextual evidence is accumulated to predict frame-level probabilities of start and end action boundaries. Our action-independent evidence module is incorporated within a pipeline to calculate confidence scores and action classes. We achieve an average mAP of 34.6% on ActivityNet-1.3, particularly outperforming previous methods with the highest IoU of 0.95. TVNet also achieves mAP of 56.0% when combined with PGCN and 59.1% with MUSES at 0.5 IoU on THUMOS14 and outperforms prior work at all thresholds. Our code is available at https://github.com/hanielwang/TVNet."
2201.00347,Observations of asteroid magnitude-phase relations at the Kharadze Abastumani Astrophysical Observatory,"['V. G. Shevchenko1', 'R. Ya. Inasaridze', 'Yu. N. Krugly', 'V. V. Ayvazian', 'G. V. Kapanadze', 'G. Datashvili', 'I. G. Slyusarev', 'V. G. Chiorny', 'I. E. Molotov']",ARXIV,http://arxiv.org/pdf/2201.00347v1,2022-01-02T12:35:10Z,2022-01-02T12:35:10Z,['10.48550/arXiv.2201.00347'],In frame of an implementation of the cooperative program studying of asteroids between the Kharadze Abastumani Astrophysical Observatory and the Astronomical Institute of V.N. Karazin Kharkiv National University the observations for five main-belt asteroids were performed to obtain their magnitude-phase relations and other physical characteristics. Preliminary results of the photometrical observations for the large dark asteroid (1390) Abastumani are presented.
2201.00152,On structure theorems and non-saturated examples,"['Qinqi Wu', 'Hui Xu', 'Xiangdong Ye']",ARXIV,http://arxiv.org/pdf/2201.00152v1,2022-01-01T09:27:21Z,2022-01-01T09:27:21Z,['10.48550/arXiv.2201.00152'],"For any minimal system $(X,T)$ and $d\geq 1$ there is an associated minimal system $(N_{d}(X), \mathcal{G}_{d}(T))$, where $\mathcal{G}_{d}(T)$ is the group generated by $T\times\cdots\times T$ and $T\times T^2\times\cdots\times T^{d}$ and $N_{d}(X)$ is the orbit closure of the diagonal under $\mathcal{G}_{d}(T)$. It is known that the maximal $d$-step pro-nilfactor of $N_d(X)$ is $N_d(X_d)$, where $X_d$ is the maximal $d$-step pro-nilfactor of $X$. In this paper, we further study the structure of $N_d(X)$. We show that the maximal distal factor of $N_d(X)$ is $N_d(X_{dis})$ with $X_{dis}$ being the maximal distal factor of $X$, and prove that as minimal systems $(N_{d}(X), \mathcal{G}_{d}(T))$ has the same structure theorem as $(X,T)$. In addition, a non-saturated metric example $(X,T)$ is constructed, which is not $T\times T^2$-saturated and is a Toeplitz minimal system."
2201.00208,Lagrangian fillings for Legendrian links of finite or affine Dynkin type,"['Byung Hee An', 'Youngjin Bae', 'Eunjeong Lee']",ARXIV,http://arxiv.org/pdf/2201.00208v2,2022-01-01T15:19:10Z,2022-02-08T18:23:51Z,['10.48550/arXiv.2201.00208'],"We prove that there are at least as many exact embedded Lagrangian fillings as seeds for Legendrian links of finite type $\mathsf{ADE}$ or affine type $\tilde{\mathsf{D}} \tilde{\mathsf{E}}$. We also provide as many Lagrangian fillings with rotational symmetry as seeds of type $\mathsf{B}$, $\mathsf{G}_2$, $\tilde{\mathsf{G}}_2$, $\tilde{\mathsf{B}}$, or $\tilde{\mathsf{C}}_2$, and with conjugation symmetry as seeds of type $\mathsf{F}_4$, $\mathsf{C}$, $\mathsf{E}_6^{(2)}$, $\tilde{\mathsf{F}}_4$, or $\mathsf{A}_5^{(2)}$. These families are the first known Legendrian links with (infinitely many) exact Lagrangian fillings (with symmetry) that exhaust all seeds in the corresponding cluster structures beyond type $\mathsf{A} \mathsf{D}$. Furthermore, we show that the $N$-graph realization of (twice of) Coxeter mutation of type $\tilde{\mathsf{D}} \tilde{\mathsf{E}}$ corresponds to a Legendrian loop of the corresponding Legendrian links. Especially, the loop of type $\tilde{\mathsf{D}}$ coincides with the one considered by Casals and Ng."
2201.00417,Non-local parameterization of atmospheric subgrid processes with neural networks,"['Peidong Wang', 'Janni Yuval', ""Paul A. O'Gorman""]",ARXIV,http://arxiv.org/pdf/2201.00417v2,2022-01-02T20:55:18Z,2022-12-26T02:24:50Z,"['10.48550/arXiv.2201.00417', '10.1029/2022MS002984']","Subgrid processes in global climate models are represented by parameterizations which are a major source of uncertainties in simulations of climate. In recent years, it has been suggested that machine-learning (ML) parameterizations based on high-resolution model output data could be superior to traditional parameterizations. Currently, both traditional and ML parameterizations of subgrid processes in the atmosphere are based on a single-column approach, which only use information from single atmospheric columns. However, single-column parameterizations might not be ideal since certain atmospheric phenomena, such as organized convective systems, can cross multiple grid boxes and involve slantwise circulations that are not purely vertical. Here we train neural networks (NNs) using non-local inputs spanning over 3$\times$3 columns of inputs. We find that including the non-local inputs improves the offline prediction of a range of subgrid processes. The improvement is especially notable for subgrid momentum transport and for atmospheric conditions associated with mid-latitude fronts and convective instability. Using an interpretability method, we find that the NN improvements partly rely on using the horizontal wind divergence, and we further show that including the divergence or vertical velocity as a separate input substantially improves offline performance. However, non-local winds continue to be useful inputs for parameterizating subgrid momentum transport even when the vertical velocity is included as an input. Overall, our results imply that the use of non-local variables and the vertical velocity as inputs could improve the performance of ML parameterizations, and the use of these inputs should be tested in online simulations in future work."
2201.00156,Low energy supersymmetry confronted with current experiments: an overview,"['Fei Wang', 'Wenyu Wang', 'Jin Min Yang', 'Yang Zhang', 'Bin Zhu']",ARXIV,http://arxiv.org/pdf/2201.00156v1,2022-01-01T10:15:12Z,2022-01-01T10:15:12Z,['10.48550/arXiv.2201.00156'],"This study provides a brief overview of low-energy supersymmetry (SUSY) in light of current experimental constraints, such as collider searches, dark matter searches, and muon $g-2$ measurements. In addition, we survey a variety of low energy supersymmetric models: the phenomenological minimal supersymmetric model (MSSM); the supersymmetric models with cut-off-scale boundary conditions, i.e., the minimal supergravity (mSUGRA) or the constrained MSSM (CMSSM), the gauge mediation of SUSY breaking (GMSB), and the anomaly mediation of SUSY breaking (AMSB), as well as their extensions. The conclusion is that the low energy SUSY can survive all current experimental constraints and remains compelling, albeit suffering from a little fine-tuning problem. The fancy models like mSUGRA, GMSB, and AMSB need to be extended if the muon $g-2$ anomaly comes from new physics."
2201.00282,Approximate solutions for Dorodnitzyn's gaseous boundary layer limit formula,['C. V. Valencia-Negrete'],ARXIV,http://arxiv.org/pdf/2201.00282v1,2022-01-02T03:36:41Z,2022-01-02T03:36:41Z,['10.48550/arXiv.2201.00282'],"Oleinik's \emph{no back-flow} condition ensures the existence and uniqueness of solutions for the Prandtl equations in a rectangular domain $R\subset \mathbb{R}^2$. It also allowed us to find a limit formula for Dorodnitzyn's stationary compre\-ssible boundary layer with constant total energy on a bounded convex domain in the plane $\mathbb{R}^2$. Under the same assumption, we can give an approximate solution $u$ for the limit formula if $|u|<\!\!<\!\!<1$: \[u(z)\cong \delta * c * \left[z+\frac{6}{25}\cdot \frac{1}{2i_0} \cdot \frac{4U^2}{3}z^4\right]+o(z^5),\] that corresponds to an approximate horizontal velocity component when a small parameter $\epsilon$ given by the quotient of the maximum height of the domain divided by its length tends to zero. Here, $c>0$, $\delta$ is the boundary layer's height in Dorodnitzyn's coordinates, $U$ is the \emph{free-stream} velocity at the upper boundary of the domain, and $T_0$ is the absolute surface temperature."
2201.00419,VISAS -- Detecting GPS spoofing attacks against drones by analyzing camera's video stream,"['Barak Davidovich', 'Ben Nassi', 'Yuval Elovici']",ARXIV,http://arxiv.org/pdf/2201.00419v1,2022-01-02T21:19:08Z,2022-01-02T21:19:08Z,['10.48550/arXiv.2201.00419'],"In this study, we propose an innovative method for the real-time detection of GPS spoofing attacks targeting drones, based on the video stream captured by a drone's camera. The proposed method collects frames from the video stream and their location (GPS); by calculating the correlation between each frame, our method can identify an attack on a drone. We first analyze the performance of the suggested method in a controlled environment by conducting experiments on a flight simulator that we developed. Then, we analyze its performance in the real world using a DJI drone. Our method can provide different levels of security against GPS spoofing attacks, depending on the detection interval required; for example, it can provide a high level of security to a drone flying at an altitude of 50-100 meters over an urban area at an average speed of 4 km/h in conditions of low ambient light; in this scenario, the method can provide a level of security that detects any GPS spoofing attack in which the spoofed location is a distance of 1-4 meters (an average of 2.5 meters) from the real location."
2201.00165,Hamiltonian cycles above expectation in r-graphs and quasi-random r-graphs,['Raphael Yuster'],ARXIV,http://arxiv.org/pdf/2201.00165v1,2022-01-01T10:54:01Z,2022-01-01T10:54:01Z,"['10.48550/arXiv.2201.00165', '10.1016/j.jctb.2021.12.002']","Let $H_r(n,p)$ denote the maximum number of Hamiltonian cycles in an $n$-vertex $r$-graph with density $p \in (0,1)$. The expected number of Hamiltonian cycles in the random $r$-graph model $G_r(n,p)$ is $E(n,p)=p^n(n-1)!/2$ and in the random graph model $G_r(n,m)$ with $m=p\binom{n}{r}$ it is, in fact, slightly smaller than $E(n,p)$. For graphs, $H_2(n,p)$ is proved to be only larger than $E(n,p)$ by a polynomial factor and it is an open problem whether a quasi-random graph with density $p$ can be larger than $E(n,p)$ by a polynomial factor. For hypergraphs (i.e. $r \ge 3$) the situation is drastically different. For all $r \ge 3$ it is proved that $H_r(n,p)$ is larger than $E(n,p)$ by an {\em exponential} factor and, moreover, there are quasi-random $r$-graphs with density $p$ whose number of Hamiltonian cycles is larger than $E(n,p)$ by an exponential factor."
2201.00383,Integrating Artificial Intelligence and Augmented Reality in Robotic Surgery: An Initial dVRK Study Using a Surgical Education Scenario,"['Yonghao Long', 'Jianfeng Cao', 'Anton Deguet', 'Russell H. Taylor', 'Qi Dou']",ARXIV,http://arxiv.org/pdf/2201.00383v2,2022-01-02T17:34:10Z,2022-03-03T13:42:24Z,['10.48550/arXiv.2201.00383'],"Robot-assisted surgery has become progressively more and more popular due to its clinical advantages. In the meanwhile, the artificial intelligence and augmented reality in robotic surgery are developing rapidly and receive lots of attention. However, current methods have not discussed the coherent integration of AI and AR in robotic surgery. In this paper, we develop a novel system by seamlessly merging artificial intelligence module and augmented reality visualization to automatically generate the surgical guidance for robotic surgery education. Specifically, we first leverage reinforcement leaning to learn from expert demonstration and then generate 3D guidance trajectory, providing prior context information of the surgical procedure. Along with other information such as text hint, the 3D trajectory is then overlaid in the stereo view of dVRK, where the user can perceive the 3D guidance and learn the procedure. The proposed system is evaluated through a preliminary experiment on surgical education task peg-transfer, which proves its feasibility and potential as the next generation of robot-assisted surgery education solution."
2201.00162,"MLOps -- Definitions, Tools and Challenges","['G. Symeonidis', 'E. Nerantzis', 'A. Kazakis', 'G. A. Papakostas']",ARXIV,http://arxiv.org/pdf/2201.00162v1,2022-01-01T10:38:31Z,2022-01-01T10:38:31Z,['10.48550/arXiv.2201.00162'],"This paper is an overview of the Machine Learning Operations (MLOps) area. Our aim is to define the operation and the components of such systems by highlighting the current problems and trends. In this context, we present the different tools and their usefulness in order to provide the corresponding guidelines. Moreover, the connection between MLOps and AutoML (Automated Machine Learning) is identified and how this combination could work is proposed."
2201.00436,"An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation","['Shuyin Xia', 'Xinyu Bai', 'Guoyin Wang', 'Deyu Meng', 'Xinbo Gao', 'Zizhong Chen', 'Elisabeth Giem']",ARXIV,http://arxiv.org/pdf/2201.00436v2,2021-12-29T12:45:49Z,2022-01-12T01:56:24Z,['10.48550/arXiv.2201.00436'],"This paper present a strong data mining method based on rough set, which can realize feature selection, classification and knowledge representation at the same time. Rough set has good interpretability, and is a popular method for feature selections. But low efficiency and low accuracy are its main drawbacks that limits its application ability. In this paper,corresponding to the accuracy, we first find the ineffectiveness of rough set because of overfitting, especially in processing noise attribute, and propose a robust measurement for an attribute, called relative importance.we proposed the concept of ""rough concept tree"" for knowledge representation and classification. Experimental results on public benchmark data sets show that the proposed framework achieves higher accurcy than seven popular or the state-of-the-art feature selection methods."
2201.00247,Now is the time to build a national data ecosystem for materials science and chemistry research data,"['E. M. Campo', 'S. Shankar', 'A. S. Szalay', 'R. J. Hanisch']",ARXIV,http://arxiv.org/pdf/2201.00247v1,2022-01-01T22:40:23Z,2022-01-01T22:40:23Z,['10.48550/arXiv.2201.00247'],"A call for coordinated action from government, academia, and industry."
2201.00298,Role of surface functional groups to superconductivity in Nb$_2$C-MXene: Experiments and density functional theory calculations,"['Kai Wang', 'Haolin Jin', 'Hongye Li', 'Zhongquan Mao', 'Lingyun Tang', 'Dan Huang', 'Ji-Hai Liao', 'Jiang Zhang']",ARXIV,http://arxiv.org/pdf/2201.00298v1,2022-01-02T05:54:05Z,2022-01-02T05:54:05Z,"['10.48550/arXiv.2201.00298', '10.1016/j.surfin.2021.101711']","The recently discovered surface-group-dependent superconductivity in Nb$_2$C-MXene fabricated by the molten salts method is attracting wide attention. However, regarding the superconductivity of Nb$_2$C-MXene with functional F groups (Nb$_2$CF$_x$), there were some conflicting results in experimental and theoretical studies. Herein, we systematically carried out experimental and theoretical investigations on the superconductivity in Nb$_2$C-MXene with the Cl functional group (Nb$_2$CCl$_x$) and Nb$_2$CF$_x$. The experimental results of the Meissner effect and zero resistivity have proved that Nb$_2$CClx is superconducting with the transition temperature (Tc) ~ 5.2 K. We extract its superconducting parameters from the temperature dependence of resistivity and the field dependence of the magnetization. The Ginzburg-Landau parameter K$_G$$_L$ is estimated to be 2.41, indicating that Nb$_2$CClx is a typical type-II superconductor. Conversely, both magnetic and electrical transport measurements demonstrate that Nb$_2$CF$_x$ is not superconducting. The first-principles density functional theory (DFT) calculations show that the Tc of Nb$_2$Cl$_x$ is ~ 5.2 K, while Nb$_2$CF$_x$ is dynamically unstable with imaginary frequency in phonon spectrum, which is in good agreement with the experimental results. Our studies not only are useful for clarifying the present inconsistency but also offer referential significance for future investigations on the superconductivity of MXenes."
2201.00167,Generating Adversarial Samples For Training Wake-up Word Detection Systems Against Confusing Words,"['Haoxu Wang', 'Yan Jia', 'Zeqing Zhao', 'Xuyang Wang', 'Junjie Wang', 'Ming Li']",ARXIV,http://arxiv.org/pdf/2201.00167v1,2022-01-01T11:01:43Z,2022-01-01T11:01:43Z,['10.48550/arXiv.2201.00167'],"Wake-up word detection models are widely used in real life, but suffer from severe performance degradation when encountering adversarial samples. In this paper we discuss the concept of confusing words in adversarial samples. Confusing words are commonly encountered, which are various kinds of words that sound similar to the predefined keywords. To enhance the wake word detection system's robustness against confusing words, we propose several methods to generate the adversarial confusing samples for simulating real confusing words scenarios in which we usually do not have any real confusing samples in the training set. The generated samples include concatenated audio, synthesized data, and partially masked keywords. Moreover, we use a domain embedding concatenated system to improve the performance. Experimental results show that the adversarial samples generated in our approach help improve the system's robustness in both the common scenario and the confusing words scenario. In addition, we release the confusing words testing database called HI-MIA-CW for future research."
2201.00263,"Einstein-type structures, Besse's conjecture and a uniqueness result for a $\varphi$-CPE metric in its conformal class","['Giulio Colombo', 'Luciano Mari', 'Marco Rigoli']",ARXIV,http://arxiv.org/pdf/2201.00263v2,2022-01-01T23:46:38Z,2022-07-01T09:34:06Z,['10.48550/arXiv.2201.00263'],"In this paper, we study an extension of the CPE conjecture to manifolds $M$ which support a structure relating curvature to the geometry of a smooth map $\varphi : M \to N$. The resulting system, denoted by $(\varphi-\mathrm{CPE})$, is natural from the variational viewpoint and describes stationary points for the integrated $\varphi$-scalar curvature functional restricted to metrics with unit volume and constant $\varphi$-scalar curvature. We prove both a rigidity statement for solutions to $(\varphi-\mathrm{CPE})$ in a conformal class, and a gap theorem characterizing the round sphere among manifolds supporting $(\varphi-\mathrm{CPE})$ with $\varphi$ a harmonic map."
2201.00390,Critical crossover phenomena driven by symmetry-breaking defects at quantum transitions,"['Alessio Franchi', 'Davide Rossini', 'Ettore Vicari']",ARXIV,http://arxiv.org/pdf/2201.00390v1,2022-01-02T18:23:54Z,2022-01-02T18:23:54Z,"['10.48550/arXiv.2201.00390', '10.1103/PhysRevE.105.034139']","We study the effects of symmetry-breaking defects at continuous quantum transitions (CQTs), which may arise from localized external fields coupled to the order-parameter operator. The problem is addressed within renormalization-group (RG) and finite-size scaling frameworks. We consider the paradigmatic one-dimensional quantum Ising models at their CQT, in the presence of defects which break the global ${\mathbb Z}_2$ symmetry. We show that such defects can give rise to notable critical crossover regimes where the ground-state properties experience substantial and rapid changes, from symmetric conditions to symmetry-breaking boundaries. An effective characterization of these crossover phenomena driven by defects is achieved by analyzing the ground-state fidelity associated with small changes of the defect strength. Within the critical crossover regime, the fidelity susceptibility shows a power-law divergence when increasing the system size, related to the RG dimension of the defect strength; in contrast, outside the critical defect regime, it remains finite. We support the RG scaling arguments with numerical results."
2201.00192,The Symmetry Enriched Center Functor is Fully Faithful,['Long Sun'],ARXIV,http://arxiv.org/pdf/2201.00192v2,2022-01-01T14:10:15Z,2022-07-19T00:51:15Z,"['10.48550/arXiv.2201.00192', '10.1007/s00220-022-04456-0']","In this work, inspired by some physical intuitions, we define a series of symmetry enriched categories to describe symmetry enriched topological (SET) orders, and define a new tensor product, called the relative tensor product, which describes the stacking of 2+1D SET orders. Then we choose and modify the domain and codomain categories, and manage to make the Drinfeld center a fully faithful symmetric monoidal functor. It turns out that this functor, named the symmetry enriched center functor, provides a precise and rather complete mathematical formulation of the boundary-bulk relation of symmetry enriched topological (SET) orders. We also provide another description of the relative tensor product via a condensable algebra."
2201.00301,Investigating Cargo Loss in Logistics Systems using Low-Cost Impact Sensors,"['Prasang Gupta', 'Antoinette Young', 'Anand Rao']",ARXIV,http://arxiv.org/pdf/2201.00301v2,2022-01-02T06:02:13Z,2022-04-19T05:16:19Z,"['10.48550/arXiv.2201.00301', '10.5121/csit.2022.120618']","Cargo loss/damage is a very common problem faced by almost any business with a supply chain arm, leading to major problems like revenue loss and reputation tarnishing. This problem can be solved by employing an asset and impact tracking solution. This would be more practical and effective for high-cost cargo in comparison to low-cost cargo due to the high costs associated with the sensors and overall solution. In this study, we propose a low-cost solution architecture that is scalable, user-friendly, easy to adopt and is viable for a large range of cargo and logistics systems. Taking inspiration from a real-life use case we solved for a client, we also provide insights into the architecture as well as the design decisions that make this a reality."
2201.00187,Image Restoration using Feature-guidance,"['Maitreya Suin', 'Kuldeep Purohit', 'A. N. Rajagopalan']",ARXIV,http://arxiv.org/pdf/2201.00187v1,2022-01-01T13:10:19Z,2022-01-01T13:10:19Z,['10.48550/arXiv.2201.00187'],"Image restoration is the task of recovering a clean image from a degraded version. In most cases, the degradation is spatially varying, and it requires the restoration network to both localize and restore the affected regions. In this paper, we present a new approach suitable for handling the image-specific and spatially-varying nature of degradation in images affected by practically occurring artifacts such as blur, rain-streaks. We decompose the restoration task into two stages of degradation localization and degraded region-guided restoration, unlike existing methods which directly learn a mapping between the degraded and clean images. Our premise is to use the auxiliary task of degradation mask prediction to guide the restoration process. We demonstrate that the model trained for this auxiliary task contains vital region knowledge, which can be exploited to guide the restoration network's training using attentive knowledge distillation technique. Further, we propose mask-guided convolution and global context aggregation module that focuses solely on restoring the degraded regions. The proposed approach's effectiveness is demonstrated by achieving significant improvement over strong baselines."
2201.00478,$T\overline T$-deformed modular forms,['John Cardy'],ARXIV,http://arxiv.org/pdf/2201.00478v2,2022-01-03T05:10:46Z,2022-02-12T13:49:18Z,"['10.48550/arXiv.2201.00478', '10.4310/CNTP.2022.v16.n3.a1']","Certain objects of conformal field theory, for example partition functions on the rectangle and the torus, and one-point functions on the torus, are either invariant or transform simply under the modular group, properties which should be preserved under the $T\overline T$ deformation. The formulation and proof of this statement in fact extents to more general functions such as $T\overline T$ deformed modular and Jacobi forms. We show that the deformation acts simply on their Mellin transform, multiplying it by a universal entire function. Finally we show that Maass forms on the torus are eigenfunctions of the $T\overline T$ deformation."
2201.00479,Exchange Bias and Interface-related Effects in Two-dimensional van der Waals Magnetic Heterostructures: Open Questions and Perspectives,"['Manh-Huong Phan', 'Vijaysankar Kalappattil', 'Valery Ortiz Jimenez', 'Yen Thi Hai Pham', 'Nivarthana W. Y. A. Y. Mudiyanselage', 'Derick Detellem', 'Chang-Ming Hung', 'Amit Chanda', 'Tatiana Eggers']",ARXIV,http://arxiv.org/pdf/2201.00479v1,2022-01-03T05:15:47Z,2022-01-03T05:15:47Z,['10.48550/arXiv.2201.00479'],"The exchange bias (EB) effect is known as a fundamentally and technologically important magnetic property of a magnetic bilayer film. It is manifested as a horizontal shift in a magnetic hysteresis loop of a film subject to cooling in the presence of a magnetic field. The EB effect in van der Waals (vdW) heterostructures offers a novel approach for tuning the magnetic properties of the newly discovered single-layer magnets, as well as adds a new impetus to magnetic vdW heterostructures. Indeed, intriguing EB effects have recently been reported in a variety of low-dimensional vdW magnetic systems ranging from a weakly interlayer-coupled vdW magnet (e.g., Fe3GeTe2) to a bilayer composed of two different magnetic vdW materials (e.g., Fe3GeTe2/CrCl3, Fe3GeTe2/FePS3, Fe3GeTe2/MnPS3), to bilayers of two different vdW defective magnets (e.g., VSe2/MoS2), or to metallic ferromagnet/vdW defective magnet interfaces (e.g., Fe/MoS2). Despite their huge potential in spintronic device applications, the physical origins of the observed EB effects have remained elusive to researchers. We present here a critical review of the EB effect and associated phenomena such as magnetic proximity (MP) in various vdW heterostructure systems and propose approaches to addressing some of the emerging fundamental questions."
2201.00477,Quark-nuclear hybrid equation of state for neutron stars under modern observational constraints,"['G. A. Contrera', 'D. Blaschke', 'J. P. Carlomagno', 'A. G. Grunfeld', 'S. Liebing']",ARXIV,http://arxiv.org/pdf/2201.00477v2,2022-01-03T05:10:17Z,2022-04-29T16:38:49Z,"['10.48550/arXiv.2201.00477', '10.1103/PhysRevC.105.045808']","We study a family of equations of state for hybrid neutron star matter. The hybrid EOS are obtained by a Maxwell construction of the first-order phase transition between a hadronic phase described by the relativistic density-functional EOS of the ""DD2"" class with excluded volume effects and a deconfined quark matter phase modeled by an instantaneous nonlocal version of the Nambu-Jona-Lasinio model in SU(2)$_f$ with vector interactions and color superconductivity. The form factor in the nonlocal quark matter model is fitted to lattice QCD results in the Coulomb gauge. Owing to strong coupling in the vector meson and diquark channels, a coexistence phase of color superconductivity and chiral symmetry breaking occurs. Our results show an approximately constant behavior for the squared speed of sound with values of 0.4 - 0.6 in the density region relevant for neutron star interiors. To simultaneously fulfill the constraints from the Neutron Star Interior Composition Explorer radius measurement for PSR J0740+6620 and tidal deformability from GW170817 it is necessary to consider a $\mu$-dependent bag pressure that mimics confinement."
2201.00420,Data-driven Sensor Deployment for Spatiotemporal Field Reconstruction,['Jiahong Chen'],ARXIV,http://arxiv.org/pdf/2201.00420v1,2022-01-02T21:19:35Z,2022-01-02T21:19:35Z,"['10.48550/arXiv.2201.00420', '10.15878/j.cnki.instrumentation.2019.03.005']","This paper concerns the data-driven sensor deployment problem in large spatiotemporal fields. Traditionally, sensor deployment strategies have been heavily dependent on model-based planning approaches. However, model-based approaches do not typically maximize the information gain in the field, which tends to generate less effective sampling locations and lead to high reconstruction error. In the present paper, a data-driven approach is developed to overcome the drawbacks of the model-based approach and improve the spatiotemporal field reconstruction accuracy. The proposed method can select the most informative sampling locations to represent the entire spatiotemporal field. To this end, the proposed method decomposes the spatiotemporal field using principal component analysis (PCA) and finds the top r essential entities of the principal basis. The corresponding sampling locations of the selected entities are regarded as the sensor deployment locations. The observations collected at the selected sensor deployment locations can then be used to reconstruct the spatiotemporal field, accurately. Results are demonstrated using a National Oceanic and Atmospheric Administration sea surface temperature dataset. In the present study, the proposed method achieved the lowest reconstruction error among all methods."
2201.00306,Unipotent Generators for Arithmetic Groups,['Tyakal N. Venkataramana'],ARXIV,http://arxiv.org/pdf/2201.00306v1,2022-01-02T06:36:41Z,2022-01-02T06:36:41Z,['10.48550/arXiv.2201.00306'],We sketch a simplification of proofs of old results on the arithmeticity of the group generated by opposing integral unipotent radicals in higher rank arithmetic groups
2201.00430,Classifying Subset Feedback Vertex Set for $H$-Free Graphs,"['Giacomo Paesani', 'Daniël Paulusma', 'Paweł Rzążewski']",ARXIV,http://arxiv.org/pdf/2201.00430v2,2022-01-02T23:09:20Z,2022-07-17T22:09:21Z,['10.48550/arXiv.2201.00430'],"In the Feedback Vertex Set problem, we aim to find a small set $S$ of vertices in a graph intersecting every cycle. The Subset Feedback Vertex Set problem requires $S$ to intersect only those cycles that include a vertex of some specified set $T$. We also consider the Weighted Subset Feedback Vertex Set problem, where each vertex $u$ has weight $w(u)>0$ and we ask that $S$ has small weight. By combining known NP-hardness results with new polynomial-time results we prove full complexity dichotomies for Subset Feedback Vertex Set and Weighted Subset Feedback Vertex Set for $H$-free graphs, that is, graphs that do not contain a graph $H$ as an induced subgraph."
2201.00252,Helmholtz Solutions for the Fractional Laplacian and Other Related Operators,"['Vincent Guan', 'Mathav Murugan', 'Juncheng Wei']",ARXIV,http://arxiv.org/pdf/2201.00252v3,2022-01-01T22:55:17Z,2022-01-12T02:03:19Z,"['10.48550/arXiv.2201.00252', '10.1142/S021919972250016X']","We show that the bounded solutions to the fractional Helmholtz equation, $(-\Delta)^s u= u$ for $0<s<1$ in $\mathbb{R}^n$, are given by the bounded solutions to the classical Helmholtz equation $(-\Delta)u= u$ in $\mathbb{R}^n$ for $n \ge 2$ when $u$ is additionally assumed to be vanishing at $\infty$. When $n=1$, we show that the bounded fractional Helmholtz solutions are again given by the classical solutions $A\cos{x} + B\sin{x}$. We show that this classification of fractional Helmholtz solutions extends for $1<s \le 2$ and $s\in \mathbb{N}$ when $u \in C^\infty(\mathbb{R}^n)$. Finally, we prove that the classical solutions are the unique bounded solutions to the more general equation $\psi(-\Delta) u= \psi(1)u$ in $\mathbb{R}^n$, when $\psi$ is complete Bernstein and certain regularity conditions are imposed on the associated weight $a(t)$."
2201.00483,First operation of undoped CsI directly coupled with SiPMs at 77 Kelvin,"['Keyu Ding', 'Jing Liu', 'Yongjin Yang', 'Dmitry Chernyak']",ARXIV,http://arxiv.org/pdf/2201.00483v2,2022-01-03T05:33:37Z,2022-04-05T15:26:34Z,"['10.48550/arXiv.2201.00483', '10.1140/epjc/s10052-022-10289-x']","The light yield of a small undoped cesium iodide (CsI) crystal directly coupled with two silicon photomultipliers (SiPMs) at about 77~Kelvin was measured to be $43.0 \pm 1.1$~photoelectrons (PE) per keV electron-equivalent (keV$_\text{ee}$) using $X$ and $\gamma$-ray peaks from an $^{241}$Am radioactive source from 18 to 60 keV. The high light yield together with some other technical advantages illustrate the great potential of this novel combination for neutrino and low-mass dark matter detection, particularly at accelerator-based neutrino sources, where random background can be highly suppressed by requiring coincident triggers between SiPMs and beam pulse timing signals. Some potential drawbacks of using cryogenic SiPMs instead of photomultiplier tubes (PMTs) were identified, such as worse energy resolution and optical cross-talks between SiPMs. Their influence to rare-event detection was discussed and possible solutions were provided."
2201.00251,Phonon condensation and cooling via nonlinear feedback,"['Xu Zheng', 'Baowen Li']",ARXIV,http://arxiv.org/pdf/2201.00251v1,2022-01-01T22:53:48Z,2022-01-01T22:53:48Z,['10.48550/arXiv.2201.00251'],"We show that in multimode mechanical systems, the amplification of the lowest mode and the damping of all the other modes can be realized simultaneously via nonlinear feedback. The feedback-induced dynamics of the multimode system is related to the formation of phonon condensation. The phonon statistics of the lowest mode are similar to those of a phonon laser. Finally, we show the coherence of the lowest mode can be improved by an order of magnitude."
2201.00168,Self-attention Multi-view Representation Learning with Diversity-promoting Complementarity,"['Jian-wei Liu', 'Xi-hao Ding', 'Run-kun Lu', 'Xionglin Luo']",ARXIV,http://arxiv.org/pdf/2201.00168v1,2022-01-01T11:17:02Z,2022-01-01T11:17:02Z,['10.48550/arXiv.2201.00168'],"Multi-view learning attempts to generate a model with a better performance by exploiting the consensus and/or complementarity among multi-view data. However, in terms of complementarity, most existing approaches only can find representations with single complementarity rather than complementary information with diversity. In this paper, to utilize both complementarity and consistency simultaneously, give free rein to the potential of deep learning in grasping diversity-promoting complementarity for multi-view representation learning, we propose a novel supervised multi-view representation learning algorithm, called Self-Attention Multi-View network with Diversity-Promoting Complementarity (SAMVDPC), which exploits the consistency by a group of encoders, uses self-attention to find complementary information entailing diversity. Extensive experiments conducted on eight real-world datasets have demonstrated the effectiveness of our proposed method, and show its superiority over several baseline methods, which only consider single complementary information."
2201.00360,Algebraic structure of path-independent quantum control,"['Wen-Long Ma', 'Shu-Shen Li', 'Liang Jiang']",ARXIV,http://arxiv.org/pdf/2201.00360v2,2022-01-02T14:13:14Z,2022-04-25T04:57:56Z,"['10.48550/arXiv.2201.00360', '10.1103/PhysRevResearch.4.023102']","Path-independent (PI) quantum control has recently been proposed to integrate quantum error correction and quantum control [Phys. Rev. Lett. 125, 110503 (2020)], achieving fault-tolerant quantum gates against ancilla errors. Here we reveal the underlying algebraic structure of PI quantum control. The PI Hamiltonians and propagators turn out to lie in an algebra isomorphic to the ordinary matrix algebra, which we call the PI matrix algebra. The PI matrix algebra, defined on the Hilbert space of a composite system (including an ancilla system and a central system), is isomorphic to the matrix algebra defined on the Hilbert space of the ancilla system. By extending the PI matrix algebra to the Hilbert-Schmidt space of the composite system, we provide an exact and unifying condition for PI quantum control against ancilla noise."
2201.00322,Superpotentials of D-branes in Calabi-Yau Manifolds with Several Moduli by Mirror Symmetry and Blown-up,"['Xuan Li', 'Yuan-Chun Jing', 'Fu-Zhong Yang']",ARXIV,http://arxiv.org/pdf/2201.00322v1,2022-01-02T09:06:35Z,2022-01-02T09:06:35Z,"['10.48550/arXiv.2201.00322', '10.1007/JHEP02(2022)203']","We study B-brane superpotentials depending on several closed- and open- moduli on Calabi-Yau hypersurfaces and complete intersections. By blowing up the ambient space along a curve wrapped by B-branes in a Calabi-Yau manifold, we obtain a blow-up new manifold and the period integral satisfying the GKZ-system. Via mirror symmetry to A-model, we calculate the superpotentials and extract Ooguri-Vafa invariants for concrete examples of several open-closed moduli in Calabi-Yau manifolds."
2201.00127,Extremal sequences related to the Jacobi symbol,"['Santanu Mondal', 'Krishnendu Paul', 'Shameek Paul']",ARXIV,http://arxiv.org/pdf/2201.00127v2,2022-01-01T06:17:29Z,2022-12-12T14:01:37Z,['10.48550/arXiv.2201.00127'],"For a weight-set $A\subseteq \mathbb Z_n$, the $A$-weighted zero-sum constant $C_A(n)$ is defined to be the smallest natural number $k$, such that any sequence of $k$ elements in $\mathbb Z_n$ has an $A$-weighted zero-sum subsequence of consecutive terms. A sequence of length $C_A(n)-1$ in $\mathbb Z_n$ which does not have any $A$-weighted zero-sum subsequence of consecutive terms will be called a $C$-extremal sequence for $A$. Let $\big(\frac{x}{n}\big)$ denote the Jacobi symbol of $x\in\mathbb Z_n$. We characterize the $C$-extremal sequences for the weight-set $S(n)=\big\{\,x\in U(n):\big(\frac{x}{n}\big)=1\,\big\}$ and for the weight-set $L(n;p)=\big\{\,x\in U(n):\big(\frac{x}{n}\big)=\big(\frac{x}{p}\big)\,\big\}$ where $p$ is a prime divisor of $n$. We can define $D$-extremal sequences for these weight-sets in a way analogous to the definition of $C$-extremal sequences. We also characterize these sequences."
2201.00355,Theory and Practice of Quality Assurance for Machine Learning Systems An Experiment Driven Approach,"['Samuel Ackerman', 'Guy Barash', 'Eitan Farchi', 'Orna Raz', 'Onn Shehory']",ARXIV,http://arxiv.org/pdf/2201.00355v2,2022-01-02T13:11:16Z,2022-04-12T07:37:52Z,['10.48550/arXiv.2201.00355'],"The crafting of machine learning (ML) based systems requires statistical control throughout its life cycle. Careful quantification of business requirements and identification of key factors that impact the business requirements reduces the risk of a project failure. The quantification of business requirements results in the definition of random variables representing the system key performance indicators that need to be analyzed through statistical experiments. In addition, available data for training and experiment results impact the design of the system. Once the system is developed, it is tested and continually monitored to ensure it meets its business requirements. This is done through the continued application of statistical experiments to analyze and control the key performance indicators. This book teaches the art of crafting and developing ML based systems. It advocates an ""experiment first"" approach stressing the need to define statistical experiments from the beginning of the project life cycle. It also discusses in detail how to apply statistical control on the ML based system throughout its lifecycle."
2201.00437,Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting: A Review,"['Ali Bou Nassif', 'Bassel Soudan', 'Mohammad Azzeh', 'Imtinan Attilli', 'Omar AlMulla']",ARXIV,http://arxiv.org/pdf/2201.00437v1,2021-12-29T07:44:42Z,2021-12-29T07:44:42Z,['10.48550/arXiv.2201.00437'],"Electrical utilities depend on short-term demand forecasting to proactively adjust production and distribution in anticipation of major variations. This systematic review analyzes 240 works published in scholarly journals between 2000 and 2019 that focus on applying Artificial Intelligence (AI), statistical, and hybrid models to short-term load forecasting (STLF). This work represents the most comprehensive review of works on this subject to date. A complete analysis of the literature is conducted to identify the most popular and accurate techniques as well as existing gaps. The findings show that although Artificial Neural Networks (ANN) continue to be the most commonly used standalone technique, researchers have been exceedingly opting for hybrid combinations of different techniques to leverage the combined advantages of individual methods. The review demonstrates that it is commonly possible with these hybrid combinations to achieve prediction accuracy exceeding 99%. The most successful duration for short-term forecasting has been identified as prediction for a duration of one day at an hourly interval. The review has identified a deficiency in access to datasets needed for training of the models. A significant gap has been identified in researching regions other than Asia, Europe, North America, and Australia."
2201.00275,Coloring the distance graphs,['Jindrich Zapletal'],ARXIV,http://arxiv.org/pdf/2201.00275v1,2022-01-02T02:29:15Z,2022-01-02T02:29:15Z,['10.48550/arXiv.2201.00275'],Let n>0 be a number. Let Gn be the graph on n-dimensional Euclidean space connecting points of rational distance. It is consistent with the choiceless theory ZF+DC that Gn has countable chromatic number yet Gn+1 does not.
2201.00111,Role of Data Augmentation Strategies in Knowledge Distillation for Wearable Sensor Data,"['Eun Som Jeon', 'Anirudh Som', 'Ankita Shukla', 'Kristina Hasanaj', 'Matthew P. Buman', 'Pavan Turaga']",ARXIV,http://arxiv.org/pdf/2201.00111v1,2022-01-01T04:40:14Z,2022-01-01T04:40:14Z,"['10.48550/arXiv.2201.00111', '10.1109/JIOT.2021.3139038']","Deep neural networks are parametrized by several thousands or millions of parameters, and have shown tremendous success in many classification problems. However, the large number of parameters makes it difficult to integrate these models into edge devices such as smartphones and wearable devices. To address this problem, knowledge distillation (KD) has been widely employed, that uses a pre-trained high capacity network to train a much smaller network, suitable for edge devices. In this paper, for the first time, we study the applicability and challenges of using KD for time-series data for wearable devices. Successful application of KD requires specific choices of data augmentation methods during training. However, it is not yet known if there exists a coherent strategy for choosing an augmentation approach during KD. In this paper, we report the results of a detailed study that compares and contrasts various common choices and some hybrid data augmentation strategies in KD based human activity analysis. Research in this area is often limited as there are not many comprehensive databases available in the public domain from wearable devices. Our study considers databases from small scale publicly available to one derived from a large scale interventional study into human activity and sedentary behavior. We find that the choice of data augmentation techniques during KD have a variable level of impact on end performance, and find that the optimal network choice as well as data augmentation strategies are specific to a dataset at hand. However, we also conclude with a general set of recommendations that can provide a strong baseline performance across databases."
2201.00212,"The Impact of Nitrogen Doping on Structural and Electronic Properties of Titanium Sesquioxide, Ti 2 O 3 : An ab-initio Study","['Lynet Allan', 'George O Amolo', 'Julius Mwabora', 'Silas Mureramanzi']",ARXIV,http://arxiv.org/pdf/2201.00212v1,2022-01-01T15:38:10Z,2022-01-01T15:38:10Z,['10.48550/arXiv.2201.00212'],"Titanium-based oxides are abundant, chemically stable, non-toxic, and highly versatile materials, with applications ranging from photovoltaics to catalysis. For rutile and anatase phases of Titanium dioxide (TiO2), the bandgap ranges from 3.0-3.2 eV, which are too large to absorb in the visible range (400 nm - 700 nm), resulting in poor photo-catalytic efficiency. Nitrogen doping into TiO2 has been able to narrow its bandgap, forming an absorption tail in the visible-light region. However, TiO2 has limits to which it can be doped, suggesting investigations of the oxygen-deficient Ti203. Using the state-of-the-art Density Functional Theory (DFT) as implemented in the Quantum ESPRESSO package, we report on the structural and electronic properties of corundum-type Ti2N20 (an example TinN2O2n-3 compound with n=2). The most stable sample of the oxynitride (Ti2N2O-P1), has a bandgap of 2.2 eV, which is clearly near the middle of the visible light part of the electromagnetic spectrum, and has no in-gap states, suggesting that they are more efficient visible-light-driven materials for photocatalytic applications compared to TiO2, TiO2: N and Ti2O3."
2201.00123,Tadpoles and vacuum bubbles in light-front quantization,"['Sophia S. Chabysheva', 'John R. Hiller']",ARXIV,http://arxiv.org/pdf/2201.00123v1,2022-01-01T05:24:21Z,2022-01-01T05:24:21Z,"['10.48550/arXiv.2201.00123', '10.1103/PhysRevD.105.116006']","We develop a method by which vacuum transitions may be included in light-front calculations. This allows tadpole contributions which are important for symmetry-breaking effects and yet are missing from standard light-front calculations. These transitions also dictate a nontrivial vacuum and contributions from vacuum bubbles to physical states. In nonperturbative calculations these separate classes of contributions (tadpoles and bubbles) cannot be filtered; instead, we regulate the bubbles and subtract the vacuum energy from the eigenenergy of physical states. The key is replacement of momentum-conserving delta functions with model functions of finite width; the width becomes the regulator and is removed after subtractions. The approach is illustrated in free scalar theory, quenched scalar Yukawa theory, and in a limited Fock-space truncation of $\phi^4$ theory."
2201.00300,A new combinatorial approach for edge universality of Wigner matrices,['Debapratim Banerjee'],ARXIV,http://arxiv.org/pdf/2201.00300v2,2022-01-02T06:01:04Z,2022-10-14T15:23:02Z,['10.48550/arXiv.2201.00300'],"In this paper we introduce a new combinatorial approach to analyze the trace of large powers of Wigner matrices. Our approach is motivated from the paper by \citet{sosh}. However the counting approach is different. We start with classical word sentence approach similar to \citet{AZ05} and take the motivation from \citet{sinaisosh}, \citet{sosh} and \citet{peche2009universality} to encode the words to objects similar to Dyck paths. To be precise the map takes a word to a Dyck path with some edges removed from it. Using this new counting we prove edge universality for large Wigner matrices with sub-Gaussian entries. One novelty of this approach is unlike \citet{sinaisosh}, \citet{sosh} and \citet{peche2009universality} we do not need to assume the entries of the matrices are symmetrically distributed around $0$. The main technical contribution of this paper is two folded. Firstly we produce an encoding of the ""contributing words"" (for definition one might look at Section \ref{sec:word}) of the Wigner matrix which retrieves the edge universality. Hence this is the best one can do. We hope this method will be applicable to many other scenarios in random matrices. Secondly in course of the paper we give a combinatorial description of the GOE Tracy Widom law. The explanation for GUE is very similar. This explanation might be important for the models where exact calculations are not available but some combinatorial structures are present."
2201.00177,Adaptive Image Inpainting,"['Maitreya Suin', 'Kuldeep Purohit', 'A. N. Rajagopalan']",ARXIV,http://arxiv.org/pdf/2201.00177v1,2022-01-01T12:16:01Z,2022-01-01T12:16:01Z,['10.48550/arXiv.2201.00177'],"Image inpainting methods have shown significant improvements by using deep neural networks recently. However, many of these techniques often create distorted structures or blurry textures inconsistent with surrounding areas. The problem is rooted in the encoder layers' ineffectiveness in building a complete and faithful embedding of the missing regions. To address this problem, two-stage approaches deploy two separate networks for a coarse and fine estimate of the inpainted image. Some approaches utilize handcrafted features like edges or contours to guide the reconstruction process. These methods suffer from huge computational overheads owing to multiple generator networks, limited ability of handcrafted features, and sub-optimal utilization of the information present in the ground truth. Motivated by these observations, we propose a distillation based approach for inpainting, where we provide direct feature level supervision for the encoder layers in an adaptive manner. We deploy cross and self distillation techniques and discuss the need for a dedicated completion-block in encoder to achieve the distillation target. We conduct extensive evaluations on multiple datasets to validate our method."
2201.00349,"Geometric Quantization: Particles, Fields and Strings","['David S Berman', 'Gabriel Cardoso']",ARXIV,http://arxiv.org/pdf/2201.00349v1,2022-01-02T12:48:36Z,2022-01-02T12:48:36Z,"['10.48550/arXiv.2201.00349', '10.1142/S0217751X22300022']","These notes present an introduction to the method of geometric quantization. We discuss the main theorems in a style suitable for a theoretical physicist with an eye towards the physical motivation and the interpretation of the geometric construction as providing a solution to Dirac's axioms of quantization. We provide in detail the examples of free relativistic particles, their corresponding quantum fields, and the bosonic string using formalism of double field theory. Based on lectures written by Gabriel Cardoso."
2201.00421,Symmetric states for $C^*$-Fermi systems I: De Finetti theorem,['Francesco Fidaleo'],ARXIV,http://arxiv.org/pdf/2201.00421v1,2022-01-02T21:34:18Z,2022-01-02T21:34:18Z,"['10.48550/arXiv.2201.00421', '10.1142/S0129055X22500301']","n the present note, which is the first part of a work concerning the study of the set of the symmetric states for Fermi systems, we describe the extension of the De Finetti theorem to the infinite Fermi $C^*$-tensor product of a single (separable) general $\bz^2$-graded $C^*$-algebra."
2201.00160,Employing Typicality in Optimal Control Theory,"['Aviv Aroch', 'Shimshon Kallush', 'Ronnie Kosloff']",ARXIV,http://arxiv.org/pdf/2201.00160v1,2022-01-01T10:36:56Z,2022-01-01T10:36:56Z,['10.48550/arXiv.2201.00160'],"Controlling the dynamics of quantum systems is a crucial task in quantum science and technology. Obtaining the driving field that transforms the quantum systems to its objective is a typical control task. This task is hard, scaling unfavorably with the size of Hilbert space. To tackle this issue we employ typicality to assist in finding the control field for such systems. To demonstrate the method we choose the control task of cooling the fine structure states of the AlF molecule, from relatively high temperatures which results in large Hilbert space. Using quantum typicality, we demonstrate that we can simulate an ensemble of states, enabling a control task addressing simultaneously many states. We employ this method to find a control field for cooling molecules with large number of internal sates, corresponding to high initial temperatures."
2201.00285,Applications of Gaussian Mutation for Self Adaptation in Evolutionary Genetic Algorithms,['Okezue Bell'],ARXIV,http://arxiv.org/pdf/2201.00285v2,2022-01-02T04:18:25Z,2022-01-05T06:52:18Z,['10.48550/arXiv.2201.00285'],"In recent years, optimization problems have become increasingly more prevalent due to the need for more powerful computational methods. With the more recent advent of technology such as artificial intelligence, new metaheuristics are needed that enhance the capabilities of classical algorithms. More recently, researchers have been looking at Charles Darwin's theory of natural selection and evolution as a means of enhancing current approaches using machine learning. In 1960, the first genetic algorithm was developed by John H. Holland and his student. We explore the mathematical intuition of the genetic algorithm in developing systems capable of evolving using Gaussian mutation, as well as its implications in solving optimization problems."
2201.00328,Implicit representation of sparse hereditary families,['Noga Alon'],ARXIV,http://arxiv.org/pdf/2201.00328v1,2022-01-02T09:57:25Z,2022-01-02T09:57:25Z,['10.48550/arXiv.2201.00328'],"For a hereditary family of graphs $\FF$, let $\FF_n$ denote the set of all members of $\FF$ on $n$ vertices. The speed of $\FF$ is the function $f(n)=|\FF_n|$. An implicit representation of size $\ell(n)$ for $\FF_n$ is a function assigning a label of $\ell(n)$ bits to each vertex of any given graph $G \in \FF_n$, so that the adjacency between any pair of vertices can be determined by their labels. Bonamy, Esperet, Groenland and Scott proved that the minimum possible size of an implicit representation of $\FF_n$ for any hereditary family $\FF$ with speed $2^{\Omega(n^2)}$ is $(1+o(1)) \log_2 |\FF_n|/n~(=\Theta(n))$. A recent result of Hatami and Hatami shows that the situation is very different for very sparse hereditary families. They showed that for every $\delta>0$ there are hereditary families of graphs with speed $2^{O(n \log n)}$ that do not admit implicit representations of size smaller than $n^{1/2-\delta}$. In this note we show that even a mild speed bound ensures an implicit representation of size $O(n^c)$ for some $c<1$. Specifically we prove that for every $\eps>0$ there is an integer $d \geq 1$ so that if $\FF$ is a hereditary family with speed $f(n) \leq 2^{(1/4-\eps)n^2}$ then $\FF_n$ admits an implicit representation of size $O(n^{1-1/d} \log n)$. Moreover, for every integer $d>1$ there is a hereditary family for which this is tight up to the logarithmic factor."
2201.00340,Electrochemically-driven insulator-metal transition in ionic-liquid-gated antiferromagnetic Mott-insulating NiS$_2$ single crystals,"['Sajna Hameed', 'Bryan Voigt', 'John Dewey', 'William Moore', 'Damjan Pelc', 'Bhaskar Das', 'Sami El-Khatib', 'Javier Garcia-Barriocanal', 'Bing Luo', 'Nick Seaton', 'Guichuan Yu', 'Chris Leighton', 'Martin Greven']",ARXIV,http://arxiv.org/pdf/2201.00340v1,2022-01-02T11:37:44Z,2022-01-02T11:37:44Z,['10.48550/arXiv.2201.00340'],"Motivated by the existence of superconductivity in pyrite-structure CuS$_2$, we explore the possibility of ionic-liquid-gating-induced superconductivity in the proximal antiferromagnetic Mott insulator NiS$_2$. A clear gating-induced transition from a two-dimensional insulating state to a three-dimensional metallic state is observed at positive gate bias on single crystal surfaces. No evidence for superconductivity is observed down to the lowest measured temperature of 0.45 K, however. Based on transport, energy-dispersive X-ray spectroscopy, X-ray photoelectron spectroscopy, atomic force microscopy, and other techniques, we deduce an electrochemical gating mechanism involving a substantial decrease in the S:Ni ratio (over hundreds of nm), which is both non-volatile and irreversible. This is in striking contrast to the reversible, volatile, surface-limited, electrostatic gate effect in pyrite FeS$_2$. We attribute this stark difference in electrochemical vs. electrostatic gating response in NiS$_2$ and FeS$_2$ to the much larger S diffusion coefficient in NiS$_2$, analogous to the different behaviors observed among electrolyte-gated oxides with differing O-vacancy diffusivities. The gating irreversibility, on the other hand, is associated with the lack of atmospheric S; this is in contrast to the better understood oxide case, where electrolysis of atmospheric H$_2$O provides an O reservoir. This study of NiS$_2$ thus provides new insight into electrolyte gating mechanisms in functional materials, in a previously unexplored limit."
2201.00269,IQDUBBING: Prosody modeling based on discrete self-supervised speech representation for expressive voice conversion,"['Wendong Gan', 'Bolong Wen', 'Ying Yan', 'Haitao Chen', 'Zhichao Wang', 'Hongqiang Du', 'Lei Xie', 'Kaixuan Guo', 'Hai Li']",ARXIV,http://arxiv.org/pdf/2201.00269v1,2022-01-02T01:22:38Z,2022-01-02T01:22:38Z,['10.48550/arXiv.2201.00269'],"Prosody modeling is important, but still challenging in expressive voice conversion. As prosody is difficult to model, and other factors, e.g., speaker, environment and content, which are entangled with prosody in speech, should be removed in prosody modeling. In this paper, we present IQDubbing to solve this problem for expressive voice conversion. To model prosody, we leverage the recent advances in discrete self-supervised speech representation (DSSR). Specifically, prosody vector is first extracted from pre-trained VQ-Wav2Vec model, where rich prosody information is embedded while most speaker and environment information are removed effectively by quantization. To further filter out the redundant information except prosody, such as content and partial speaker information, we propose two kinds of prosody filters to sample prosody from the prosody vector. Experiments show that IQDubbing is superior to baseline and comparison systems in terms of speech quality while maintaining prosody consistency and speaker similarity."
2201.00141,Isotropization and Complexity of Decoupled Solutions in Self-interacting Brans-Dicke Gravity,"['M. Sharif', 'Amal Majid']",ARXIV,http://arxiv.org/pdf/2201.00141v1,2022-01-01T07:40:24Z,2022-01-01T07:40:24Z,['10.48550/arXiv.2201.00141'],"The aim of this work is to formulate two new solutions by decoupling the field equations via a minimal geometric deformation in the context of self-interacting Brans-Dicke gravity. We introduce an extra source in the anisotropic fluid distribution to generate new analogs of existing solutions. The radial metric function is transformed to decouple the field equations into two sets such that each array corresponds to one source only. The system corresponding to the original matter distribution is specified by metric functions of well-behaved solutions. On the other hand, the second set is closed by imposing constraints on the additional matter source. For this purpose, we have applied the isotropization condition as well as vanishing complexity condition on the new source. Smooth matching of interior and exterior spacetimes at the junction provides values of the unknown constants. Interesting physical features of corresponding models are checked by employing the mass and radius of the star PSR J1614-2230. It is concluded that both extensions yield viable and stable models for certain values of the decoupling parameter."
2201.00102,Impact of fuel chemistry on the global consumption speed of large hydrocarbon fuel/air flames,"['Aaron J. Fillo', 'Jonathan Bonebrake', 'David L. Blunck']",ARXIV,http://arxiv.org/pdf/2201.00102v1,2022-01-01T03:07:37Z,2022-01-01T03:07:37Z,['10.48550/arXiv.2201.00102'],"Large hydrocarbon fuels are used for ground and air transportation and will be for the foreseeable future. Despite their extensive use, turbulent combustion of large hydrocarbon fuels, remains relatively poorly understood and difficult to predict. A key parameter when burning these fuels is the turbulent consumption speed; the velocity at which fuel and air are consumed through a turbulent flame front. Such information can be useful as a model input parameter and for validation of modeled results. In this study, turbulent consumption speeds were measured for three jet-like fuels using a premixed turbulent Bunsen burner. The burner was used to independently control turbulence intensity, unburned temperature, and equivalence ratio. Each fuel had similar heat releases (within 2%), laminar flame speeds (within 5-15 %), and adiabatic flame temperatures. Despite this similarity, for constant Re_D and turbulence intensity, A2 (i.e., jet-A) has the highest turbulent flame speeds and remains stable (i.e., without tip quenching) at lower {\phi} than the other fuels evaluated. In contrast the C1 fuel, which contains no aromatics, has the slowest turbulent flame speeds and exhibits tip quenching at higher {\phi} then the other fuels. C1 was the most sensitive to the influence of turbulence, as evidenced by this fuel having the largest ratio of turbulent to laminar flame speeds. The C1 fuel had the highest stretch sensitivity, in general, as indicated by calculated Markstein numbers. This work shows that turbulent flame speeds and tip stability of multi-component large hydrocarbon fuels can be sensitive to the chemical class of its components. The results from the current work indicate that caution may be needed when using alternative or surrogate fuels to replicate conventional fuels, especially if the alternative fuels are missing chemical classes of fuels that influence stretch sensitivities."
2201.00287,"Drug repurposing for SARS-COV-2: A high-throughput molecular docking, molecular dynamics, machine learning, & ab-initio study","['Jatin Kashyap', 'Dibakar Datta']",ARXIV,http://arxiv.org/pdf/2201.00287v3,2022-01-02T04:22:50Z,2022-04-07T03:52:06Z,"['10.48550/arXiv.2201.00287', '10.1007/s10853-022-07195-8']","A molecule of dimension 125nm has caused around 479 Million human infections (80M for the USA) & 6.1 Million human deaths (977,000 for the USA) worldwide and slashed the global economy by US$ 8.5 Trillion over two years. The only other events in recent history that caused comparative human life loss through direct usage (either by (wo)man or nature, respectively) of structure-property relations of 'nano-structures' (either (wo)man-made or nature, respectively) were nuclear bomb attacks of Japanese cities by the USA during World War II and 1918 Flu Pandemic. This molecule is SARS-CoV-2, which causes a disease known as COVID-19. The high liability cost of the pandemic had incentivized various private, government, and academic entities to work towards finding a cure for these & emerging diseases. As result, multiple vaccine candidates are discovered to avoid the infection in first place. But so far, there has been no success in finding fully effective therapeutics candidates. In this paper, we attempted to provide multiple therapy candidates based upon a sophisticated multi-scale in-silico framework. We have used the following robust framework to screen the ligands; Step-I: high throughput docking, Step-II: molecular dynamics, Step-III: density functional theory analysis. In total, we have analyzed 2.2 Million unique protein binding site/ligand combinations. The proteins were selected based on recent experimental studies. Step-I had filtered that number down to 10 ligands/protein based on molecular docking binding energy, further screening down to 2 ligands/protein based on drug-likeness analysis. Additionally, these two ligands/proteins were investigated in Step-II with a molecular dynamic based RMSD analysis. It finally suggested three ligands (ZINC1176619532, ZINC517580540, ZINC952855827) attacking different binding sites of the protein(7BV2), which were further analyzed in Step III."
2201.00286,Reinforcement Learning for Task Specifications with Action-Constraints,"['Arun Raman', 'Keerthan Shagrithaya', 'Shalabh Bhatnagar']",ARXIV,http://arxiv.org/pdf/2201.00286v1,2022-01-02T04:22:01Z,2022-01-02T04:22:01Z,['10.48550/arXiv.2201.00286'],"In this paper, we use concepts from supervisory control theory of discrete event systems to propose a method to learn optimal control policies for a finite-state Markov Decision Process (MDP) in which (only) certain sequences of actions are deemed unsafe (respectively safe). We assume that the set of action sequences that are deemed unsafe and/or safe are given in terms of a finite-state automaton; and propose a supervisor that disables a subset of actions at every state of the MDP so that the constraints on action sequence are satisfied. Then we present a version of the Q-learning algorithm for learning optimal policies in the presence of non-Markovian action-sequence and state constraints, where we use the development of reward machines to handle the state constraints. We illustrate the method using an example that captures the utility of automata-based methods for non-Markovian state and action specifications for reinforcement learning and show the results of simulations in this setting."
2201.00163,Development of Diabetic Foot Ulcer Datasets: An Overview,"['Moi Hoon Yap', 'Connah Kendrick', 'Neil D. Reeves', 'Manu Goyal', 'Joseph M. Pappachan', 'Bill Cassidy']",ARXIV,http://arxiv.org/pdf/2201.00163v1,2022-01-01T10:45:07Z,2022-01-01T10:45:07Z,['10.48550/arXiv.2201.00163'],"This paper provides conceptual foundation and procedures used in the development of diabetic foot ulcer datasets over the past decade, with a timeline to demonstrate progress. We conduct a survey on data capturing methods for foot photographs, an overview of research in developing private and public datasets, the related computer vision tasks (detection, segmentation and classification), the diabetic foot ulcer challenges and the future direction of the development of the datasets. We report the distribution of dataset users by country and year. Our aim is to share the technical challenges that we encountered together with good practices in dataset development, and provide motivation for other researchers to participate in data sharing in this domain."
2201.00388,Discrimination of dephasing channels,"['Milajiguli Rexiti', 'Laleh Memarzadeh', 'Stefano Mancini']",ARXIV,http://arxiv.org/pdf/2201.00388v2,2022-01-02T18:15:55Z,2022-05-26T07:12:48Z,"['10.48550/arXiv.2201.00388', '10.1088/1751-8121/ac6d2c']","The problem of dephasing channel discrimination is addressed for finite-dimensional systems. In particular, the optimization with respect to input states without energy constraint is solved analytically for qubit, qutrit and ququart. Additionally, it is shown that resorting to side entanglement assisted strategy is completely useless in this case."
2201.00149,Echo chambers in the Ising model and implications on the mean magnetization,"['Talia Baravi', 'Ofer Feinerman', 'Oren Raz']",ARXIV,http://arxiv.org/pdf/2201.00149v2,2022-01-01T08:50:58Z,2022-02-16T11:28:56Z,"['10.48550/arXiv.2201.00149', '10.1088/1742-5468/ac5d42']","The echo-chamber effect is a common term in opinion dynamic modeling to describe how a person's opinion might be artificially enhanced as it is reflected back at her through social interactions. Here, we study the existence of this effect in statistical mechanics models, which are commonly used to study opinion dynamics. We show that the Ising model does not exhibit echo-chambers, but this result is a consequence of a special symmetry. We then distinguish between three types of models: (i) those with a strong echo-chamber symmetry, that have no echo-chambers at all; (ii) those with a weak echo-chamber symmetry that can exhibit echo-chambers but only if there are external fields in the system, and (iii) models without echo-chamber symmetry that generically have echo-chambers. We use these results to construct an efficient algorithm to efficiently and precisely calculate magnetization in arbitrary tree networks. Finally, We apply this algorithm to study two systems: phase transitions in the random field Ising model on a Bethe lattice and the influence optimization problem in social networks."
2201.00157,Contact surgery numbers,"['John Etnyre', 'Marc Kegel', 'Sinem Onaran']",ARXIV,http://arxiv.org/pdf/2201.00157v2,2022-01-01T10:21:22Z,2023-04-27T10:17:10Z,['10.48550/arXiv.2201.00157'],"It is known that any contact 3-manifold can be obtained by rational contact Dehn surgery along a Legendrian link L in the standard tight contact 3-sphere. We define and study various versions of contact surgery numbers, the minimal number of components of a surgery link L describing a given contact 3-manifold under consideration. In the first part of the paper, we relate contact surgery numbers to other invariants in terms of various inequalities. In particular, we show that the contact surgery number of a contact manifold is bounded from above by the topological surgery number of the underlying topological manifold plus three. In the second part, we compute contact surgery numbers of all contact structures on the 3-sphere. Moreover, we completely classify the contact structures with contact surgery number one on $S^1\times S^2$, the Poincar\'e homology sphere, and the Brieskorn sphere $\Sigma(2,3,7)$. We conclude that there exist infinitely many non-isotopic contact structures on each of the above manifolds which cannot be obtained by a single rational contact surgery from the standard tight contact $3$-sphere. We further obtain results for the 3-torus and lens spaces. As one ingredient of the proofs of the above results we generalize computations of the homotopical invariants of contact structures to contact surgeries with more general surgery coefficients which might be of independent interest."
2201.00416,A Generalized RSK for Enumerating Linear Series on $n$-pointed Curves,"['Maria Gillespie', 'Andrew Reimer-Berg']",ARXIV,http://arxiv.org/pdf/2201.00416v1,2022-01-02T20:53:39Z,2022-01-02T20:53:39Z,['10.48550/arXiv.2201.00416'],"We give a combinatorial proof of a recent geometric result of Farkas and Lian on linear series on curves with prescribed incidence conditions. The result states that the expected number of degree-$d$ morphisms from a general genus $g$, $n$-marked curve $C$ to $\mathbb{P}^r$, sending the marked points on $C$ to specified general points in $\mathbb{P}^r$, is equal to $(r+1)^g$ for sufficiently large $d$. This computation may be rephrased as an intersection problem on Grassmannians, which has a natural combinatorial interpretation in terms of Young tableaux by the classical Littlewood-Richardson rule. We give a bijection, generalizing the well-known RSK correspondence, between the tableaux in question and the $(r+1)$-ary sequences of length $g$, and we explore our bijection's combinatorial properties. We also apply similar methods to give a combinatorial interpretation and proof of the fact that, in the modified setting in which $r=1$ and several marked points map to the same point in $\mathbb{P}^1$, the number of morphisms is still $2^g$ for sufficiently large $d$."
2201.00186,Maximum size of digraphs of given radius,['Stijn Cambie'],ARXIV,http://arxiv.org/pdf/2201.00186v2,2022-01-01T13:09:30Z,2022-04-18T17:50:40Z,['10.48550/arXiv.2201.00186'],"In $1967$, Vizing determined the maximum size of a graph with given order and radius. In $1973$, Fridman answered the same question for digraphs with given order and outradius. We investigate that question when restricting to biconnected digraphs. Biconnected digraphs are the digraphs with a finite total distance and hence the interesting ones, as we want to note a connection between minimizing the total distance and maximizing the size under the same constraints. We characterize the extremal digraphs maximizing the size among all biconnected digraphs of order $n$ and outradius $3$, as well as when the order is sufficiently large compared to the outradius. As such, we solve a problem of Dankelmann asymptotically. We also consider these questions for bipartite digraphs and solve a second problem of Dankelmann partially."
2201.00310,On a family of elliptic curves of rank at least $2$,"['Kalyan Chakraborty', 'Richa Sharma']",ARXIV,http://arxiv.org/pdf/2201.00310v1,2022-01-02T07:02:36Z,2022-01-02T07:02:36Z,['10.48550/arXiv.2201.00310'],"Let $C_{m} : y^{2} = x^{3} - m^{2}x +p^{2}q^{2}$ be a family of elliptic curves over $\mathbb{Q}$, where $m$ is a positive integer and $p, q$ are distinct odd primes. We study the torsion part and the rank of $C_m(\mathbb{Q})$. More specifically, we prove that the torsion subgroup of $C_{m}(\mathbb{Q})$ is trivial and the $\mathbb{Q}$-rank of this family is at least $2$, whenever $m \not \equiv 0 \pmod 4$ and $m \equiv 2 \pmod {64}$ with neither $p$ nor $q$ divides $m$."
2201.00254,Subfield prestige and gender inequality in computing,"['Nicholas LaBerge', 'K. Hunter Wapman', 'Allison C. Morgan', 'Sam Zhang', 'Daniel B. Larremore', 'Aaron Clauset']",ARXIV,http://arxiv.org/pdf/2201.00254v2,2022-01-01T23:00:32Z,2022-05-09T19:28:00Z,['10.48550/arXiv.2201.00254'],"Women and people of color remain dramatically underrepresented among computing faculty, and improvements in demographic diversity are slow and uneven. Effective diversification strategies depend on quantifying the correlates, causes, and trends of diversity in the field. But field-level demographic changes are driven by subfield hiring dynamics because faculty searches are typically at the subfield level. Here, we quantify and forecast variations in the demographic composition of the subfields of computing using a comprehensive database of training and employment records for 6882 tenure-track faculty from 269 PhD-granting computing departments in the United States, linked with 327,969 publications. We find that subfield prestige correlates with gender inequality, such that faculty working in computing subfields with more women tend to hold positions at less prestigious institutions. In contrast, we find no significant evidence of racial or socioeconomic differences by subfield. Tracking representation over time, we find steady progress toward gender equality in all subfields, but more prestigious subfields tend to be roughly 25 years behind the less prestigious subfields in gender representation. These results illustrate how the choice of subfield in a faculty search can shape a department's gender diversity."
2201.00146,Discovery of subdiffusion problem with noisy data via deep learning,"['Xingjian Xu', 'Minghua Chen']",ARXIV,http://arxiv.org/pdf/2201.00146v1,2022-01-01T08:18:35Z,2022-01-01T08:18:35Z,['10.48550/arXiv.2201.00146'],"Data-driven discovery of partial differential equations (PDEs) from observed data in machine learning has been developed by embedding the discovery problem. Recently, the discovery of traditional ODEs dynamics using linear multistep methods in deep learning have been discussed in [Racheal and Du, SIAM J. Numer. Anal. 59 (2021) 429-455; Du et al. arXiv:2103.11488]. We extend this framework to the data-driven discovery of the time-fractional PDEs, which can effectively characterize the ubiquitous power-law phenomena. In this paper, identifying source function of subdiffusion with noisy data using L1 approximation in deep neural network is presented. In particular, two types of networks for improving the generalization of the subdiffusion problem are designed with noisy data. The numerical experiments are given to illustrate the availability using deep learning. To the best of our knowledge, this is the first topic on the discovery of subdiffusion in deep learning with noisy data."
2201.00292,Fair Data Representation for Machine Learning at the Pareto Frontier,"['Shizhou Xu', 'Thomas Strohmer']",ARXIV,http://arxiv.org/pdf/2201.00292v4,2022-01-02T05:05:26Z,2023-11-24T15:06:36Z,['10.48550/arXiv.2201.00292'],"As machine learning powered decision-making becomes increasingly important in our daily lives, it is imperative to strive for fairness in the underlying data processing. We propose a pre-processing algorithm for fair data representation via which supervised learning results in estimations of the Pareto frontier between prediction error and statistical disparity. Particularly, the present work applies the optimal affine transport to approach the post-processing Wasserstein-2 barycenter characterization of the optimal fair $L^2$-objective supervised learning via a pre-processing data deformation. Furthermore, we show that the Wasserstein-2 geodesics from the conditional (on sensitive information) distributions of the learning outcome to their barycenter characterizes the Pareto frontier between $L^2$-loss and the average pairwise Wasserstein-2 distance among sensitive groups on the learning outcome. Numerical simulations underscore the advantages: (1) the pre-processing step is compositive with arbitrary conditional expectation estimation supervised learning methods and unseen data; (2) the fair representation protects the sensitive information by limiting the inference capability of the remaining data with respect to the sensitive data; (3) the optimal affine maps are computationally efficient even for high-dimensional data."
2201.00129,A Surrogate-Assisted Controller for Expensive Evolutionary Reinforcement Learning,"['Yuxing Wang', 'Tiantian Zhang', 'Yongzhe Chang', 'Bin Liang', 'Xueqian Wang', 'Bo Yuan']",ARXIV,http://arxiv.org/pdf/2201.00129v2,2022-01-01T06:42:51Z,2022-04-27T15:30:26Z,"['10.48550/arXiv.2201.00129', '10.1016/j.ins.2022.10.134']","The integration of Reinforcement Learning (RL) and Evolutionary Algorithms (EAs) aims at simultaneously exploiting the sample efficiency as well as the diversity and robustness of the two paradigms. Recently, hybrid learning frameworks based on this principle have achieved great success in various challenging robot control tasks. However, in these methods, policies from the genetic population are evaluated via interactions with the real environments, limiting their applicability in computationally expensive problems. In this work, we propose Surrogate-assisted Controller (SC), a novel and efficient module that can be integrated into existing frameworks to alleviate the computational burden of EAs by partially replacing the expensive policy evaluation. The key challenge in applying this module is to prevent the optimization process from being misled by the possible false minima introduced by the surrogate. To address this issue, we present two strategies for SC to control the workflow of hybrid frameworks. Experiments on six continuous control tasks from the OpenAI Gym platform show that SC can not only significantly reduce the cost of fitness evaluations, but also boost the performance of the original hybrid frameworks with collaborative learning and evolutionary processes."
2201.00393,ros2_tracing: Multipurpose Low-Overhead Framework for Real-Time Tracing of ROS 2,"['Christophe Bédard', 'Ingo Lütkebohle', 'Michel Dagenais']",ARXIV,http://arxiv.org/pdf/2201.00393v4,2022-01-02T19:03:24Z,2022-07-30T20:52:44Z,"['10.48550/arXiv.2201.00393', '10.1109/LRA.2022.3174346']","Testing and debugging have become major obstacles for robot software development, because of high system complexity and dynamic environments. Standard, middleware-based data recording does not provide sufficient information on internal computation and performance bottlenecks. Other existing methods also target very specific problems and thus cannot be used for multipurpose analysis. Moreover, they are not suitable for real-time applications. In this paper, we present ros2_tracing, a collection of flexible tracing tools and multipurpose instrumentation for ROS 2. It allows collecting runtime execution information on real-time distributed systems, using the low-overhead LTTng tracer. Tools also integrate tracing into the invaluable ROS 2 orchestration system and other usability tools. A message latency experiment shows that the end-to-end message latency overhead, when enabling all ROS 2 instrumentation, is on average 0.0033 ms, which we believe is suitable for production real-time systems. ROS 2 execution information obtained using ros2_tracing can be combined with trace data from the operating system, enabling a wider range of precise analyses, that help understand an application execution, to find the cause of performance bottlenecks and other issues. The source code is available at: https://github.com/ros2/ros2_tracing."
2201.00476,On invariant of the regularity index of fat points,['Phan Van Thien'],ARXIV,http://arxiv.org/pdf/2201.00476v1,2022-01-03T05:07:49Z,2022-01-03T05:07:49Z,['10.48550/arXiv.2201.00476'],"We prove invariant of the regularity index of fat points under changes of the linear subspace containing the support of the fat points. Then we show that Segre's bound is attained by any set of s non-degenerate equimultiple fat points in $\mathbb P^n$, $s\le n+3$. We also give an example showing that there always exists a set of n+4 non-degenerate equimultiple fat points in $\mathbb P^n$ such that Segre's bound is not attained."
2201.00227,Deep Learning Applications for Lung Cancer Diagnosis: A systematic review,"['Hesamoddin Hosseini', 'Reza Monsefi', 'Shabnam Shadroo']",ARXIV,http://arxiv.org/pdf/2201.00227v1,2022-01-01T18:29:11Z,2022-01-01T18:29:11Z,['10.48550/arXiv.2201.00227'],"Lung cancer has been one of the most prevalent disease in recent years. According to the research of this field, more than 200,000 cases are identified each year in the US. Uncontrolled multiplication and growth of the lung cells result in malignant tumour formation. Recently, deep learning algorithms, especially Convolutional Neural Networks (CNN), have become a superior way to automatically diagnose disease. The purpose of this article is to review different models that lead to different accuracy and sensitivity in the diagnosis of early-stage lung cancer and to help physicians and researchers in this field. The main purpose of this work is to identify the challenges that exist in lung cancer based on deep learning. The survey is systematically written that combines regular mapping and literature review to review 32 conference and journal articles in the field from 2016 to 2021. After analysing and reviewing the articles, the questions raised in the articles are being answered. This research is superior to other review articles in this field due to the complete review of relevant articles and systematic write up."
2201.00131,Direct determination of entanglement monotones for arbitrary dimensional bipartite states using statistical correlators and one set of complementary measurements,"['Debadrita Ghosh', 'Thomas Jennewein', 'Urbasi Sinha']",ARXIV,http://arxiv.org/pdf/2201.00131v1,2022-01-01T06:50:40Z,2022-01-01T06:50:40Z,['10.48550/arXiv.2201.00131'],"Higher dimensional quantum systems (qudits) present a potentially more efficient means, compared to qubits, for implementing various information theoretic tasks. One of the ubiquitous resources in such explorations is entanglement. Entanglement Monotones (EMs) are of key importance, particularly for assessing the efficacy of a given entangled state as a resource for information theoretic tasks. Till date, investigations towards determination of EMs have focused on providing their tighter lower bounds. There is yet no general scheme available for direct determination of the EMs. Consequently, an empirical determination of any EM has not yet been achieved for entangled qudit states. The present paper fills this gap, both theoretically as well as experimentally. First, we derive analytical relations between statistical correlation measures i.e. Mutual Predictability (MP), Mutual Information (MI) and Pearson Correlation Coefficient (PCC) and standard EMs i.e. Negativity (N) and Entanglement of Formation (EOF) in arbitrary dimensions. As a proof of concept, we then experimentally measure MP, MI and PCC of two-qutrit pure states and determine their N and EOF using these derived relations. This is a useful addition to the experimenter's toolkit wherein by using a limited number of measurements (in this case 1 set of measurements), one can directly measure the EMs in a bipartite arbitrary dimensional system. We obtain the value of N for our bipartite qutrit to be 0.907 $\pm$ 0.013 and the EOF to be 1.323 $\pm$ 0.022. Since the present scheme enables determination of more than one entanglement monotone by the same limited number of measurements, we argue that it can serve as a unique experimental platform for quantitatively comparing and contrasting the operational implications of entanglement monotones as well as showing their non-monotonicity for a given bipartire pure qudit state."
2201.00202,Possible early universe signals in proton collisions at the Large Hadron Collider,"['Raghunath Sahoo', 'Tapan Kumar Nayak']",ARXIV,http://arxiv.org/pdf/2201.00202v1,2022-01-01T15:03:58Z,2022-01-01T15:03:58Z,"['10.48550/arXiv.2201.00202', '10.18520/cs/v121/i11/1403-1408']","Our universe was born about 13.8 billion years ago from an extremely hot and dense singular point, in a process known as the Big Bang. The hot and dense matter which dominated the system within a few microseconds of its birth was in the form of a soup of elementary quarks and gluons, known as the quark-gluon plasma (QGP). Signatures compatible with the formation of the QGP matter have experimentally been observed in heavy-ion (such as Au or Pb) collisions at ultra-relativistic energies. Recently, experimental data of proton-proton (pp) collisions at the CERN Large Hadron Collider (LHC) have also shown signals resembling those of the QGP formation, which made these studies quite stimulating as to how the collision of small systems features in producing the early universe signals. In this article, we report on some of the compelling experimental results and give an account of the present understanding. We review the pp physics program at the LHC and discuss future prospects in the context of exploring the nature of the primordial matter in the early universe."
2201.00377,Parkour Spot ID: Feature Matching in Satellite and Street view images using Deep Learning,"['João Morais', 'Kaushal Rathi', 'Bhuvaneshwar Mohan', 'Shantanu Rajesh']",ARXIV,http://arxiv.org/pdf/2201.00377v1,2022-01-02T16:55:00Z,2022-01-02T16:55:00Z,['10.48550/arXiv.2201.00377'],"How to find places that are not indexed by Google Maps? We propose an intuitive method and framework to locate places based on their distinctive spatial features. The method uses satellite and street view images in machine vision approaches to classify locations. If we can classify locations, we just need to repeat for non-overlapping locations in our area of interest. We assess the proposed system in finding Parkour spots in the campus of Arizona State University. The results are very satisfactory, having found more than 25 new Parkour spots, with a rate of true positives above 60%."
2201.00398,An elementary approach to local combinatorial formulae for the Euler class of a PL spherical fiber bundle,['Gaiane Panina'],ARXIV,http://arxiv.org/pdf/2201.00398v2,2022-01-02T19:30:00Z,2022-01-30T08:14:14Z,['10.48550/arXiv.2201.00398'],"We present an elementary approach to local combinatorial formulae for the Euler class of a fiber-oriented triangulated spherical fiber bundle. The approach is based on sections averaging technique and very basic knowledge of simplicial (co)homology theory. Our formulae are close relatives of those by N. Mn\""{e}v."
2201.00294,Exploring Native Atomic Defects in NiTe2,"['Wen-Xiao Wang', 'Kaihui Li', 'Xiaoshan Dong', 'Hao Xie', 'Jinglan Qiu', 'Chunqiang Xu', 'Kai Liu', 'Juntao Song', 'Yi-Wen Wei', 'Ke-Ke Bai', 'Xiaofeng Xu', 'Ying Liu']",ARXIV,http://arxiv.org/pdf/2201.00294v1,2022-01-02T05:16:37Z,2022-01-02T05:16:37Z,['10.48550/arXiv.2201.00294'],"Nickel ditelluride (NiTe2), a new discovered type-II Dirac semimetal whose Dirac node lies close to its Fermi level, is expected to exhibit exotic phenomena including Lifshitz transition and superconductivity. As we know, defects are inevitable for transition metal dichalcogenides and have significant impacts on the optical and electronic properties. However, the systematic study of defects in NiTe2 is still lack. Here, by using high-resolution scanning tunneling microscopy combined with first-principles calculations, the point defects including the vacancy, intercalation and antisite defects in NiTe2 are systematically investigated. We identified five main types native defects and revealed that the growth condition could affect the type of native defects. By controlling the ratio of ingredient during synthesis, the types of point defects are expected to be manipulated, especially antisite defects. Additionally, we find native defects could slightly dope the topological surface states. Our results provide a facile way to manipulate defects for future optimizing the electronic properties of NiTe2 and other related materials."
2201.00223,They Still Haven't Told You,['Bruce Knuteson'],ARXIV,http://arxiv.org/pdf/2201.00223v1,2022-01-01T17:55:44Z,2022-01-01T17:55:44Z,['10.48550/arXiv.2201.00223'],"The world's stock markets display a decades-long pattern of overnight and intraday returns seemingly consistent with only one explanation: one or more large, long-lived quant firms tending to expand its portfolio early in the day (when its trading moves prices more) and contract its portfolio later in the day (when its trading moves prices less), losing money on its daily round-trip trades to create mark-to-market gains on its large existing book. In the fourteen years since this extraordinary pattern of overnight and intraday returns was first noted in the literature, no plausible alternative explanation has been advanced. The main question remaining is therefore which of the few firms capable of profitably trading in this manner are guilty of having done so. If any of this is news to you, it is because the people you trust to alert you to such problems still haven't told you."
2201.00375,Ferrihydrite nanoparticles entrapped in shear-induced multilamellar vesicles,['Luigi Gentile'],ARXIV,http://arxiv.org/pdf/2201.00375v1,2022-01-02T16:35:37Z,2022-01-02T16:35:37Z,"['10.48550/arXiv.2201.00375', '10.1016/j.jcis.2021.09.192']","Hypothesis Ferrihydrite (Fh) nanoparticles are receiving considerable scientific interest due to their large reactive surface areas, crystalline structures, and nanoparticle morphology. They are of great importance in biogeochemical processes and have the ability to sequester hazardous and toxic substances. Here, the working hypothesis was to entrap fractal-like Fh nanoparticles, with a radius of gyration of 6.2 nm and a primary building block of polydisperse spheres with a radius of 0.8 nm, in a shear-induced multilamellar vesicle (MLV) state using a 40 wt.% polyethylene glycol dodecyl ether surfactant. Experiments Small- and Wide- Angle X-ray scattering revealed the equilibrium state of the non-ionic planar lamellar phase, the Fh dispersion, and their mixture. The MLV state was induced by using a shear flow in a Taylor-Couette geometry of a rheometer. Findings The nonionic surfactant initially exhibited a lamellar gel phase with two distinct d-spacings of 11.0 and 9.7 nm, which collapsed into the MLV state under shear flow. The Fh nanoparticles induced bilayer attraction by suppressing lamellar layer undulations, decreasing the d-spacing. These results are helpful in the understanding of the relationship between nanoparticle size and nanoparticle-bilayers interactions and provides insight on Fh encapsulations in a kinetically stable MLVs state."
2201.00324,Rank $1$ perturbations in random matrix theory -- a review of exact results,['Peter J. Forrester'],ARXIV,http://arxiv.org/pdf/2201.00324v2,2022-01-02T09:20:28Z,2022-01-21T04:46:47Z,['10.48550/arXiv.2201.00324'],"A number of random matrix ensembles permitting exact determination of their eigenvalue and eigenvector statistics maintain this property under a rank $1$ perturbation. Considered in this review are the additive rank $1$ perturbation of the Hermitian Gaussian ensembles, the multiplicative rank $1$ perturbation of the Wishart ensembles, and rank $1$ perturbations of Hermitian and unitary matrices giving rise to a two-dimensional support for the eigenvalues. The focus throughout is on exact formulas, which are typically the result of various integrable structures. The simplest is that of a determinantal point process, with others relating to partial differential equations implied by a formulation in terms of certain random tridiagonal matrices. Attention is also given to eigenvector overlaps in the setting of a rank $1$ perturbation."
2201.00224,An angular rainbow of light from curved spacetime,['Alexei A. Deriglazov'],ARXIV,http://arxiv.org/pdf/2201.00224v2,2022-01-01T17:58:54Z,2022-01-06T23:51:28Z,"['10.48550/arXiv.2201.00224', '10.1016/j.physleta.2021.127915']","We try to go beyond the geometrical optics approximation, by showing that a massless polarized particle allows a wide class of non minimal interactions with an arbitrary gravitational field. One specific example of a curvature-dependent interaction is presented, that results in a frequency-dependent Faraday effect. Even in a Schwarzschild spacetime, this leads to the angular dispersion of polarization planes for a linearly-polarized beam of waves with different frequencies, propagating along the same ray."
2201.00262,On automatic differentiation for the Matérn covariance,"['Oana Marin', 'Christopher Geoga', 'Michel Schanen']",ARXIV,http://arxiv.org/pdf/2201.00262v1,2022-01-01T23:34:54Z,2022-01-01T23:34:54Z,['10.48550/arXiv.2201.00262'],"To target challenges in differentiable optimization we analyze and propose strategies for derivatives of the Mat\'ern kernel with respect to the smoothness parameter. This problem is of high interest in Gaussian processes modelling due to the lack of robust derivatives of the modified Bessel function of second kind with respect to order. In the current work we focus on newly identified series expansions for the modified Bessel function of second kind valid for complex orders. Using these expansions we obtain highly accurate results using the complex step method. Furthermore, we show that the evaluations using the recommended expansions are also more efficient than finite differences."
2201.00438,Exact scalar (quasi-)normal modes of black holes and solitons in gauged SUGRA,"['Monserrat Aguayo', 'Ankai Hernández', 'José Mena', 'Julio Oliva', 'Marcelo Oyarzo']",ARXIV,http://arxiv.org/pdf/2201.00438v1,2022-01-03T00:01:37Z,2022-01-03T00:01:37Z,"['10.48550/arXiv.2201.00438', '10.1007/JHEP07(2022)021']","In this paper we identify a new family of black holes and solitons that lead to the exact integration of scalar probes, even in the presence of a non-minimal coupling with the Ricci scalar which has a non-trivial profile. The backgrounds are planar and spherical black holes as well as solitons of $SU\left( 2\right) \times SU\left( 2\right) $ $\mathcal{N}=4$ gauged supergravity in four dimensions. On these geometries, we compute the spectrum of (quasi-)normal modes for the non-minimally coupled scalar field. We find that the equation for the radial dependence can be integrated in terms of hypergeometric functions leading to an exact expression for the frequencies. The solutions do not asymptote to a constant curvature spacetime, nevertheless the asymptotic region acquires an extra conformal Killing vector. For the black hole, the scalar probe is purely ingoing at the horizon, and requiring that the solutions lead to an extremum of the action principle we impose a Dirichlet boundary condition at infinity. Surprisingly, the quasinormal modes do not depend on the radius of the black hole, therefore this family of geometries can be interpreted as isospectral in what regards to the wave operator non-minimally coupled to the Ricci scalar. We find both purely damped modes, as well as exponentially growing unstable modes depending on the values of the non-minimal coupling parameter. For the solitons we show that the same integrability property is achieved separately in a non-supersymmetric solutions as well as for the supersymmetric one. Imposing regularity at the origin and a well defined extremum for the action principle we obtain the spectra that can also lead to purely oscillatory modes as well as to unstable scalar probes, depending on the values of the non-minimal coupling."
2201.00206,Learning Free Gait Transition for Quadruped Robots via Phase-Guided Controller,"['Yecheng Shao', 'Yongbin Jin', 'Xianwei Liu', 'Weiyan He', 'Hongtao Wang', 'Wei Yang']",ARXIV,http://arxiv.org/pdf/2201.00206v1,2022-01-01T15:15:42Z,2022-01-01T15:15:42Z,"['10.48550/arXiv.2201.00206', '10.1109/LRA.2021.3136645']","Gaits and transitions are key components in legged locomotion. For legged robots, describing and reproducing gaits as well as transitions remain longstanding challenges. Reinforcement learning has become a powerful tool to formulate controllers for legged robots. Learning multiple gaits and transitions, nevertheless, is related to the multi-task learning problems. In this work, we present a novel framework for training a simple control policy for a quadruped robot to locomote in various gaits. Four independent phases are used as the interface between the gait generator and the control policy, which characterizes the movement of four feet. Guided by the phases, the quadruped robot is able to locomote according to the generated gaits, such as walk, trot, pacing and bounding, and to make transitions among those gaits. More general phases can be used to generate complex gaits, such as mixed rhythmic dancing. With the control policy, the Black Panther robot, a medium-dog-sized quadruped robot, can perform all learned motor skills while following the velocity commands smoothly and robustly in natural environment."
2201.00366,Monogamy of quantum entanglement,"['Xiao-Lan Zong', 'Hao-Hao Yin', 'Wei Song', 'Zhuo-Liang Cao']",ARXIV,http://arxiv.org/pdf/2201.00366v3,2022-01-02T15:03:56Z,2022-06-18T15:47:44Z,"['10.48550/arXiv.2201.00366', '10.3389/fphy.2022.880560']","Unlike classical correlation, quantum entanglement cannot be freely shared among many parties. This restricted shareability of entanglement among multi-party systems is known as monogamy of entanglement, which is one of the most fundamental properties of entanglement. Here, we summarize recent theoretical progress in the field of monogamy of entanglement. We firstly review the standard CKW-type monogamy inequalities in terms of various entanglement measures. In particular, the squashed entanglement and one-way distillable entanglement are monogamous for arbitrary dimensional systems. We then introduce some generalized version of monogamy inequalities which extend and sharpen the traditional ones. We also consider the dual polygamy inequalities for multi-party systems. Moreover, we present two new definitions to define monogamy of entanglement. Finally, some challenges and future directions for monogamy of entanglement are highlighted."
2201.00290,Develop of a Pneumatic Force Sensor Prototype,"['Luis Alarcon', 'Job Ledezma']",ARXIV,http://arxiv.org/pdf/2201.00290v1,2022-01-02T05:03:10Z,2022-01-02T05:03:10Z,['10.48550/arXiv.2201.00290'],"One of the difficulties of applying a SEA force control is the complexity that exists when implementing its three main components, which must work together one after the other. To facilitate the implementation of a force control by SEA, in this thesis the pneumatic force sensor is developed. A pneumatic force sensor differs from other force sensors in that it can work as a force sensor and as an elastic element. These features facilitate the implementation of force control by SEA, by reducing the number of components required. On the other hand, the pneumatic force sensor has reduced proportions to facilitate its installation in manipulator robots and biomechatronic prostheses. The first step that was made for the development of the pneumatic force sensor was the construction of the mathematical model of the sensor, to later use the MATLAB / Simulink software to simulate it. With the data obtained from the simulation of the mathematical model, the CAD model and the sensor planes were developed in SolidWorks software. Subsequently, the prototype of the pneumatic force sensor was built based on the plans made in the SolidWorks software. Once the stage of construction of the pneumatic force sensor was completed, the calibration and classification of the force sensor was carried out based on the UNE-EN ISO 376 standard, and the experimental tests were carried out to validate the sensor. Once the classification of the pneumatic force sensor was obtained, the results of the simulation of the mathematical model were compared with the results of the experimental test. vi In the comparison, it was possible to show a graphic coherence in the results obtained, validating the pneumatic force sensor system."
2201.00411,"The Introspective Agent: Interdependence of Strategy, Physiology, and Sensing for Embodied Agents","['Sarah Pratt', 'Luca Weihs', 'Ali Farhadi']",ARXIV,http://arxiv.org/pdf/2201.00411v1,2022-01-02T20:14:01Z,2022-01-02T20:14:01Z,['10.48550/arXiv.2201.00411'],"The last few years have witnessed substantial progress in the field of embodied AI where artificial agents, mirroring biological counterparts, are now able to learn from interaction to accomplish complex tasks. Despite this success, biological organisms still hold one large advantage over these simulated agents: adaptation. While both living and simulated agents make decisions to achieve goals (strategy), biological organisms have evolved to understand their environment (sensing) and respond to it (physiology). The net gain of these factors depends on the environment, and organisms have adapted accordingly. For example, in a low vision aquatic environment some fish have evolved specific neurons which offer a predictable, but incredibly rapid, strategy to escape from predators. Mammals have lost these reactive systems, but they have a much larger fields of view and brain circuitry capable of understanding many future possibilities. While traditional embodied agents manipulate an environment to best achieve a goal, we argue for an introspective agent, which considers its own abilities in the context of its environment. We show that different environments yield vastly different optimal designs, and increasing long-term planning is often far less beneficial than other improvements, such as increased physical ability. We present these findings to broaden the definition of improvement in embodied AI passed increasingly complex models. Just as in nature, we hope to reframe strategy as one tool, among many, to succeed in an environment. Code is available at: https://github.com/sarahpratt/introspective."
2201.00376,Charged Lepton Flavor Violation at the High-Energy Colliders: Neutrino Mass Relevant Particles,['Yongchao Zhang'],ARXIV,http://arxiv.org/pdf/2201.00376v2,2022-01-02T16:44:12Z,2022-03-16T13:54:15Z,"['10.48550/arXiv.2201.00376', '10.3390/universe8030164']","We summarize the potential charged lepton flavor violation (LFV) from neutrino mass relevant models, for instance the seesaw mechanisms. In particular, we study, in a model-dependent way, the LFV signals at the high-energy hadron and lepton colliders originating from the beyond standard model (BSM) neutral scalar $H$, doubly charged scalar $H^{\pm\pm}$, heavy neutrino $N$, heavy $W_R$ boson, and the $Z'$ boson. For the neutral scalar, doubly charged scalar and $Z'$ boson, the LFV signals originate from the (effective) LFV couplings of these particles to the charged leptons, while for the heavy neutrino $N$ and $W_R$ boson, the LFV effects are from flavor mixing in the neutrino sector. We consider current limits on these BSM particles and estimate their prospects at future high-energy hadron and lepton colliders."
2201.00100,Boosting RGB-D Saliency Detection by Leveraging Unlabeled RGB Images,"['Xiaoqiang Wang', 'Lei Zhu', 'Siliang Tang', 'Huazhu Fu', 'Ping Li', 'Fei Wu', 'Yi Yang', 'Yueting Zhuang']",ARXIV,http://arxiv.org/pdf/2201.00100v1,2022-01-01T03:02:27Z,2022-01-01T03:02:27Z,"['10.48550/arXiv.2201.00100', '10.1109/TIP.2021.3139232']","Training deep models for RGB-D salient object detection (SOD) often requires a large number of labeled RGB-D images. However, RGB-D data is not easily acquired, which limits the development of RGB-D SOD techniques. To alleviate this issue, we present a Dual-Semi RGB-D Salient Object Detection Network (DS-Net) to leverage unlabeled RGB images for boosting RGB-D saliency detection. We first devise a depth decoupling convolutional neural network (DDCNN), which contains a depth estimation branch and a saliency detection branch. The depth estimation branch is trained with RGB-D images and then used to estimate the pseudo depth maps for all unlabeled RGB images to form the paired data. The saliency detection branch is used to fuse the RGB feature and depth feature to predict the RGB-D saliency. Then, the whole DDCNN is assigned as the backbone in a teacher-student framework for semi-supervised learning. Moreover, we also introduce a consistency loss on the intermediate attention and saliency maps for the unlabeled data, as well as a supervised depth and saliency loss for labeled data. Experimental results on seven widely-used benchmark datasets demonstrate that our DDCNN outperforms state-of-the-art methods both quantitatively and qualitatively. We also demonstrate that our semi-supervised DS-Net can further improve the performance, even when using an RGB image with the pseudo depth map."
2201.00281,Evidence synthesis with reconstructed survival data,"['Chenqi Fu', 'Shouhao Zhou', 'Xuelin Huang', 'Nicholas J. Short', 'Farhad Ravandi-Kashani', 'Donald A. Berry']",ARXIV,http://arxiv.org/pdf/2201.00281v1,2022-01-02T03:09:22Z,2022-01-02T03:09:22Z,['10.48550/arXiv.2201.00281'],"We present a general approach to synthesizing evidence of time-to-event endpoints in meta-analyses of aggregate data (AD). Our work goes beyond most previous meta-analytic research by using reconstructed survival data as a source of information. A Bayesian multilevel regression model, called the ""meta-analysis of reconstructed survival data"" (MARS), is introduced, by modeling and integrating reconstructed survival information with other types of summary data, to estimate the hazard ratio function and survival probabilities. The method attempts to reduce selection bias, and relaxes the presumption of proportional hazards in individual clinical studies from the conventional approaches restricted to hazard ratio estimates. Theoretically, we establish the asymptotic consistency of MARS, and investigate its relative efficiency with respect to the individual participant data (IPD) meta-analysis. In simulation studies, the MARS demonstrated comparable performance to IPD meta-analysis with minor deviation from the true values, suggesting great robustness and efficiency achievable in AD meta-analysis with finite sample. Finally, we applied MARS in a meta-analysis of acute myeloid leukemia to assess the association of minimal residual disease with survival, to help respond to FDA's emerging concerns on translational use of surrogate biomarker in drug development of hematologic malignancies."
2201.00233,"A new criterion for $\mathcal{M}, \mathcal{N}$-adhesivity, with an application to hierarchical graphs","['Davide Castelnovo', 'Fabio Gadducci', 'Marino Miculan']",ARXIV,http://arxiv.org/pdf/2201.00233v3,2022-01-01T19:03:44Z,2022-06-15T17:42:08Z,['10.48550/arXiv.2201.00233'],"Adhesive categories provide an abstract framework for the algebraic approach to rewriting theory, where many general results can be recast and uniformly proved. However, checking that a model satisfies the adhesivity properties is sometimes far from immediate. In this paper we present a new criterion giving a sufficient condition for $\mathcal{M}, \mathcal{N}$-adhesivity, a generalisation of the original notion of adhesivity. We apply it to several existing categories, and in particular to hierarchical graphs, a formalism that is notoriously difficult to fit in the mould of algebraic approaches to rewriting and for which various alternative definitions float around."
2201.00314,The Maximum Principle for Discounted Optimal Control of Partially Observed Forward-Backward Stochastic Systems with Jumps on Infinite Horizon,"['Yueyang Zheng', 'Jingtao Shi']",ARXIV,http://arxiv.org/pdf/2201.00314v1,2022-01-02T07:23:40Z,2022-01-02T07:23:40Z,['10.48550/arXiv.2201.00314'],"This paper is concerned with a discounted optimal control problem of partially observed forward-backward stochastic systems with jumps on infinite horizon. The control domain is convex and a kind of infinite horizon observation equation is introduced. The uniquely solvability of infinite horizon forward (backward) stochastic differential equation with jumps is obtained and more extended analysis, especially for the backward case, is made. Some new estimates are first given and proved for the critical variational inequality. Then an ergodic maximum principle is obtained by introducing some infinite horizon adjoint equations whose uniquely solvabilities are guaranteed necessarily. Finally, some comparison are made with two kinds of representative infinite horizon stochastic systems and their related optimal controls."
2201.00154,Compact hyperbolic Coxeter four-polytopes with eight facets,"['Jiming Ma', 'Fangting Zheng']",ARXIV,http://arxiv.org/pdf/2201.00154v3,2022-01-01T09:29:09Z,2022-11-22T04:34:07Z,['10.48550/arXiv.2201.00154'],"In this paper, we obtain the complete classification for compact hyperbolic Coxeter four-dimensional polytopes with eight facets."
2201.00204,Low-Density Spreading Design Based on an Algebraic Scheme for NOMA Systems,"['Goldwyn Millar', 'Michel Kulhandjian', 'Ayse Alaca', 'Saban Alaca', ""Claude D'Amours"", 'Halim Yanikomeroglu']",ARXIV,http://arxiv.org/pdf/2201.00204v1,2022-01-01T15:10:39Z,2022-01-01T15:10:39Z,['10.48550/arXiv.2201.00204'],"NOMA) technique based on an algebraic design is studied. We propose an improved low-density spreading (LDS) sequence design based on projective geometry. In terms of its bit error rate (BER) performance, our proposed improved LDS code set outperforms the existing LDS designs over the frequency nonselective Rayleigh fading and additive white Gaussian noise (AWGN) channels. We demonstrated that achieving the best BER depends on the minimum distance."
2201.00265,Similarity reductions of peakon equations: the $b$-family,"['Lucy E. Barnes', 'Andrew N. W. Hone']",ARXIV,http://arxiv.org/pdf/2201.00265v5,2022-01-02T00:05:24Z,2022-05-21T11:51:44Z,"['10.48550/arXiv.2201.00265', '10.1134/S0040577922080104']","The $b$-family is a one-parameter family of Hamiltonian partial differential equations of non-evolutionary type, which arises in shallow water wave theory. It admits a variety of solutions, including the celebrated peakons, which are weak solutions in the form of peaked solitons with a discontinuous first derivative at the peaks, as well as other interesting solutions that have been obtained in exact form and/or numerically. In each of the special cases $b=2,3$ (the Camassa-Holm and Degasperis-Procesi equations, respectively) the equation is completely integrable, in the sense that it admits a Lax pair and an infinite hierarchy of commuting local symmetries, but for other values of the parameter $b$ it is non-integrable. After a discussion of travelling waves via the use of a reciprocal transformation, which reduces to a hodograph transformation at the level of the ordinary differential equation satisfied by these solutions, we apply the same technique to the scaling similarity solutions of the $b$-family, and show that when $b=2$ or $3$ this similarity reduction is related by a hodograph transformation to particular cases of the Painlev\'e III equation, while for all other choices of $b$ the resulting ordinary differential equation is not of Painlev\'e type."
2201.00394,Solving the signed Roman domination and signed total Roman domination problems with exact and heuristic methods,"['Vladimir Filipović', 'Dragan Matić', 'Aleksandar Kartelj']",ARXIV,http://arxiv.org/pdf/2201.00394v1,2022-01-02T19:20:39Z,2022-01-02T19:20:39Z,['10.48550/arXiv.2201.00394'],"In this paper we deal with the signed Roman domination and signed total Roman domination problems. For each problem we propose two integer linear programming (ILP) formulations, the constraint programming (CP) formulation and variable neighborhood search (VNS) method. We present proofs for the correctness of the ILP formulations and a polyhedral study in which we show that the polyhedrons of the two model relaxations are equivalent. VNS uses specifically designed penalty function that allows the appearance of slightly infeasible solutions. The acceptance of these solutions directs the overall search process to the promising areas in the long run. All proposed approaches are tested on the large number of instances. Experimental results indicate that all of them reach optimal solutions for the most of small and middle scale instances. Both ILP models have proven to be more successful than the other two methods."
2201.00327,Endpoint estimates and optimality for the generalized spherical maximal operator on radial functions,"['Adam Nowak', 'Luz Roncal', 'Tomasz Z. Szarek']",ARXIV,http://arxiv.org/pdf/2201.00327v2,2022-01-02T09:55:05Z,2023-01-23T11:02:50Z,['10.48550/arXiv.2201.00327'],"We find sharp conditions for the maximal operator associated with generalized spherical mean Radon transform on radial functions $M^{\a,\b}_t$ to be bounded on power weighted Lebesgue spaces. Moreover, we also obtain the corresponding endpoint results in terms of optimal power weighted weak and restricted weak type estimates."
2201.00118,Semantic Search for Large Scale Clinical Ontologies,"['Duy-Hoa Ngo', 'Madonna Kemp', 'Donna Truran', 'Bevan Koopman', 'Alejandro Metke-Jimenez']",ARXIV,http://arxiv.org/pdf/2201.00118v1,2022-01-01T05:15:42Z,2022-01-01T05:15:42Z,['10.48550/arXiv.2201.00118'],"Finding concepts in large clinical ontologies can be challenging when queries use different vocabularies. A search algorithm that overcomes this problem is useful in applications such as concept normalisation and ontology matching, where concepts can be referred to in different ways, using different synonyms. In this paper, we present a deep learning based approach to build a semantic search system for large clinical ontologies. We propose a Triplet-BERT model and a method that generates training data directly from the ontologies. The model is evaluated using five real benchmark data sets and the results show that our approach achieves high results on both free text to concept and concept to concept searching tasks, and outperforms all baseline methods."
2201.00414,FUSeg: The Foot Ulcer Segmentation Challenge,"['Chuanbo Wang', 'Amirreza Mahbod', 'Isabella Ellinger', 'Adrian Galdran', 'Sandeep Gopalakrishnan', 'Jeffrey Niezgoda', 'Zeyun Yu']",ARXIV,http://arxiv.org/pdf/2201.00414v1,2022-01-02T20:34:09Z,2022-01-02T20:34:09Z,['10.48550/arXiv.2201.00414'],"Acute and chronic wounds with varying etiologies burden the healthcare systems economically. The advanced wound care market is estimated to reach $22 billion by 2024. Wound care professionals provide proper diagnosis and treatment with heavy reliance on images and image documentation. Segmentation of wound boundaries in images is a key component of the care and diagnosis protocol since it is important to estimate the area of the wound and provide quantitative measurement for the treatment. Unfortunately, this process is very time-consuming and requires a high level of expertise. Recently automatic wound segmentation methods based on deep learning have shown promising performance but require large datasets for training and it is unclear which methods perform better. To address these issues, we propose the Foot Ulcer Segmentation challenge (FUSeg) organized in conjunction with the 2021 International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI). We built a wound image dataset containing 1,210 foot ulcer images collected over 2 years from 889 patients. It is pixel-wise annotated by wound care experts and split into a training set with 1010 images and a testing set with 200 images for evaluation. Teams around the world developed automated methods to predict wound segmentations on the testing set of which annotations were kept private. The predictions were evaluated and ranked based on the average Dice coefficient. The FUSeg challenge remains an open challenge as a benchmark for wound segmentation after the conference."
2201.00120,Lower bounds for moments of quadratic twisted self-dual $\textrm{GL}(3)$ central $L$-values,"['Shenghao Hua', 'Bingrong Huang']",ARXIV,http://arxiv.org/pdf/2201.00120v2,2022-01-01T05:18:06Z,2022-12-18T08:48:10Z,['10.48550/arXiv.2201.00120'],"In this paper, we prove the conjectured order lower bound for the $k$-th moment of central values of quadratic twisted self-dual $\textrm{GL}(3)$ $L$-functions for all $k\geq 1$, based on our recent work on the twisted first moment of central values in this family of $L$-functions."
2201.00313,Secure Determinant Codes for Distributed Storage Systems,"['Adel Elmahdy', 'Michelle Kleckler', 'Soheil Mohajer']",ARXIV,http://arxiv.org/pdf/2201.00313v2,2022-01-02T07:21:46Z,2022-12-30T03:00:43Z,['10.48550/arXiv.2201.00313'],"The information-theoretic secure exact-repair regenerating codes for distributed storage systems (DSSs) with parameters $(n,k=d,d,\ell)$ are studied in this paper. We consider distributed storage systems with $n$ nodes, in which the original data can be recovered from any subset of $k=d$ nodes, and the content of any node can be retrieved from those of any $d$ helper nodes. Moreover, we consider two secrecy constraints, namely, Type-I, where the message remains secure against an eavesdropper with access to the content of any subset of up to $\ell$ nodes, and Type-II, in which the message remains secure against an eavesdropper who can observe the incoming repair data from all possible nodes to a fixed but unknown subset of up to $\ell$ compromised nodes. Two classes of secure determinant codes are proposed for Type-I and Type-II secrecy constraints. Each proposed code can be designed for a range of per-node storage capacity and repair bandwidth for any system parameters. They lead to two achievable secrecy trade-offs, for Type-I and Type-II security."
2201.00389,A Normal Graph Algebra,['Harold N. Ward'],ARXIV,http://arxiv.org/pdf/2201.00389v2,2022-01-02T18:20:00Z,2023-05-22T15:26:28Z,['10.48550/arXiv.2201.00389'],"We define a normal graph algebra modeled on algebras used in genetics. Although the algebra does not always determine its graph, it often highlights special features. After developing basic properties of the algebra, we examine those of certain minimal graphs. We then apply the results to the Petersen graph, finding connections between some of its many aspects. For example, the outer automorphisms of Sym(6) emerge naturally. The normal algebra of the Petersen graph is unique among normal graph algebras."
2201.00350,The Interpretability of LSTM Models for Predicting Oil Company Stocks: Impact of Correlated Features,"['Javad T. Firouzjaee', 'Pouriya Khaliliyan']",ARXIV,http://arxiv.org/pdf/2201.00350v5,2022-01-02T12:52:37Z,2023-12-20T09:09:47Z,['10.48550/arXiv.2201.00350'],"Oil companies are among the largest companies in the world whose economic indicators in the global stock market have a great impact on the world economy\cite{ec00} and market due to their relation to gold\cite{ec01}, crude oil\cite{ec02}, and the dollar\cite{ec03}. This study investigates the impact of correlated features on the interpretability of Long Short-Term Memory(LSTM)\cite{ec04} models for predicting oil company stocks. To achieve this, we designed a Standard Long Short-Term Memory (LSTM) network and trained it using various correlated datasets. Our approach aims to improve the accuracy of stock price prediction by considering the multiple factors affecting the market, such as crude oil prices, gold prices, and the US dollar. The results demonstrate that adding a feature correlated with oil stocks does not improve the interpretability of LSTM models. These findings suggest that while LSTM models may be effective in predicting stock prices, their interpretability may be limited. Caution should be exercised when relying solely on LSTM models for stock price prediction as their lack of interpretability may make it difficult to fully understand the underlying factors driving stock price movements. We have employed complexity analysis to support our argument, considering that financial markets encompass a form of physical complex system\cite{ec05}. One of the fundamental challenges faced in utilizing LSTM models for financial markets lies in interpreting the unexpected feedback dynamics within them."
2201.00331,"Off-shell $t\bar{t}b\bar{b}$ production at the LHC: QCD corrections, theory uncertainties and $b$-jet definitions",['Giuseppe Bevilacqua'],ARXIV,http://arxiv.org/pdf/2201.00331v1,2022-01-02T10:28:22Z,2022-01-02T10:28:22Z,['10.48550/arXiv.2201.00331'],"We present state-of-the-art predictions for off-shell $t\bar{t}b\bar{b}$ production with di-lepton decays at the LHC with $\sqrt{s}=13$ TeV. Results are accurate at NLO in QCD and include all resonant and non-resonant diagrams, interferences and finite-width effects for top quarks and $W$ bosons. We discuss the impact of QCD corrections and assess theoretical uncertainties from scale and PDF dependence at the integrated and differential level. Additionally we investigate the size of contributions induced by initial-state $b$ quarks to the NLO cross section."
2201.00302,Entropies of Serre functors for higher hereditary algebras,['Yang Han'],ARXIV,http://arxiv.org/pdf/2201.00302v2,2022-01-02T06:13:11Z,2022-02-08T08:29:24Z,['10.48550/arXiv.2201.00302'],"For a higher hereditary algebra, we calculate its upper (lower) Serre dimension, the entropy and polynomial entropy of Serre functor, and the Hochschild (co)homology entropy of Serre quasi-functor. These invariants are given by its Calabi-Yau dimension for a higher representation-finite algebra, and by its global dimension and the spectral radius and polynomial growth rate of its Coxeter matrix for a higher representation-infinite algebra. For this, we prove the Yomdin type inequality on Hochschild homology entropy for a finite dimensional elementary algebra of finite global dimension. Our calculations imply that the Kikuta and Ouchi's question on relations between entropy and Hochschild (co)homology entropy has positive answer, and the Gromov-Yomdin type equalities on entropy and Hochschild (co)homology entropy hold, for the Serre functor on perfect derived category and the Serre quasi-functor on perfect dg module category of an indecomposable elementary higher hereditary algebra."
2201.00211,Temperature Effect on Charge-state Transition Levels of Defects in Semiconductors,"['Shuang Qiao', 'Yu-Ning Wu', 'Xiaolan Yan', 'Bartomeu Monserrat', 'Su-Huai Wei', 'Bing Huang']",ARXIV,http://arxiv.org/pdf/2201.00211v1,2022-01-01T15:35:46Z,2022-01-01T15:35:46Z,"['10.48550/arXiv.2201.00211', '10.1103/PhysRevB.105.115201']","Defects are crucial in determining the overall physical properties of semiconductors. Generally, the charge-state transition level (TEL), one of the key physical quantities that determines the dopability of defects in semiconductors, is temperature dependent. However, little is known about the temperature dependence of TEL, and, as a result, almost all existing defect theories in semiconductors are built on a temperature-independent approximation. In this article, by deriving the basic formulas for temperature-dependent TEL, we have established two fundamental rules for the temperature dependence of TEL in semiconductors. Based on these rules, surprisingly, it is found that the temperature dependences of TEL for different defects are rather diverse: it can become shallower, deeper, or stay unchanged. This defect-specific behavior is mainly determined by the synergistic or opposing effects between free energy corrections (determined by the local volume change around the defect during a charge-state transition) and band edge changes (which differ for different semiconductors). These basic formulas and rules, confirmed by a large number of state-of-the-art temperature-dependent defect calculations in GaN, may potentially be widely adopted as guidelines for understanding or optimizing doping behaviors in semiconductors at finite temperatures."
2201.00309,Optimizing Machine Learning Inference Queries with Correlative Proxy Models,"['Zhihui Yang', 'Zuozhi Wang', 'Yicong Huang', 'Yao Lu', 'Chen Li', 'X. Sean Wang']",ARXIV,http://arxiv.org/pdf/2201.00309v1,2022-01-02T06:58:02Z,2022-01-02T06:58:02Z,['10.48550/arXiv.2201.00309'],"We consider accelerating machine learning (ML) inference queries on unstructured datasets. Expensive operators such as feature extractors and classifiers are deployed as user-defined functions(UDFs), which are not penetrable with classic query optimization techniques such as predicate push-down. Recent optimization schemes (e.g., Probabilistic Predicates or PP) assume independence among the query predicates, build a proxy model for each predicate offline, and rewrite a new query by injecting these cheap proxy models in the front of the expensive ML UDFs. In such a manner, unlikely inputs that do not satisfy query predicates are filtered early to bypass the ML UDFs. We show that enforcing the independence assumption in this context may result in sub-optimal plans. In this paper, we propose CORE, a query optimizer that better exploits the predicate correlations and accelerates ML inference queries. Our solution builds the proxy models online for a new query and leverages a branch-and-bound search process to reduce the building costs. Results on three real-world text, image and video datasets show that CORE improves the query throughput by up to 63% compared to PP and up to 80% compared to running the queries as it is."
2201.00335,A model theory of topology,['Paolo Lipparini'],ARXIV,http://arxiv.org/pdf/2201.00335v1,2022-01-02T11:11:48Z,2022-01-02T11:11:48Z,['10.48550/arXiv.2201.00335'],"An algebraization of the notion of topology has been proposed more than seventy years ago in a classical paper by McKinsey and Tarski. However, in McKinsey and Tarski's setting the model theoretical notion of homomorphism does not correspond to the notion of continuity. We notice that the two notions correspond if instead we consider a preorder relation $ \sqsubseteq $ defined by $a \sqsubseteq b$ if $a$ is contained in the topological closure of $b$. A specialization poset is a partially ordered set endowed with a further coarser preorder relation $ \sqsubseteq $. We show that every specialization poset can be embedded in the specialization poset naturally associated to some topological space, where the order relation corresponds to set-theoretical inclusion. Specialization semilattices are defined in an analogous way and the corresponding embedding theorem is proved. The interest of these structures arises from the fact that they also occur in many rather disparate settings, even far removed from topology."
2201.00415,On universal sampling representation,['V. N. Temlyakov'],ARXIV,http://arxiv.org/pdf/2201.00415v1,2022-01-02T20:51:49Z,2022-01-02T20:51:49Z,['10.48550/arXiv.2201.00415'],"For the multivariate trigonometric polynomials we study convolution with the corresponding the de la Vallee Poussin kernel from the point of view of discretization. In other words, we replace the normalized Lebesgue measure by a discrete measure in such a way, which preserves the convolution properties and provides sampling discretization of integral norms. We prove that in the two-variate case the Fibonacci point sets provide an ideal (in the sense of order) solution. We also show that the Korobov point sets provide a suboptimal (up to logarithmic factors) solution for an arbitrary number of variables."
2201.00207,AutoDES: AutoML Pipeline Generation of Classification with Dynamic Ensemble Strategy Selection,"['Yunpu Zhao', 'Rui Zhang', 'Xiaqing Li']",ARXIV,http://arxiv.org/pdf/2201.00207v2,2022-01-01T15:17:07Z,2022-07-20T03:40:02Z,['10.48550/arXiv.2201.00207'],"Automating machine learning has achieved remarkable technological developments in recent years, and building an automated machine learning pipeline is now an essential task. The model ensemble is the technique of combining multiple models to get a better and more robust model. However, existing automated machine learning tends to be simplistic in handling the model ensemble, where the ensemble strategy is fixed, such as stacked generalization. There have been many techniques on different ensemble methods, especially ensemble selection, and the fixed ensemble strategy limits the upper limit of the model's performance. In this article, we present a novel framework for automated machine learning. Our framework incorporates advances in dynamic ensemble selection, and to our best knowledge, our approach is the first in the field of AutoML to search and optimize ensemble strategies. In the comparison experiments, our method outperforms the state-of-the-art automated machine learning frameworks with the same CPU time in 42 classification datasets from the OpenML platform. Ablation experiments on our framework validate the effectiveness of our proposed method."
2201.00433,Direct Nuclear Reactions,"['Carlos A. Bertulani', 'Angela Bonaccorso']",ARXIV,http://arxiv.org/pdf/2201.00433v2,2022-01-02T23:39:34Z,2022-01-24T05:39:05Z,['10.48550/arXiv.2201.00433'],"In this brief review we discuss the basic theoretical concepts used in the experimental studies of the most common cases of direct reactions such as (a) elastic scattering, (b) inelastic scattering, (c) Coulomb excitation, (d) transfer reactions and (e) breakup reactions."
2201.00140,Toward Pareto Efficient Fairness-Utility Trade-off inRecommendation through Reinforcement Learning,"['Yingqiang Ge', 'Xiaoting Zhao', 'Lucia Yu', 'Saurabh Paul', 'Diane Hu', 'Chu-Cheng Hsieh', 'Yongfeng Zhang']",ARXIV,http://arxiv.org/pdf/2201.00140v1,2022-01-01T07:35:41Z,2022-01-01T07:35:41Z,"['10.48550/arXiv.2201.00140', '10.1145/3488560.3498487']","The issue of fairness in recommendation is becoming increasingly essential as Recommender Systems touch and influence more and more people in their daily lives. In fairness-aware recommendation, most of the existing algorithmic approaches mainly aim at solving a constrained optimization problem by imposing a constraint on the level of fairness while optimizing the main recommendation objective, e.g., CTR. While this alleviates the impact of unfair recommendations, the expected return of an approach may significantly compromise the recommendation accuracy due to the inherent trade-off between fairness and utility. This motivates us to deal with these conflicting objectives and explore the optimal trade-off between them in recommendation. One conspicuous approach is to seek a Pareto efficient solution to guarantee optimal compromises between utility and fairness. Moreover, considering the needs of real-world e-commerce platforms, it would be more desirable if we can generalize the whole Pareto Frontier, so that the decision-makers can specify any preference of one objective over another based on their current business needs. Therefore, in this work, we propose a fairness-aware recommendation framework using multi-objective reinforcement learning, called MoFIR, which is able to learn a single parametric representation for optimal recommendation policies over the space of all possible preferences. Specially, we modify traditional DDPG by introducing conditioned network into it, which conditions the networks directly on these preferences and outputs Q-value-vectors. Experiments on several real-world recommendation datasets verify the superiority of our framework on both fairness metrics and recommendation measures when compared with all other baselines. We also extract the approximate Pareto Frontier on real-world datasets generated by MoFIR and compare to state-of-the-art fairness methods."
2201.00253,Fieldable muon spectrometer using multi-layer pressurized gas Cherenkov radiators and its applications,"['Junghyun Bae', 'Stylianos Chatzidakis']",ARXIV,http://arxiv.org/pdf/2201.00253v1,2022-01-01T22:55:42Z,2022-01-01T22:55:42Z,['10.48550/arXiv.2201.00253'],"Cosmic ray muons have been considered as a non-conventional radiation probe in various applications. To utilize cosmic ray muons in engineering applications, two important quantities, trajectory and momentum, must be known. The muon trajectories are easily reconstructed using two-fold detector arrays with a high spatial resolution. However, precise measurement of muon momentum is difficult to be achieved without deploying large and expensive spectrometers such as solenoid magnets. Here, we propose a new method to estimate muon momentum using multi-layer pressurized gas Cherenkov radiators. This is accurate, portable, compact (< 1m3), and easily coupled with existing muon detectors without the need of neither bulky magnetic nor time-of-flight spectrometers. The results show that not only our new muon spectrometer can measure muon momentum with a resolution of +-0.5 GeV/c in a momentum range of 0.1 to 10.0 GeV/c, but also we can reconstruct cosmic muon spectrum with high accuracy (~90%)."
2201.00330,"Isospin Mixing and the Cubic Isobaric Multiplet Mass Equation in the Lowest T = 2, A = 32 Quintet","['M. Kamil', 'S. Triambak', 'A. Magilligan', 'A. García', 'B. A. Brown', 'P. Adsley', 'V. Bildstein', 'C. Burbadge', 'A. Diaz Varela', 'T. Faestermann', 'P. E. Garrett', 'R. Hertenberger', 'N. Y. Kheswa', 'K. G. Leach', 'R. Lindsay', 'D. J. Marín-Lámbarri', 'F. Ghazi Moradi', 'N. J. Mukwevho', 'R. Neveling', 'J. C. Nzobadila Ondze', 'P. Papka', 'L. Pellegri', 'V. Pesudo', 'B. M. Rebeiro', 'M. Scheck', 'F. D. Smit', 'H. -F. Wirth']",ARXIV,http://arxiv.org/pdf/2201.00330v1,2022-01-02T10:19:38Z,2022-01-02T10:19:38Z,"['10.48550/arXiv.2201.00330', '10.1103/PhysRevC.104.L061303']","The isobaric multiplet mass equation (IMME) is known to break down in the first T = 2, A = 32 isospin quintet. In this work we combine high-resolution experimental data with state-of-the-art shell-model calculations to investigate isospin mixing as a possible cause for this violation. The experimental data are used to validate isospin-mixing matrix elements calculated with newly developed shell-model Hamiltonians. Our analysis shows that isospin mixing with nonanalog T = 1 states contributes to the IMME breakdown, making the requirement of an anomalous cubic term inevitable for the multiplet."
2201.00134,Giant widening of interface magnetic layer in almost compensated iron garnet,"['Y. B. Kudasov', 'M. V. Logunov', 'R. V. Kozabaranov', 'I. V. Makarov', 'V. V. Platonov', 'O. M. Surdin', 'D. A. Maslov', 'A. S. Korshunov', 'I. S. Strelkov', 'A. I. Stognij', 'V. D. Selemir', 'S. A. Nikitov']",ARXIV,http://arxiv.org/pdf/2201.00134v1,2022-01-01T07:03:48Z,2022-01-01T07:03:48Z,"['10.48550/arXiv.2201.00134', '10.1063/5.0086067']","A two-sublattice ferrimagnet undergoes a transition from a collinear to canted magnetic phase at magnetic field oriented along an easy magnetization direction. In this work, we study the transition by means of the magneto-optical Faraday effect in a thin film of compensated iron garnet (Lu$_{3-{\rm{x}}}$Bi$_{\rm{x}}$)(Fe$_{5-{\rm{y}}-{\rm{z}}}$Ga$_{\rm{y}}$Al$_{\rm{z}}$)O$_{12}$ grown on Gd$_3$Ga$_5$O$_{12}$ substrate. In the immediate vicinity of the compensation temperature a precursor of the transition with a complex shape was observed. Using a special sample with variable thickness we demonstrate an interfacial origin of the precursor. Diffusion of gadolinium from the substrate into the film forms a thin intermixed layer with enhanced magnetization. It induces an extended inhomogeneous magnetic structure in the film. A two-step shape of the precursor appears due to an easy-plane anisotropy of the intermixed magnetic layer. We emphasize that an effective width of the inhomogeneous magnetization distribution in the film grows enormously while approaching the compensation temperature."
2201.00318,On Sensitivity of Deep Learning Based Text Classification Algorithms to Practical Input Perturbations,"['Aamir Miyajiwala', 'Arnav Ladkat', 'Samiksha Jagadale', 'Raviraj Joshi']",ARXIV,http://arxiv.org/pdf/2201.00318v2,2022-01-02T08:33:49Z,2022-01-23T14:50:54Z,"['10.48550/arXiv.2201.00318', '10.1007/978-3-031-10464-0_42']","Text classification is a fundamental Natural Language Processing task that has a wide variety of applications, where deep learning approaches have produced state-of-the-art results. While these models have been heavily criticized for their black-box nature, their robustness to slight perturbations in input text has been a matter of concern. In this work, we carry out a data-focused study evaluating the impact of systematic practical perturbations on the performance of the deep learning based text classification models like CNN, LSTM, and BERT-based algorithms. The perturbations are induced by the addition and removal of unwanted tokens like punctuation and stop-words that are minimally associated with the final performance of the model. We show that these deep learning approaches including BERT are sensitive to such legitimate input perturbations on four standard benchmark datasets SST2, TREC-6, BBC News, and tweet_eval. We observe that BERT is more susceptible to the removal of tokens as compared to the addition of tokens. Moreover, LSTM is slightly more sensitive to input perturbations as compared to CNN based model. The work also serves as a practical guide to assessing the impact of discrepancies in train-test conditions on the final performance of models."
2201.00194,FamilySeer: Towards Optimized Tensor Codes by Exploiting Computation Subgraph Similarity,"['Shanjun Zhang', 'Mingzhen Li', 'Hailong Yang', 'Yi Liu', 'Zhongzhi Luan', 'Depei Qian']",ARXIV,http://arxiv.org/pdf/2201.00194v1,2022-01-01T14:22:43Z,2022-01-01T14:22:43Z,['10.48550/arXiv.2201.00194'],"Deploying various deep learning (DL) models efficiently has boosted the research on DL compilers. The difficulty of generating optimized tensor codes drives DL compiler to ask for the auto-tuning approaches, and the increasing demands require increasing auto-tuning efficiency and quality. Currently, the DL compilers partition the input DL models into several subgraphs and leverage the auto-tuning to find the optimal tensor codes of these subgraphs. However, existing auto-tuning approaches usually regard subgraphs as individual ones and overlook the similarities across them, and thus fail to exploit better tensor codes under limited time budgets. We propose FamilySeer, an auto-tuning framework for DL compilers that can generate better tensor codes even with limited time budgets. FamilySeer exploits the similarities and differences among subgraphs can organize them into subgraph families, where the tuning of one subgraph can also improve other subgraphs within the same family. The cost model of each family gets more purified training samples generated by the family and becomes more accurate so that the costly measurements on real hardware can be replaced with the lightweight estimation through cost model. Our experiments show that FamilySeer can generate model codes with the same code performance more efficiently than state-of-the-art auto-tuning frameworks."
2201.00480,TFCN: Temporal-Frequential Convolutional Network for Single-Channel Speech Enhancement,"['Xupeng Jia', 'Dongmei Li']",ARXIV,http://arxiv.org/pdf/2201.00480v1,2022-01-03T05:17:13Z,2022-01-03T05:17:13Z,['10.48550/arXiv.2201.00480'],"Deep learning based single-channel speech enhancement tries to train a neural network model for the prediction of clean speech signal. There are a variety of popular network structures for single-channel speech enhancement, such as TCNN, UNet, WaveNet, etc. However, these structures usually contain millions of parameters, which is an obstacle for mobile applications. In this work, we proposed a light weight neural network for speech enhancement named TFCN. It is a temporal-frequential convolutional network constructed of dilated convolutions and depth-separable convolutions. We evaluate the performance of TFCN in terms of Short-Time Objective Intelligibility (STOI), perceptual evaluation of speech quality (PESQ) and a series of composite metrics named Csig, Cbak and Covl. Experimental results show that compared with TCN and several other state-of-the-art algorithms, the proposed structure achieves a comparable performance with only 93,000 parameters. Further improvement can be achieved at the cost of more parameters, by introducing dense connections and depth-separable convolutions with normal ones. Experiments also show that the proposed structure can work well both in causal and non-causal situations."
2201.00368,"A priori estimates, uniqueness and non-degeneracy of positive solutions of the Choquard equation",['Zexing Li'],ARXIV,http://arxiv.org/pdf/2201.00368v1,2022-01-02T15:34:13Z,2022-01-02T15:34:13Z,['10.48550/arXiv.2201.00368'],"We consider the positive solutions for the nonlocal Choquard equation $- \Delta u + u - (|\cdot|^{-\alpha} * |u|^p) |u|^{p-2} u = 0$ in $\mathbb{R}^d$. Compared with ground states, positive solutions form a larger class of solutions and lack variational information. Within the range of parameters of Ma-Zhao's result [Ma-Zhao, 2010] on symmetry, we prove a priori estimates for positive solutions, generalizing the classical method of De Figueiredo-Lions-Russbaum [De Figueiredo-Lions-Nussbaum, 1982] to the unbounded domain and the nonlocal nonlinearity in our model. As an application, we show uniqueness and non-degeneracy results for the positive solution of the Choquard equation when $d \in \{ 3, 4, 5\}$, $p \ge 2$ and $(\alpha, p)$ close to $(d-2, 2)$."
2201.00151,Multiple stellar populations in Schwarzschild modeling and the application to the Fornax dwarf,"['Klaudia Kowalczyk', 'Ewa L. Lokas']",ARXIV,http://arxiv.org/pdf/2201.00151v1,2022-01-01T09:05:11Z,2022-01-01T09:05:11Z,"['10.48550/arXiv.2201.00151', '10.1051/0004-6361/202142212']","Dwarf spheroidal (dSph) galaxies are believed to be strongly dark matter dominated and thus are considered perfect objects to study dark matter distribution and test theories of structure formation. They possess resolved, multiple stellar populations that offer new possibilities for modeling. A promising tool for the dynamical modeling of these objects is the Schwarzschild orbit superposition method. In this work we extend our previous implementation of the scheme to include more than one population of stars and a more general form of the mass-to-light ratio function. We tested the improved approach on a nearly spherical, gas-free galaxy formed in the cosmological context from the Illustris simulation. We modeled the binned velocity moments for stars split into two populations by metallicity and demonstrate that in spite of larger sampling errors the increased number of constraints leads to significantly tighter confidence regions on the recovered density and velocity anisotropy profiles. We then applied the method to the Fornax dSph galaxy with stars similarly divided into two populations. In comparison with our earlier work, we find the anisotropy parameter to be slightly increasing, rather than decreasing, with radius and more strongly constrained. We are also able to infer anisotropy for each stellar population separately and find them to be significantly different."
2201.00384,On the effectiveness of Randomized Signatures as Reservoir for Learning Rough Dynamics,"['Enea Monzio Compagnoni', 'Anna Scampicchio', 'Luca Biggio', 'Antonio Orvieto', 'Thomas Hofmann', 'Josef Teichmann']",ARXIV,http://arxiv.org/pdf/2201.00384v3,2022-01-02T17:37:25Z,2023-04-26T09:06:44Z,['10.48550/arXiv.2201.00384'],"Many finance, physics, and engineering phenomena are modeled by continuous-time dynamical systems driven by highly irregular (stochastic) inputs. A powerful tool to perform time series analysis in this context is rooted in rough path theory and leverages the so-called Signature Transform. This algorithm enjoys strong theoretical guarantees but is hard to scale to high-dimensional data. In this paper, we study a recently derived random projection variant called Randomized Signature, obtained using the Johnson-Lindenstrauss Lemma. We provide an in-depth experimental evaluation of the effectiveness of the Randomized Signature approach, in an attempt to showcase the advantages of this reservoir to the community. Specifically, we find that this method is preferable to the truncated Signature approach and alternative deep learning techniques in terms of model complexity, training time, accuracy, robustness, and data hungriness."
2201.00413,Strong convergence of the thresholding scheme for the mean curvature flow of mean convex sets,"['Jakob Fuchs', 'Tim Laux']",ARXIV,http://arxiv.org/pdf/2201.00413v3,2022-01-02T20:21:49Z,2022-07-15T18:13:54Z,['10.48550/arXiv.2201.00413'],"In this work, we analyze Merriman, Bence and Osher's thresholding scheme, a time discretization for mean curvature flow. We restrict to the two-phase setting and mean convex initial conditions. In the sense of the minimizing movements interpretation of Esedoglu and Otto we show the time-integrated energy of the approximation to converge to the time-integrated energy of the limit. As a corollary, the conditional convergence results of Otto and one of the authors become unconditional in the two-phase mean convex case. Our results are general enough to handle the extension of the scheme to anisotropic flows for which a non-negative kernel can be chosen."
2201.00358,On the Mass and Magnetic Field of the Neutron Star in the Ultraluminous X-Ray Source NGC 300 ULX1,['Mehmet Hakan Erkut'],ARXIV,http://arxiv.org/pdf/2201.00358v1,2022-01-02T13:23:02Z,2022-01-02T13:23:02Z,"['10.48550/arXiv.2201.00358', '10.31590/ejosat.939104']","The accreting compact objects in most of ultraluminous X-ray sources (ULXs) are likely to be neutron stars rather than black holes as suggested by the recent detection of periodic pulsations from some of these sources located in neighboring galaxies and one ULX that has hitherto been discovered in our own galaxy. As a member of the ULX family, NGC 300 ULX1 is a new pulsating ULX (PULX) spinning up at substantially high rates compared with other PULXs. In this paper, the strength of the magnetic field on the surface of the neutron star is inferred from the energy of the cyclotron absorption line detected in the pulsed X-ray spectrum of NGC 300 ULX1 and the plausible ranges for the neutron-star mass and beaming fraction are estimated using the observed spin period and period derivative of the pulsar and the measured X-ray flux of the source. Our analysis favors proton cyclotron resonance scattering as a viable mechanism to account for both the observed cyclotron energy and high spin-up rates provided that the absorption line is generated close to the surface of the neutron star."
2201.00153,A Note On Local Regularity of Axisymmetric Solutions to the Navier-Stokes Equations,['Gregory Seregin'],ARXIV,http://arxiv.org/pdf/2201.00153v1,2022-01-01T09:28:24Z,2022-01-01T09:28:24Z,"['10.48550/arXiv.2201.00153', '10.1007/s00021-022-00667-6']","In the paper, a new {\it slightly supercritical} condition, providing {\it local} regularity of axially symmetric solutions to the non-stationary 3D Navier-Stokes equations, is discussed. It generalises almost all known results in the local regularity theory of weak axisymmetric solutions."
2201.00323,V-LinkNet: Learning Contextual Inpainting Across Latent Space of Generative Adversarial Network,"['Jireh Jam', 'Connah Kendrick', 'Vincent Drouard', 'Kevin Walker', 'Moi Hoon Yap']",ARXIV,http://arxiv.org/pdf/2201.00323v2,2022-01-02T09:14:23Z,2022-05-17T11:48:51Z,['10.48550/arXiv.2201.00323'],"Image inpainting is a key technique in image processing task to predict the missing regions and generate realistic images. Given the advancement of existing generative inpainting models with feature extraction, propagation and reconstruction capabilities, there is lack of high-quality feature extraction and transfer mechanisms in deeper layers to tackle persistent aberrations on the generated inpainted regions. Our method, V-LinkNet, develops high-level feature transference to deep level textural context of inpainted regions our work, proposes a novel technique of combining encoders learning through a recursive residual transition layer (RSTL). The RSTL layer easily adapts dual encoders by increasing the unique semantic information through direct communication. By collaborating the dual encoders structure with contextualised feature representation loss function, our system gains the ability to inpaint with high-level features. To reduce biases from random mask-image pairing, we introduce a standard protocol with paired mask-image on the testing set of CelebA-HQ, Paris Street View and Places2 datasets. Our results show V-LinkNet performed better on CelebA-HQ and Paris Street View using this standard protocol. We will share the standard protocol and our codes with the research community upon acceptance of this paper."
2201.00126,Etude de classification des bacteriophages,"['Dung Nguyen', 'Alix Boc', 'Abdoulaye Banire Diallo', 'Vladimir Makarenkov']",ARXIV,http://arxiv.org/pdf/2201.00126v1,2022-01-01T06:12:39Z,2022-01-01T06:12:39Z,['10.48550/arXiv.2201.00126'],"Phages are one of the most present groups of organisms in the biosphere. Their identification continues and their taxonomies are divergent. However, due to their evolution mode and the complexity of their species ecosystem, their classification is not complete. Here, we present a new approach to the phages classification that combines the methods of horizontal gene transfer detection and ancestral sequence reconstruction."
2201.00291,Intrinsic Superflat Bands in General Twisted Bilayer Systems,"['Hongfei Wang', 'Shaojie Ma', 'Shuang Zhang', 'Dangyuan Lei']",ARXIV,http://arxiv.org/pdf/2201.00291v1,2022-01-02T05:03:59Z,2022-01-02T05:03:59Z,"['10.48550/arXiv.2201.00291', '10.1038/s41377-022-00838-0']","Twisted bilayer systems with discrete magic angles, such as twisted bilayer graphene featuring moir\'{e} superlattices, provide a versatile platform for exploring novel physical properties. Here, we discover a class of superflat bands in general twisted bilayer systems beyond the low-energy physics of magic-angle twisted counterparts. By considering continuous lattice dislocation, we obtain intrinsic localized states, which are spectrally isolated at lowest and highest energies and spatially centered around the AA stacked region, governed by the macroscopic effective energy potential well. Such localized states exhibit negligible inter-cell coupling and support the formation of superflat bands in a wide and continuous parameter space, which can be mimicked using a twisted bilayer nanophotonic system. Our finding suggests that general twisted bilayer systems can realize continuously tunable superflat bands and the corresponding localized states for various photonic, phononic and mechanical waves."
2201.00321,Optimal control of SDEs with expected path constraints and related constrained FBSDEs,"['Ying Hu', 'Shanjian Tang', 'Zuo Quan Xu']",ARXIV,http://arxiv.org/pdf/2201.00321v2,2022-01-02T09:04:07Z,2022-08-13T00:24:04Z,['10.48550/arXiv.2201.00321'],"In this paper, we consider optimal control of stochastic differential equations subject to an expected path constraint. The stochastic maximum principle is given for a general optimal stochastic control in terms of constrained FBSDEs. In particular, the compensated process in our adjoint equation is deterministic, which seems to be new in the literature. For the typical case of linear stochastic systems and quadratic cost functionals (i.e., the so-called LQ optimal stochastic control), a verification theorem is established, and the existence and uniqueness of the constrained reflected FBSDEs are also given."
2201.00364,Exploring temperature dependent electron-electron interaction of topological crystalline insulators (SnS and SnSe) within Matsubara-time domain,"['Antik Sihi', 'Sudhir K. Pandey']",ARXIV,http://arxiv.org/pdf/2201.00364v1,2022-01-02T14:47:22Z,2022-01-02T14:47:22Z,"['10.48550/arXiv.2201.00364', '10.1088/1361-648X/ac5f62']","Both experimental and theoretical studies show non-trivial topological behaviour in native rocksalt phase for SnS and SnSe and categorize these materials in topological crystalline insulators. Here, the detailed electronic structures studies of SnS and SnSe in the rocksalt phase are carried out using many-body $GW$ based theory and density functional theory both for ground states and temperature dependent excited states. The estimated values of fundamental direct bandgaps around L-point using $G_0W_0$ (mBJ) are $\sim$0.27 ($\sim$0.13) eV and $\sim$0.37 ($\sim$0.17) eV for SnS and SnSe, respectively. The strength of hybridization between Sn 5$p$ and S 3$p$ (Se 4$p$) orbitals for SnS (SnSe) shows strong k-dependence. The behaviour of $\overline{W}$ ($\omega$), which is the averaged value of diagonal matrix elements of fully screened Coulomb interaction, suggests to use full-$GW$ method for exploring the excited states because the correlation effects within these two materials are relatively weak. The temperature dependent electronic structure calculations for SnS and SnSe provide linearly decreasing behaviour of bandgaps with rise in temperatures. The existence of collective excitation of quasiparticles in form of plasmon is predicted for these compounds, where the estimated values of plasmon frequency are $\sim$9.5 eV and $\sim$9.3 eV for SnS and SnSe, respectively. The imaginary part of self-energy and mass renormalization factor ($Z_\textbf{k}(\omega)$) due to electron-electron interaction (EEI) are also calculated along W-L-$\Gamma$ direction for both the materials. The present comparative study reveals that the behaviour of temperature dependent EEI for SnS and SnSe are the almost same and EEI is important for high temperature transport properties."
2201.00142,Impact of Evolving Protocols and COVID-19 on Internet Traffic Shares,"['Luca Schumann', 'Trinh Viet Doan', 'Tanya Shreedhar', 'Ricky Mok', 'Vaibhav Bajpai']",ARXIV,http://arxiv.org/pdf/2201.00142v2,2022-01-01T07:51:16Z,2022-01-15T17:36:53Z,['10.48550/arXiv.2201.00142'],"The rapid deployment of new Internet protocols over the last few years and the COVID-19 pandemic more recently (2020) has resulted in a change in the Internet traffic composition. Consequently, an updated microscopic view of traffic shares is needed to understand how the Internet is evolving to capture both such shorter- and longer-term events. Toward this end, we observe traffic composition at a research network in Japan and a Tier-1 ISP in the USA. We analyze the traffic traces passively captured at two inter-domain links: MAWI (Japan) and CAIDA (New York-Sao Paulo), which cover 100GB of data for MAWI traces and 4TB of data for CAIDA traces in total. We begin by studying the impact of COVID-19 on the MAWI link: We find a substantial increase in the traffic volume of OpenVPN and rsync, as well as increases in traffic volume from cloud storage and video conferencing services, which shows that clients shift to remote work during the pandemic. For traffic traces between March 2018 to December 2018, we find that the use of IPv6 is increasing quickly on the CAIDA monitor: The IPv6 traffic volume increases from 1.1% in March 2018 to 6.1% in December 2018, while the IPv6 traffic share remains stable in the MAWI dataset at around 9% of the traffic volume. Among other protocols at the application layer, 60%-70% of IPv4 traffic on the CAIDA link is HTTP(S) traffic, out of which two-thirds are encrypted; for the MAWI link, more than 90% of the traffic is Web, of which nearly 75% is encrypted. Compared to previous studies, this depicts a larger increase in encrypted Web traffic of up to a 3-to-1 ratio of HTTPS to HTTP. As such, our observations in this study further reconfirm that traffic shares change with time and can vary greatly depending on the vantage point studied despite the use of the same generalized methodology and analyses, which can also be applied to other traffic monitoring datasets."
2201.00481,Optimal Reinsurance to Minimize the Probability of Drawdown under the Mean-Variance Premium Principle: Asymptotic Analysis,"['Pablo Azcue', 'Xiaoqing Liang', 'Nora Muler', 'Virginia R. Young']",ARXIV,http://arxiv.org/pdf/2201.00481v1,2022-01-03T05:25:00Z,2022-01-03T05:25:00Z,['10.48550/arXiv.2201.00481'],"In this paper, we consider an optimal reinsurance problem to minimize the probability of drawdown for the scaled Cram\'er-Lundberg risk model when the reinsurance premium is computed according to the mean-variance premium principle. We extend the work of Liang et al. [16] to the case of minimizing the probability of drawdown. By using the comparison method and the tool of adjustment coefficients, we show that the minimum probability of drawdown for the scaled classical risk model converges to the minimum probability for its diffusion approximation, and the rate of convergence is of order $O(n^{-1/2})$. We further show that using the optimal strategy from the diffusion approximation in the scaled classical risk model is $O(n^{-1/2})$-optimal."
2201.00198,"Symmetric Matrices, Signed Graphs, and Nodal Domain Theorems","['Chuanyuan Ge', 'Shiping Liu']",ARXIV,http://arxiv.org/pdf/2201.00198v3,2022-01-01T14:51:55Z,2022-10-20T02:25:39Z,['10.48550/arXiv.2201.00198'],"In 2001, Davies, Gladwell, Leydold, and Stadler proved discrete nodal domain theorems for eigenfunctions of generalized Laplacians, i.e., symmetric matrices with non-positive off-diagonal entries. In this paper, we establish nodal domain theorems for arbitrary symmetric matrices by exploring the induced signed graph structure. Our concepts of nodal domains for any function on a signed graph are switching invariant. When the induced signed graph is balanced, our definitions and upper bound estimates reduce to existing results for generalized Laplacians. Our approach provides a more conceptual understanding of Fiedler's results on eigenfunctions of acyclic matrices. This new viewpoint leads to lower bound estimates for the number of strong nodal domains which improves previous results of Berkolaiko and Xu-Yau. We also prove a new type of lower bound estimates by a duality argument."
2201.00338,Convergence rates for the joint solution of inverse problems with compressed sensing data,"['Andrea Ebner', 'Markus Haltmeier']",ARXIV,http://arxiv.org/pdf/2201.00338v2,2022-01-02T11:25:25Z,2022-05-16T09:01:15Z,"['10.48550/arXiv.2201.00338', '10.1088/1361-6420/aca5ae']","Compressed sensing (CS) is a powerful tool for reducing the amount of data to be collected while maintaining high spatial resolution. Such techniques work well in practice and at the same time are supported by solid theory. Standard CS results assume measurements to be made directly on the targeted signal. In many practical applications, however, CS information can only be taken from indirect data $h_\star = W x_\star$ related to the original signal by an additional forward operator. If inverting the forward operator is ill-posed, then existing CS theory is not applicable. In this paper, we address this issue and present two joint reconstruction approaches, namely relaxed $\ell^1$ co-regularization and strict $\ell^1$ co-regularization, for CS from indirect data. As main results, we derive error estimates for recovering $x_\star$ and $h_\star$. In particular, we derive a linear convergence rate in the norm for the latter. To obtain these results, solutions are required to satisfy a source condition and the CS measurement operator is required to satisfy a restricted injectivity condition. We further show that these conditions are not only sufficient but even necessary to obtain linear convergence."
2201.00130,Structural Diversity and Superconductivity in S-P-H Ternary Hydrides Under Pressure,"['Nisha Geng', 'Tiange Bi', 'Eva Zurek']",ARXIV,http://arxiv.org/pdf/2201.00130v1,2022-01-01T06:47:58Z,2022-01-01T06:47:58Z,"['10.48550/arXiv.2201.00130', '10.1021/acs.jpcc.1c10976']","Evolutionary structure searches revealed a plethora of stable and low-enthalpy metastable phases in the S-P-H ternary phase diagram under pressure. A wide variety of crystalline structure types were uncovered ranging from those possessing one-dimensional chains, two-dimensional sheets based on S-H or S-P-H square lattices as well as S-H or P-H honeycombs, and cage-like structures. Some of the cage-like structures could be derived from doping the high-pressure high-temperature superconducting $Im\bar{3}m$ H$_3$S phase with phosphorous. Most of the discovered compounds were metallic, however those derived from $Im\bar{3}m$ H$_3$S lattices with low levels of P-doping were predicted to possess the highest superconducting critical temperatures ($T_c$s). The propensity for phosphorous to assume octahedral coordination, as well as the similar radii of sulfur and phosphorous are key to maintaining a high density of states at the Fermi level in $Im\bar{3}m$ S$_{0.875}$P$_{0.125}$H$_3$, whose $T_c$ was estimated to be similar to that of H$_3$S at 200~GPa."
2201.00482,On the Shafarevich conjecture for irreducible symplectic varieties,['Teppei Takamatsu'],ARXIV,http://arxiv.org/pdf/2201.00482v2,2022-01-03T05:29:30Z,2022-04-25T02:45:48Z,['10.48550/arXiv.2201.00482'],"Irreducible symplectic varieties are higher-dimensional analogues of K3 surfaces. In this paper, we prove the Shafarevich conjecture for irreducible symplectic varieties of fixed deformation class. We also observe that the second cohomological generalization of the Shafarevich conjecture does not hold in general, and discuss another formulation of a cohomological generalization."
2201.00373,Percolation on spatial anisotropic networks,"['Ouriel Gotesdyner', 'Bnaya Gross', 'Dana Vaknin Ben Porath', 'Shlomo Havlin']",ARXIV,http://arxiv.org/pdf/2201.00373v1,2022-01-02T16:01:13Z,2022-01-02T16:01:13Z,"['10.48550/arXiv.2201.00373', '10.1088/1751-8121/ac6914']","Many realistic systems such as infrastructures are characterized by spatial structure and anisotropic alignment. Here we propose and study a model for dealing with such characteristics by introducing a parameter that controls the strength of the anisotropy in the spatial network. This parameter is added to an existing isotropic model used to describe networks under spatial constraints, thus generalizing the spatial model to take into account both spatial and anisotropic features. We study the resilience of such networks by using a percolation process and find that anisotropy has a negative impact on a network's robustness. In addition, our results suggest that the anisotropy in this model does not affect the critical exponent of the correlation length, $\nu$, which remains the same as the known $\nu$ in 2D isotropic lattices."
2201.00178,Imaging the Sun's near-surface flows using mode-coupling analysis,"['Prasad Mani', 'Chris Hanson', 'Shravan Hanasoge']",ARXIV,http://arxiv.org/pdf/2201.00178v1,2022-01-01T12:19:02Z,2022-01-01T12:19:02Z,"['10.48550/arXiv.2201.00178', '10.3847/1538-4357/ac474e']","The technique of normal-mode coupling is a powerful tool with which to seismically image non-axisymmetric phenomena in the Sun. Here we apply mode coupling in the Cartesian approximation to probe steady, near-surface flows in the Sun. Using Doppler cubes obtained from the Helioseismic and Magnetic Imager onboard the Solar Dynamics Observatory, we perform inversions on mode-coupling measurements to show that the resulting divergence and radial vorticity maps at supergranular length scales ($\sim$30 Mm) near the surface compare extremely well with those obtained using the Local Correlation Tracking method. We find that the Pearson correlation coefficient is $\geq$ 0.9 for divergence flows, while $\geq$ 0.8 is obtained for the radial vorticity."
2201.00395,Operator spreading in quantum hardcore gases,['Marko Medenjak'],ARXIV,http://arxiv.org/pdf/2201.00395v2,2022-01-02T19:20:46Z,2022-09-06T09:21:34Z,"['10.48550/arXiv.2201.00395', '10.1088/1751-8121/ac8fc4']","In this article we study a set of integrable quantum cellular automata,the quantum hardcore gases (QHCG), with an arbitrary local Hilbert space dimension, and discuss the matrix product ansatz based approach for solving the dynamics of local operators analytically. Subsequently, we focus on the dynamics of operator spreading, in particular on the out-of-time ordered correlation functions (OTOCs), operator weight spreading and operators space entanglement entropy (OSEE). All of the quantities were conjectured to provide signifying features of integrable systems and quantum chaos. We show that in QHCG OTOCs spread diffusively and that in the limit of the large local Hilbert space dimension they increase linearly with time, despite their integrability. On the other hand, it was recently conjectured that operator weight front, which is associated with the extent of operators, spreads diffusively in both, integrable and generic systems, but its decay seems to differ in these two cases. We observe that the spreading of the operator weight front in QHCG is markedly different from chaotic, generic integrable and free systems, as the front freezes in the long time limit. Finally, we discuss the OSEE in QHCG and show that it grows at most logarithmically with time in accordance with the conjectured behaviour for interacting integrable systems."
2201.00105,Topological confinement in Skyrme holography,"['Casey Cartwright', 'Benjamin Harms', 'Matthias Kaminski', 'Ronny Thomale']",ARXIV,http://arxiv.org/pdf/2201.00105v2,2022-01-01T03:33:41Z,2022-01-05T19:59:38Z,"['10.48550/arXiv.2201.00105', '10.1088/1361-6382/ac6c73']","We study phase transitions in five-dimensional Einstein Gravity with a negative cosmological constant, coupled to a Skyrme matter field. These transitions are topological generalizations of the Hawking-Page transition between thermal Anti de Sitter (AdS) spacetime and an AdS black hole. Phases are characterized by a topological number associated with the Skyrme field configuration. Depending on that topological number and on the Skyrme coupling strength, there occur transitions between those phases at two, one, or no value(s) of the temperature. Through the holographic (AdS/CFT) correspondence, these solutions are dual to topologically non-trivial states in a conformal field theory (CFT) with an SU(2)-symmetry, which support either confined or deconfined (quasi-)particles at strong coupling. We compare to similar known phase transitions, and discuss potential applications to confinement in topological phases of condensed matter and the quark-gluon plasma."
2201.00176,Correlation inequalities for the uniform 8-vertex model and the toric code model,"['Jakob E. Björnberg', 'Benjamin Lees']",ARXIV,http://arxiv.org/pdf/2201.00176v1,2022-01-01T12:10:39Z,2022-01-01T12:10:39Z,['10.48550/arXiv.2201.00176'],"We elucidate connections between four models in statistical physics and probability theory: (1) the toric code model of Kitaev, (2) the uniform eight-vertex model, (3) random walk on a hypercube, and (4) a classical Ising model with four-body interaction. As a consequence of our analysis (and of the GKS-inequalities for the Ising model) we obtain correlation inequalities for the toric code model and the uniform eight-vertex model."
2201.00108,The Mathieu group $M_{23}$ as additive functions on the finite field of size ${2^{11}}$,"['Yiming Bing', 'Bright Hu', 'Ronni Hu', 'Rhianna Li', 'Stefan Lu', 'Finn McDonald', 'Michael Sun', 'Nicholas Wolfe', 'Joshua Yao', 'Leon Zhou', 'Nathan Zhou']",ARXIV,http://arxiv.org/pdf/2201.00108v1,2022-01-01T03:58:49Z,2022-01-01T03:58:49Z,['10.48550/arXiv.2201.00108'],"We explicitly extend the standard permutation action of the Mathieu group $M_{23}$ on a 23 element set $C=C_{23}$ contained in a finite field of $2^{11}$ elements $\mathbb{F}_{2^{11}}$ to additive functions on this finite field. That is we represent $M_{23}$ as functions $\varphi:\mathbb{F}_{2^{11}}\to \mathbb{F}_{2^{11}}$ such that $\varphi(x+y)=\varphi(x)+\varphi(y)$ and $\varphi|_{C}$ is the standard permutation action. We give explicit $11\times 11$ matrices for the pair of standard generators of order $23$ and order $5$, as well as many tables to help facilitate future calculations."
2201.00412,Bayesian Generalized Additive Model Selection Including a Fast Variational Option,"['Virginia X. He', 'Matt P. Wand']",ARXIV,http://arxiv.org/pdf/2201.00412v6,2022-01-02T20:16:19Z,2023-09-28T05:43:49Z,['10.48550/arXiv.2201.00412'],"We use Bayesian model selection paradigms, such as group least absolute shrinkage and selection operator priors, to facilitate generalized additive model selection. Our approach allows for the effects of continuous predictors to be categorized as either zero, linear or non-linear. Employment of carefully tailored auxiliary variables results in Gibbsian Markov chain Monte Carlo schemes for practical implementation of the approach. In addition, mean field variational algorithms with closed form updates are obtained. Whilst not as accurate, this fast variational option enhances scalability to very large data sets. A package in the R language aids use in practice."
2201.00245,Extremely strong DLAs at high redshift: Gas cooling and H$_2$ formation,"['K. N. Telikova', 'S. A. Balashev', 'P. Noterdaeme', 'J. -K. Krogager', 'A. Ranjan']",ARXIV,http://arxiv.org/pdf/2201.00245v1,2022-01-01T22:35:42Z,2022-01-01T22:35:42Z,"['10.48550/arXiv.2201.00245', '10.1093/mnras/stab3800']","We present a spectroscopic investigation with VLT/X-shooter of seven candidate extremely strong damped Lyman-$\alpha$ absorption systems (ESDLAs, $N(\text{HI})\ge 5\times 10^{21}$ cm$^{-2}$) observed along quasar sightlines. We confirm the extremely high column densities, albeit slightly (0.1~dex) lower than the original ESDLA definition for four systems. We measured low-ionisation metal abundances and dust extinction for all systems. For two systems we also found strong associated H$_2$ absorption $\log N(\text{H$_2$)[cm$^{-2}$]}=18.16\pm0.03$ and $19.28\pm0.06$ at $z=3.26$ and $2.25$ towards J2205+1021 and J2359+1354, respectively), while for the remaining five we measured conservative upper limits on the H$_2$ column densities of typically $\log N(\text{H$_2$)[cm$^{-2}$]}<17.3$. The increased H$_2$ detection rate ($10-55$% at 68% confidence level) at high HI column density compared to the overall damped Lyman-$\alpha$ population ($\sim 5-10$%) confirms previous works. We find that these seven ESDLAs have similar observed properties as those previously studied towards quasars and gamma-ray burst afterglows, suggesting they probe inner regions of galaxies. We use the abundance of ionised carbon in excited fine-structure level to calculate the cooling rates through the CII $\lambda$158$\mu$m emission, and compare them with the cooling rates from damped Lyman-$\alpha$ systems in the literature. We find that the cooling rates distribution of ESDLAs also presents the same bimodality as previously observed for the general (mostly lower HI column density) damped Lyman-$\alpha$ population."
2201.00418,Succinct Differentiation of Disparate Boosting Ensemble Learning Methods for Prognostication of Polycystic Ovary Syndrome Diagnosis,"['Abhishek Gupta', 'Sannidhi Shetty', 'Raunak Joshi', 'Ronald Melwin Laban']",ARXIV,http://arxiv.org/pdf/2201.00418v2,2022-01-02T21:06:41Z,2022-08-14T00:49:40Z,"['10.48550/arXiv.2201.00418', '10.1109/ICAC353642.2021.9697163']","Prognostication of medical problems using the clinical data by leveraging the Machine Learning techniques with stellar precision is one of the most important real world challenges at the present time. Considering the medical problem of Polycystic Ovary Syndrome also known as PCOS is an emerging problem in women aged from 15 to 49. Diagnosing this disorder by using various Boosting Ensemble Methods is something we have presented in this paper. A detailed and compendious differentiation between Adaptive Boost, Gradient Boosting Machine, XGBoost and CatBoost with their respective performance metrics highlighting the hidden anomalies in the data and its effects on the result is something we have presented in this paper. Metrics like Confusion Matrix, Precision, Recall, F1 Score, FPR, RoC Curve and AUC have been used in this paper."
2201.00382,ECOD: Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions,"['Zheng Li', 'Yue Zhao', 'Xiyang Hu', 'Nicola Botta', 'Cezar Ionescu', 'George H. Chen']",ARXIV,http://arxiv.org/pdf/2201.00382v3,2022-01-02T17:28:35Z,2022-08-25T01:50:19Z,"['10.48550/arXiv.2201.00382', '10.1109/TKDE.2022.3159580']","Outlier detection refers to the identification of data points that deviate from a general data distribution. Existing unsupervised approaches often suffer from high computational cost, complex hyperparameter tuning, and limited interpretability, especially when working with large, high-dimensional datasets. To address these issues, we present a simple yet effective algorithm called ECOD (Empirical-Cumulative-distribution-based Outlier Detection), which is inspired by the fact that outliers are often the ""rare events"" that appear in the tails of a distribution. In a nutshell, ECOD first estimates the underlying distribution of the input data in a nonparametric fashion by computing the empirical cumulative distribution per dimension of the data. ECOD then uses these empirical distributions to estimate tail probabilities per dimension for each data point. Finally, ECOD computes an outlier score of each data point by aggregating estimated tail probabilities across dimensions. Our contributions are as follows: (1) we propose a novel outlier detection method called ECOD, which is both parameter-free and easy to interpret; (2) we perform extensive experiments on 30 benchmark datasets, where we find that ECOD outperforms 11 state-of-the-art baselines in terms of accuracy, efficiency, and scalability; and (3) we release an easy-to-use and scalable (with distributed support) Python implementation for accessibility and reproducibility."
2201.00145,Matrix Decomposition and Applications,['Jun Lu'],ARXIV,http://arxiv.org/pdf/2201.00145v3,2022-01-01T08:13:48Z,2023-12-28T08:19:55Z,['10.48550/arXiv.2201.00145'],"In 1954, Alston S. Householder published Principles of Numerical Analysis, one of the first modern treatments on matrix decomposition that favored a (block) LU decomposition-the factorization of a matrix into the product of lower and upper triangular matrices. And now, matrix decomposition has become a core technology in machine learning, largely due to the development of the back propagation algorithm in fitting a neural network. The sole aim of this survey is to give a self-contained introduction to concepts and mathematical tools in numerical linear algebra and matrix analysis in order to seamlessly introduce matrix decomposition techniques and their applications in subsequent sections. However, we clearly realize our inability to cover all the useful and interesting results concerning matrix decomposition and given the paucity of scope to present this discussion, e.g., the separated analysis of the Euclidean space, Hermitian space, Hilbert space, and things in the complex domain. We refer the reader to literature in the field of linear algebra for a more detailed introduction to the related fields."
2201.00226,Simplicial Quantum Gravity,['James B. Hartle'],ARXIV,http://arxiv.org/pdf/2201.00226v2,2022-01-01T18:20:07Z,2022-01-25T22:07:04Z,['10.48550/arXiv.2201.00226'],Simplicial approximation and the ideas associated with the Regge calculus.provide a concrete way of implementing a sum over histories formulation ofquantum gravity. A four-dimensional simplicial geometry is made up of flat four-simplices joined together.A sum over simplicial geometries is a sum over thedifferent ways the simplices can be joined together with an integral over their edge lengths.Theconstruction of the simplicial Euclidean action for this approach to quantum general relativity is illustrated. The recovery of the diffeomorphism group in the continuum limit is discussed. Some possible classes of simplicial complexes with which to define a sum over topologies are described.
2201.00144,Negative Imaginary Systems Theory for Nonlinear Systems: A Dissipativity Approach,"['Ahmed G. Ghallab', 'Ian R. Petersen']",ARXIV,http://arxiv.org/pdf/2201.00144v1,2022-01-01T08:10:55Z,2022-01-01T08:10:55Z,['10.48550/arXiv.2201.00144'],"Negative imaginary (NI) systems theory is a well-established system theoretic framework for analysis and design of linear-time-invariant (LTI) control systems. In this paper, we aim to generalize negative imaginary systems theory to a class of nonlinear systems. Based on the time domain interpretation of the NI property for LTI systems, a formal definition in terms of a dissipativity with an appropriate work rate will be used to define the nonlinear negative imaginary (NNI) property for a general nonlinear system. Mechanical systems with force actuators and position sensors are nonlinear negative imaginary according to this new definition. Using Lyapunov stability theory, we seek to establish a nonlinear generalization of the NI robust stability result for positive feedback interconnections of NNI systems. An example of a nonlinear mass-spring-damper system with force as input and displacement of the mass as output will be presented to illustrate the applicability of the NNI stability result. Furthermore, the case of NI systems with free motion will be investigated in the nonlinear domain based on the dissipativity framework of NNI systems."
2201.00137,Sum-of-Squares Program and Safe Learning On Maximizing the Region of Attraction of Partially Unknown Systems,"['Dongkun Han', 'Hejun Huang']",ARXIV,http://arxiv.org/pdf/2201.00137v1,2022-01-01T07:13:59Z,2022-01-01T07:13:59Z,['10.48550/arXiv.2201.00137'],"Recent advances in learning techniques have enabled the modelling of unknown dynamical systems directly from data. However, in many contexts, these learning-based methods are short of safety guarantee and strict stability verification. To address this issue, this paper first approximates the partially unknown nonlinear systems by using a learned state space with Gaussian Processes and Chebyshev interpolants. A Sum-of-Squares Programming based approach is then proposed to synthesize a controller by searching an optimal control Lyapunov Barrier function. In this way, we maximize the estimated region of attraction of partially unknown nonlinear systems, while guaranteeing both safety and stability. It is shown that the proposed method improves the extrapolation performance, and at the same time, generates a significantly larger estimated region of attraction."
2201.00435,Transfer-learning-based Surrogate Model for Thermal Conductivity of Nanofluids,"['Saeel S. Pai', 'Abhijeet Banthiya']",ARXIV,http://arxiv.org/pdf/2201.00435v1,2022-01-02T23:55:12Z,2022-01-02T23:55:12Z,['10.48550/arXiv.2201.00435'],"Heat transfer characteristics of nanofluids have been extensively studied since the 1990s. Research investigations show that the suspended nanoparticles significantly alter the suspension's thermal properties. The thermal conductivity of nanofluids is one of the properties that is generally found to be greater than that of the base fluid. This increase in thermal conductivity is found to depend on several parameters. Several theories have been proposed to model the thermal conductivities of nanofluids, but there is no reliable universal theory yet to model the anomalous thermal conductivity of nanofluids. In recent years, supervised data-driven methods have been successfully employed to create surrogate models across various scientific disciplines, especially for modeling difficult-to-understand phenomena. These supervised learning methods allow the models to capture highly non-linear phenomena. In this work, we have taken advantage of existing correlations and used them concurrently with available experimental results to develop more robust surrogate models for predicting the thermal conductivity of nanofluids. Artificial neural networks are trained using the transfer learning approach to predict the thermal conductivity enhancement of nanofluids with spherical particles for 32 different particle-fluid combinations (8 particles materials and 4 fluids). The large amount of lower accuracy data generated from correlations is used to coarse-tune the model parameters, and the limited amount of more trustworthy experimental data is used to fine-tune the model parameters. The transfer learning-based models' results are compared with those from baseline models which are trained only on experimental data using a goodness of fit metric. It is found that the transfer learning models perform better with goodness of fit values of 0.93 as opposed to 0.83 from the baseline models."
2201.00203,NOMA Computation Over Multi-Access Channels for Multimodal Sensing,"['Michel Kulhandjian', 'Gunes Karabulut Kurt', 'Hovannes Kulhandjian', 'Halim Yanikomeroglu', ""Claude D'Amours""]",ARXIV,http://arxiv.org/pdf/2201.00203v1,2022-01-01T15:04:26Z,2022-01-01T15:04:26Z,['10.48550/arXiv.2201.00203'],"An improved mean squared error (MSE) minimization solution based on eigenvector decomposition approach is conceived for wideband non-orthogonal multiple-access based computation over multi-access channel (NOMA-CoMAC) framework. This work aims at further developing NOMA-CoMAC for next-generation multimodal sensor networks, where a multimodal sensor monitors several environmental parameters such as temperature, pollution, humidity, or pressure. We demonstrate that our proposed scheme achieves an MSE value approximately 0.7 lower at E_b/N_o = 1 dB in comparison to that for the average sum-channel based method. Moreover, the MSE performance gain of our proposed solution increases even more for larger values of subcarriers and sensor nodes due to the benefit of the diversity gain. This, in return, suggests that our proposed scheme is eminently suitable for multimodal sensor networks."
2201.00276,Reconstruction of Fission Events in Heavy Ion Reactions with CSHINE,"['Xinyue Diao', 'Fenhai Guan', 'Yijie Wang', 'Yuhao Qin', 'Zhi Qin', 'Dong Guo', 'Qianghua Wu', 'Dawei Si', 'Xuan Zhao', 'Sheng Xiao', 'Yaopeng Zhang', 'Xianglun Wei', 'Haichuan Zou', 'Herun Yang', 'Peng Ma', 'Rongjiang Hu', 'Limin Duan', 'Artur Dobrowolski', 'Krzysztof Pomorski', 'Zhigang Xiao']",ARXIV,http://arxiv.org/pdf/2201.00276v1,2022-01-02T02:31:46Z,2022-01-02T02:31:46Z,['10.48550/arXiv.2201.00276'],"We report the reconstruction method of the fast fission events in 25 MeV/u $^{86}$Kr +$^{208}$Pb reactions at the Compact Spectrometer for Heavy IoN Experiment (CSHINE). The fission fragments are measured by three large-area parallel plate avalanche counters, which can deliver the position and the arrival timing information of the fragments. The start timing information is given by the radio frequency of the cyclotron. Using the velocities of the two fission fragments, the fission events are reconstructed. The broadening of both the velocity distribution and the azimuthal difference of the fission fragments decrease with the folding angle, in accordance with the picture that fast fission occurs. The anisotropic angular distribution of the fission axis also reveals consistently the dynamic feature the fission events."
2201.00500,Uniaxial Strain-Induced Electronic Properties Alteration of MoS$_2$ Monolayer,"['A. Setiawan', 'I. P. Handayani', 'E. Suprayoga']",ARXIV,http://arxiv.org/pdf/2201.00500v1,2022-01-03T07:21:48Z,2022-01-03T07:21:48Z,['10.48550/arXiv.2201.00500'],"Molybdenum disulfide (MoS$_2$) has attracted interest owing to its strain-tuned electronic and optical properties, making it a promising candidate for applications in strain engineering devices. In this study, we investigate the effect of uniaxial strain on the electronic properties of MoS$_2$ monolayer using first-principles calculations. Results show that a crossover of the K-K direct to -K indirect bandgap transitions occur at a strain of 1.743%. Moreover, a strong correlation is observed between the modified bandgap and the density of states (DOS) of the Mo-4d and S-3p orbitals at the valence band maximum and conduction band minimum. The uniaxial strain-tuned interatomic distance along the a-crystallographic axis does not only alter the bandgap at different rates but also affects the DOS of the Mo-4d orbital and possible electronic transitions. This study clarifies the mechanism of the electronic structural modification of two-dimensional MoS2 monolayer, which may affect intervalley transitions."
2201.00501,A note on the squares of the form $\prod_{k=1}^n (2k^2+l)$ with $l$ odd,['Russelle Guadalupe'],ARXIV,http://arxiv.org/pdf/2201.00501v2,2022-01-03T07:29:02Z,2023-12-11T15:00:03Z,['10.48550/arXiv.2201.00501'],"Let $l$ be a positive odd integer. Using Cilleruelo's method, we establish an explicit lower bound $N_l$ depending on $l$ such that for all $n\geq N_l$, $\prod_{k=1}^n (2k^2+l)$ is not a square. As an application, we determine all values of $n$ such that $\prod_{k=1}^n (2k^2+l)$ is a square for certain values of $l$."
2201.00502,"Energy Conditions in Non-minimally Coupled $f(R,T)$ Gravity","['P. K. Sahoo', 'Sanjay Mandal', 'Simran Arora']",ARXIV,http://arxiv.org/pdf/2201.00502v1,2022-01-03T07:29:56Z,2022-01-03T07:29:56Z,"['10.48550/arXiv.2201.00502', '10.1002/asna.202113886']","In today's scenario, going beyond Einstein's theory of gravity leads us to some more complete and modified gravity theories. One of them is the $f(R,T)$ gravity in which $ R $ is the Ricci scalar, and $ T $ is the trace of the energy-momentum tensor. Using a well-motivated linear $f(R,T)$ gravity model with a single parameter, we studied the strong energy condition (SEC), the weak energy condition (WEC), the null energy condition (NEC), and the dominant energy condition (DEC) under the simplest non-minimal matter geometry coupling with a perfect fluid distribution. The model parameter is constrained by energy conditions and a single parameter proposed equation of state (EoS), resulting in the compatibility of the $f(R,T)$ models with the accelerated expansion of the universe. It is seen that the EoS parameter illustrate the quintessence phase in a dominated accelerated phase, pinpoint to the cosmological constant yields as a prediction the phantom era. Also, the present values of the cosmological constant and the acceleration of the universe are used to check the viability of our linear $f(R,T)$ model of gravity. It is observed that the positive behavior of DEC and WEC indicates the validation of the model. In contrast, SEC is violating the condition resulting in the accelerated expansion of the universe."
2201.00503,Signal-Aware Direction-of-Arrival Estimation Using Attention Mechanisms,"['Wolfgang Mack', 'Julian Wechsler', 'Emanuël A. P. Habets']",ARXIV,http://arxiv.org/pdf/2201.00503v1,2022-01-03T07:30:00Z,2022-01-03T07:30:00Z,"['10.48550/arXiv.2201.00503', '10.1016/j.csl.2022.101363']","The direction-of-arrival (DOA) of sound sources is an essential acoustic parameter used, e.g., for multi-channel speech enhancement or source tracking. Complex acoustic scenarios consisting of sources-of-interest, interfering sources, reverberation, and noise make the estimation of the DOAs corresponding to the sources-of-interest a challenging task. Recently proposed attention mechanisms allow DOA estimators to focus on the sources-of-interest and disregard interference and noise, i.e., they are signal-aware. The attention is typically obtained by a deep neural network (DNN) from a short-time Fourier transform (STFT) based representation of a single microphone signal. Subsequently, attention has been applied as binary or ratio weighting to STFT-based microphone signal representations to reduce the impact of frequency bins dominated by noise, interference, or reverberation. The impact of attention on DOA estimators and different training strategies for attention and DOA DNNs are not yet studied in depth. In this paper, we evaluate systems consisting of different DNNs and signal processing-based methods for DOA estimation when attention is applied. Additionally, we propose training strategies for attention-based DOA estimation optimized via a DOA objective, i.e., end-to-end. The evaluation of the proposed and the baseline systems is performed using data generated with simulated and measured room impulse responses under various acoustic conditions, like reverberation times, noise, and source array distances. Overall, DOA estimation using attention in combination with signal-processing methods exhibits a far lower computational complexity than a fully DNN-based system; however, it yields comparable results."
2201.00504,R-Theta Local Neighborhood Pattern for Unconstrained Facial Image Recognition and Retrieval,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.00504v1,2022-01-03T07:39:23Z,2022-01-03T07:39:23Z,"['10.48550/arXiv.2201.00504', '10.1007/s11042-018-6846-z']","In this paper R-Theta Local Neighborhood Pattern (RTLNP) is proposed for facial image retrieval. RTLNP exploits relationships amongst the pixels in local neighborhood of the reference pixel at different angular and radial widths. The proposed encoding scheme divides the local neighborhood into sectors of equal angular width. These sectors are again divided into subsectors of two radial widths. Average grayscales values of these two subsectors are encoded to generate the micropatterns. Performance of the proposed descriptor has been evaluated and results are compared with the state of the art descriptors e.g. LBP, LTP, CSLBP, CSLTP, Sobel-LBP, LTCoP, LMeP, LDP, LTrP, MBLBP, BRINT and SLBP. The most challenging facial constrained and unconstrained databases, namely; AT&T, CARIA-Face-V5-Cropped, LFW, and Color FERET have been used for showing the efficiency of the proposed descriptor. Proposed descriptor is also tested on near infrared (NIR) face databases; CASIA NIR-VIS 2.0 and PolyU-NIRFD to explore its potential with respect to NIR facial images. Better retrieval rates of RTLNP as compared to the existing state of the art descriptors show the effectiveness of the descriptor"
2201.00505,Superquantile-based learning: a direct approach using gradient-based optimization,"['Yassine Laguel', 'Jérôme Malick', 'Zaid Harchaoui']",ARXIV,http://arxiv.org/pdf/2201.00505v1,2022-01-03T07:40:04Z,2022-01-03T07:40:04Z,['10.48550/arXiv.2201.00505'],"We consider a formulation of supervised learning that endows models with robustness to distributional shifts from training to testing. The formulation hinges upon the superquantile risk measure, also known as the conditional value-at-risk, which has shown promise in recent applications of machine learning and signal processing. We show that, thanks to a direct smoothing of the superquantile function, a superquantile-based learning objective is amenable to gradient-based optimization, using batch optimization algorithms such as gradient descent or quasi-Newton algorithms, or using stochastic optimization algorithms such as stochastic gradient algorithms. A companion software SPQR implements in Python the algorithms described and allows practitioners to experiment with superquantile-based supervised learning."
2201.00506,Total Controllability of nonlocal semilinear functional evolution equations with non-instantaneous impulses,"['J. Kumar', 'S. Singh', 'S. Arora', 'J. Dabas']",ARXIV,http://arxiv.org/pdf/2201.00506v1,2022-01-03T07:40:08Z,2022-01-03T07:40:08Z,['10.48550/arXiv.2201.00506'],"In this article, we are discussing a more vital concept of controllability, termed total controllability. We have considered a nonlocal semilinear functional evolution equations with non-instantaneous impulses and finite delay in Hilbert spaces. A set of sufficient conditions of total controllability is obtained for the evolution system under consideration, by imposing the theory of C_0-semigroup and Banach fixed point theorem. We also established the total controllability results for a functional integro-differential equation. Finally, an example is given to demonstrate the feasibility of derived abstract results."
2201.00507,Tensile material instabilities in elastic beam lattices lead to a bounded stability domain,"['G. Bordiga', 'D. Bigoni', 'A. Piccolroaz']",ARXIV,http://arxiv.org/pdf/2201.00507v2,2022-01-03T07:41:08Z,2022-06-02T09:52:38Z,"['10.48550/arXiv.2201.00507', '10.1098/rsta.2021.0388']","Homogenization of the incremental response of grids made up of preloaded elastic rods leads to homogeneous effective continua which may suffer macroscopic instability, occurring at the same time in both the grid and the effective continuum. This instability corresponds to the loss of ellipticity in the effective material and the formation of localized responses as, for instance, shear bands. Using lattice models of elastic rods, loss of ellipticity has always been found to occur for stress states involving compression of the rods, as usually these structural elements buckle only under compression. In this way, the locus of material stability for the effective solid is unbounded in tension, i.e. the material is always stable for a tensile prestress. A rigorous application of homogenization theory is proposed to show that the inclusion of sliders (constraints imposing axial and rotational continuity, but allowing shear jumps) in the grid of rods leads to loss of ellipticity in tension, so that the locus for material instability becomes bounded. This result explains (i.) how to design elastic materials passible of localization of deformation and shear banding for all radial stress paths; (ii.) how for all these paths a material may fail by developing strain localization and without involving cracking."
2201.00508,Superquantiles at Work: Machine Learning Applications and Efficient Subgradient Computation,"['Yassine Laguel', 'Krishna Pillutla', 'Jérôme Malick', 'Zaid Harchaoui']",ARXIV,http://arxiv.org/pdf/2201.00508v1,2022-01-03T07:42:48Z,2022-01-03T07:42:48Z,['10.48550/arXiv.2201.00508'],"R. Tyrell Rockafellar and collaborators introduced, in a series of works, new regression modeling methods based on the notion of superquantile (or conditional value-at-risk). These methods have been influential in economics, finance, management science, and operations research in general. Recently, they have been the subject of a renewed interest in machine learning, to address issues of distributional robustness and fair allocation. In this paper, we review some of these new applications of the superquantile, with references to recent developments. These applications involve nonsmooth superquantile-based objective functions that admit explicit subgradient calculations. To make these superquantile-based functions amenable to the gradient-based algorithms popular in machine learning, we show how to smooth them by infimal convolution and describe numerical procedures to compute the gradients of the smooth approximations. We put the approach into perspective by comparing it to other smoothing techniques and by illustrating it on toy examples."
2201.00509,Local Gradient Hexa Pattern: A Descriptor for Face Recognition and Retrieval,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.00509v1,2022-01-03T07:45:36Z,2022-01-03T07:45:36Z,['10.48550/arXiv.2201.00509'],"Local descriptors used in face recognition are robust in a sense that these descriptors perform well in varying pose, illumination and lighting conditions. Accuracy of these descriptors depends on the precision of mapping the relationship that exists in the local neighborhood of a facial image into microstructures. In this paper a local gradient hexa pattern (LGHP) is proposed that identifies the relationship amongst the reference pixel and its neighboring pixels at different distances across different derivative directions. Discriminative information exists in the local neighborhood as well as in different derivative directions. Proposed descriptor effectively transforms these relationships into binary micropatterns discriminating interclass facial images with optimal precision. Recognition and retrieval performance of the proposed descriptor has been compared with state-of-the-art descriptors namely LDP and LVP over the most challenging and benchmark facial image databases, i.e. Cropped Extended Yale-B, CMU-PIE, color-FERET, and LFW. The proposed descriptor has better recognition as well as retrieval rates compared to state-of-the-art descriptors."
2201.00510,Solitons in curved spacetime,['Susobhan Mandal'],ARXIV,http://arxiv.org/pdf/2201.00510v1,2022-01-03T07:46:12Z,2022-01-03T07:46:12Z,"['10.48550/arXiv.2201.00510', '10.1209/0295-5075/ac31dc']","Derrick's theorem is an important result that decides the existence of soliton configurations in field theories in different dimensions. It is proved using the extremization of finite energy of configurations under the scaling transformation. According to this theorem, the $2+1$ dimension is the critical dimension for the existence of solitons in scalar field theories without the gauge fields. In the present article, Derrick's theorem is extended in a generic curved spacetime in a covariant manner. Moreover, the existence of solitons in conformally flat spacetimes and spherically symmetric spacetimes is also shown using the approach presented in this article. Further, the approach shown in the present article in order to derive the soliton configurations is not restricted to a particular form of the field potential or curved spacetime."
2201.00511,Centre Symmetric Quadruple Pattern: A Novel Descriptor for Facial Image Recognition and Retrieval,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.00511v1,2022-01-03T07:56:24Z,2022-01-03T07:56:24Z,"['10.48550/arXiv.2201.00511', '10.1016/j.patrec.2017.10.015']","Facial features are defined as the local relationships that exist amongst the pixels of a facial image. Hand-crafted descriptors identify the relationships of the pixels in the local neighbourhood defined by the kernel. Kernel is a two dimensional matrix which is moved across the facial image. Distinctive information captured by the kernel with limited number of pixel achieves satisfactory recognition and retrieval accuracies on facial images taken under constrained environment (controlled variations in light, pose, expressions, and background). To achieve similar accuracies under unconstrained environment local neighbourhood has to be increased, in order to encode more pixels. Increasing local neighbourhood also increases the feature length of the descriptor. In this paper we propose a hand-crafted descriptor namely Centre Symmetric Quadruple Pattern (CSQP), which is structurally symmetric and encodes the facial asymmetry in quadruple space. The proposed descriptor efficiently encodes larger neighbourhood with optimal number of binary bits. It has been shown using average entropy, computed over feature images encoded with the proposed descriptor, that the CSQP captures more meaningful information as compared to state of the art descriptors. The retrieval and recognition accuracies of the proposed descriptor has been compared with state of the art hand-crafted descriptors (CSLBP, CSLTP, LDP, LBP, SLBP and LDGP) on bench mark databases namely; LFW, Colour-FERET, and CASIA-face-v5. Result analysis shows that the proposed descriptor performs well under controlled as well as uncontrolled variations in pose, illumination, background and expressions."
2201.00512,The Accretion flow in M87 is really MAD,"['Feng Yuan', 'Haiyang Wang', 'Hai Yang']",ARXIV,http://arxiv.org/pdf/2201.00512v1,2022-01-03T07:57:01Z,2022-01-03T07:57:01Z,"['10.48550/arXiv.2201.00512', '10.3847/1538-4357/ac4714']","The supermassive black holes in most galaxies in the universe are powered by hot accretion flows. Both theoretical analysis and numerical simulations have indicated that, depending on the degree of magnetization, black hole hot accretion flow is divided into two modes, namely SANE (standard and normal evolution) and MAD (magnetically arrested disk). It has been an important question which mode the hot accretion flows in individual sources should belong to in reality, SANE or MAD. This issue has been investigated in some previous works but they all suffer from various uncertainties. By using the measured rotation measure values in the prototype low-luminosity active galactic nuclei in {M87} at 2, 5, and 8 GHz along the jet at various distances from the black hole, combined with three dimensional general relativity magnetohydrodynamical numerical simulations of SANE and MAD, we show in this paper that the predicted rotation measure values by MAD are well consistent with observations, while the SANE model overestimates the rotation measure by over two orders of magnitude thus is ruled out."
2201.00513,Affine Iterations and Wrapping Effect: Various Approaches,['Nathalie Revol'],ARXIV,http://arxiv.org/pdf/2201.00513v1,2022-01-03T07:57:50Z,2022-01-03T07:57:50Z,['10.48550/arXiv.2201.00513'],"Affine iterations of the form x(n+1) = Ax(n) + b converge, using real arithmetic, if the spectral radius of the matrix A is less than 1. However, substituting interval arithmetic to real arithmetic may lead to divergence of these iterations, in particular if the spectral radius of the absolute value of A is greater than 1. We will review different approaches to limit the overestimation of the iterates, when the components of the initial vector x(0) and b are intervals. We will compare, both theoretically and experimentally, the widths of the iterates computed by these different methods: the naive iteration, methods based on the QR-and SVD-factorization of A, and Lohner's QR-factorization method. The method based on the SVD-factorization is computationally less demanding and gives good results when the matrix is poorly scaled, it is superseded either by the naive iteration or by Lohner's method otherwise."
2201.00514,Parallel adaptive weakly-compressible SPH for complex moving geometries,"['Asmelash Haftu', 'Abhinav Muta', 'Prabhu Ramachandran']",ARXIV,http://arxiv.org/pdf/2201.00514v3,2022-01-03T07:59:02Z,2022-05-14T12:30:24Z,"['10.48550/arXiv.2201.00514', '10.1016/j.cpc.2022.108377']","The use of adaptive spatial resolution to simulate flows of practical interest using Smoothed Particle Hydrodynamics (SPH) is of considerable importance. Recently, Muta and Ramachandran [1] have proposed an efficient adaptive SPH method which is capable of handling large changes in particle resolution. This allows the authors to simulate problems with much fewer particles than was possible earlier. The method was not demonstrated or tested with moving bodies or multiple bodies. In addition, the original method employed a large number of background particles to determine the spatial resolution of the fluid particles. In the present work we establish the formulation's effectiveness for simulating flow around stationary and moving geometries. We eliminate the need for the background particles in order to specify the geometry-based or solution-based adaptivity and we discuss the algorithms employed in detail. We consider a variety of benchmark problems, including the flow past two stationary cylinders, flow past different NACA airfoils at a range of Reynolds numbers, a moving square at various Reynolds numbers, and the flow past an oscillating cylinder. We also demonstrate different types of motions using single and multiple bodies. The source code is made available under an open source license, and our results are reproducible."
2201.00515,On the decay property of the cubic fourth-order Schrödinger equation,"['Xueying Yu', 'Haitian Yue', 'Zehua Zhao']",ARXIV,http://arxiv.org/pdf/2201.00515v1,2022-01-03T08:09:38Z,2022-01-03T08:09:38Z,"['10.48550/arXiv.2201.00515', '10.1090/proc/16325']","In this short paper, we prove that the solution of the cubic fourth-order Schr\""odinger equation (4NLS) on $\mathbb{R}^d$ ($5 \leq d \leq 8$) enjoys the same (pointwise) decay property as its linear solution does. This result is proved via a bootstrap argument based on the corresponding global result Pausader \cite{Pau1}. This result can be extended to more general dispersive equations (including some more 4NLS models) with scattering asymptotics."
2201.00516,Deep-potential enabled multiscale simulation of gallium nitride devices on boron arsenide cooling substrates,"['Jing Wu', 'E Zhou', 'An Huang', 'Hongbin Zhang', 'Ming Hu', 'Guangzhao Qin']",ARXIV,http://arxiv.org/pdf/2201.00516v2,2022-01-03T08:09:41Z,2022-01-13T06:45:51Z,['10.48550/arXiv.2201.00516'],"High-efficient heat dissipation plays critical role for high-power-density electronics. Experimental synthesis of ultrahigh thermal conductivity boron arsenide (BAs, 1300 W m-1K-1) cooling substrates into the wide-bandgap semiconductor of gallium nitride (GaN) devices has been realized [Nature Electronics 4, 416-423 (2021)]. However, the lack of systematic analysis on the heat transfer across the BAs-GaN interface hampers the practical applications. In this study, by constructing the accurate and high-efficient machine learning interatomic potentials, we performed multiscale simulations of the BAs-GaN heterostructures. Ultrahigh interfacial thermal conductance (ITC) of 265 MW m-2K-1 is achieved, which lies in the well-matched lattice vibrations of BAs and GaN. Moreover, the competition between grain size and boundary resistance was revealed with size increasing from 1 nm to 100 {\mu}m. Such deep-potential equipped multiscale simulations not only promote the practical applications of BAs cooling substrates in electronics, but also offer new approach for designing advanced thermal management systems."
2201.00517,The study of lepton EDMs in $U(1)_X$ SSM,"['Lu-Hao Su', 'Dan He', 'Xing-Xing Dong', 'Tai-Fu Feng', 'Shu-Min Zhao']",ARXIV,http://arxiv.org/pdf/2201.00517v3,2022-01-03T08:16:01Z,2022-05-09T12:00:45Z,['10.48550/arXiv.2201.00517'],"The minimal supersymmetric extension of the standard model (MSSM) is extended to the $U(1)_X$SSM, whose local gauge group is $SU(3)_C \times SU(2)_L \times U(1)_Y \times U(1)_X$. To obtain the $U(1)_X$SSM, we add the new superfields to the MSSM, namely: three Higgs singlets $\hat{\eta},~\hat{\bar{\eta}},~\hat{S}$ and right-handed neutrinos $\hat{\nu}_i$. The CP violating effects are considered to study the lepton electric dipole moment(EDM) in $U(1)_X$SSM. The CP violating phases in $U(1)_X$SSM are more than those in the standard model(SM). In this model, some new parameters $(\theta_S, \theta_{BB^{\prime}}, \theta_{BL})$ as CP violating phases are considered, so there are new contributions to lepton EDMs. It is conducive to exploring the source of CP violation and probing new physical beyond SM."
2201.00518,Cascaded Asymmetric Local Pattern: A Novel Descriptor for Unconstrained Facial Image Recognition and Retrieval,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.00518v1,2022-01-03T08:23:38Z,2022-01-03T08:23:38Z,"['10.48550/arXiv.2201.00518', '10.1007/s11042-019-7707-0']","Feature description is one of the most frequently studied areas in the expert systems and machine learning. Effective encoding of the images is an essential requirement for accurate matching. These encoding schemes play a significant role in recognition and retrieval systems. Facial recognition systems should be effective enough to accurately recognize individuals under intrinsic and extrinsic variations of the system. The templates or descriptors used in these systems encode spatial relationships of the pixels in the local neighbourhood of an image. Features encoded using these hand crafted descriptors should be robust against variations such as; illumination, background, poses, and expressions. In this paper a novel hand crafted cascaded asymmetric local pattern (CALP) is proposed for retrieval and recognition facial image. The proposed descriptor uniquely encodes relationship amongst the neighbouring pixels in horizontal and vertical directions. The proposed encoding scheme has optimum feature length and shows significant improvement in accuracy under environmental and physiological changes in a facial image. State of the art hand crafted descriptors namely; LBP, LDGP, CSLBP, SLBP and CSLTP are compared with the proposed descriptor on most challenging datasets namely; Caltech-face, LFW, and CASIA-face-v5. Result analysis shows that, the proposed descriptor outperforms state of the art under uncontrolled variations in expressions, background, pose and illumination."
2201.00519,Stochastic Weight Averaging Revisited,"['Hao Guo', 'Jiyong Jin', 'Bin Liu']",ARXIV,http://arxiv.org/pdf/2201.00519v4,2022-01-03T08:29:01Z,2022-09-19T01:01:58Z,['10.48550/arXiv.2201.00519'],"Averaging neural network weights sampled by a backbone stochastic gradient descent (SGD) is a simple yet effective approach to assist the backbone SGD in finding better optima, in terms of generalization. From a statistical perspective, weight averaging (WA) contributes to variance reduction. Recently, a well-established stochastic weight averaging (SWA) method is proposed, which is featured by the application of a cyclical or high constant (CHC) learning rate schedule (LRS) in generating weight samples for WA. Then a new insight on WA appears, which states that WA helps to discover wider optima and then leads to better generalization. We conduct extensive experimental studies for SWA, involving a dozen modern DNN model structures and a dozen benchmark open-source image, graph, and text datasets. We disentangle contributions of the WA operation and the CHC LRS for SWA, showing that the WA operation in SWA still contributes to variance reduction but does not always lead to wide optima. The experimental results indicate that there are global scale geometric structures in the DNN loss landscape. We then present an algorithm termed periodic SWA (PSWA) which makes use of a series of WA operations to discover the global geometric structures. PSWA outperforms its backbone SGD remarkably, providing experimental evidences for the existence of global geometric structures. Codes for reproducing the experimental results are available at https://github.com/ZJLAB-AMMI/PSWA."
2201.00520,Vision Transformer with Deformable Attention,"['Zhuofan Xia', 'Xuran Pan', 'Shiji Song', 'Li Erran Li', 'Gao Huang']",ARXIV,http://arxiv.org/pdf/2201.00520v3,2022-01-03T08:29:01Z,2022-05-24T12:52:37Z,['10.48550/arXiv.2201.00520'],"Transformers have recently shown superior performances on various vision tasks. The large, sometimes even global, receptive field endows Transformer models with higher representation power over their CNN counterparts. Nevertheless, simply enlarging receptive field also gives rise to several concerns. On the one hand, using dense attention e.g., in ViT, leads to excessive memory and computational cost, and features can be influenced by irrelevant parts which are beyond the region of interests. On the other hand, the sparse attention adopted in PVT or Swin Transformer is data agnostic and may limit the ability to model long range relations. To mitigate these issues, we propose a novel deformable self-attention module, where the positions of key and value pairs in self-attention are selected in a data-dependent way. This flexible scheme enables the self-attention module to focus on relevant regions and capture more informative features. On this basis, we present Deformable Attention Transformer, a general backbone model with deformable attention for both image classification and dense prediction tasks. Extensive experiments show that our models achieve consistently improved results on comprehensive benchmarks. Code is available at https://github.com/LeapLabTHU/DAT."
2201.00521,Thermodynamics for higher dimensional rotating black holes with variable Newton constant,['Liu Zhao'],ARXIV,http://arxiv.org/pdf/2201.00521v2,2022-01-03T08:33:50Z,2022-01-27T03:24:51Z,"['10.48550/arXiv.2201.00521', '10.1088/1674-1137/ac4f4c']","The extensivity for the thermodynamics of general $D$-dimensional rotating black holes with or without a cosmological constant can be proved analytically, provided the effective number of microscopic degrees of freedom and the chemical potential are given respectively as $N=L^{D-2}/G, \mu= GTI_D/L^{D-2}$, where $G$ is the variable Newton constant, $I_D$ is the Euclidean action and $L$ is a constant length scale. In the cases without a cosmological constant, i.e. the Myers-Perry black holes, the physical mass and the intensive variables can be expressed as explicit macro state functions in the extensive variables in a simple and compact form, which allows for an analytical calculation for the heat capacity. The results indicate that the Myers-Perry black holes with zero, one and $k$ equal rotation parameters are all thermodynamically unstable."
2201.00522,Generalized Coverage Criteria for Combinatorial Sequence Testing,"['Achiya Elyasaf', 'Eitan Farchi', 'Oded Margalit', 'Gera Weiss', 'Yeshayahu Weiss']",ARXIV,http://arxiv.org/pdf/2201.00522v4,2022-01-03T08:35:28Z,2023-10-31T07:34:39Z,"['10.48550/arXiv.2201.00522', '10.1109/TSE.2023.3279570']","We present a new model-based approach for testing systems that use sequences of actions and assertions as test vectors. Our solution includes a method for quantifying testing quality, a tool for generating high-quality test suites based on the coverage criteria we propose, and a framework for assessing risks. For testing quality, we propose a method that specifies generalized coverage criteria over sequences of actions, which extends previous approaches. Our publicly available tool demonstrates how to extract effective test suites from test plans based on these criteria. We also present a Bayesian approach for measuring the probabilities of bugs or risks, and show how this quantification can help achieve an informed balance between exploitation and exploration in testing. Finally, we provide an empirical evaluation demonstrating the effectiveness of our tool in finding bugs, assessing risks, and achieving coverage."
2201.00523,Benchmark Functions for CEC 2022 Competition on Seeking Multiple Optima in Dynamic Environments,"['Wenjian Luo', 'Xin Lin', 'Changhe Li', 'Shengxiang Yang', 'Yuhui Shi']",ARXIV,http://arxiv.org/pdf/2201.00523v2,2022-01-03T08:44:33Z,2022-01-06T09:20:13Z,['10.48550/arXiv.2201.00523'],"Dynamic and multimodal features are two important properties and widely existed in many real-world optimization problems. The former illustrates that the objectives and/or constraints of the problems change over time, while the latter means there is more than one optimal solution (sometimes including the accepted local solutions) in each environment. The dynamic multimodal optimization problems (DMMOPs) have both of these characteristics, which have been studied in the field of evolutionary computation and swarm intelligence for years, and attract more and more attention. Solving such problems requires optimization algorithms to simultaneously track multiple optima in the changing environments. So that the decision makers can pick out one optimal solution in each environment according to their experiences and preferences, or quickly turn to other solutions when the current one cannot work well. This is very helpful for the decision makers, especially when facing changing environments. In this competition, a test suit about DMMOPs is given, which models the real-world applications. Specifically, this test suit adopts 8 multimodal functions and 8 change modes to construct 24 typical dynamic multimodal optimization problems. Meanwhile, the metric is also given to measure the algorithm performance, which considers the average number of optimal solutions found in all environments. This competition will be very helpful to promote the development of dynamic multimodal optimization algorithms."
2201.00524,Waldspurger formulas in higher cohomology,['Santiago Molina'],ARXIV,http://arxiv.org/pdf/2201.00524v5,2022-01-03T08:45:10Z,2023-10-18T16:24:02Z,['10.48550/arXiv.2201.00524'],"The classical Waldspurger formula, which computes periods of quaternionic automorphic forms in maximal torus, has been used in a wide variety of arithmetic applications, such as the Birch and Swinnerton-Dyer conjecture in rank 0 situations. This is why this formula is considered the rank 0 analogue of the celebrated Gross-Zagier formula. On the other hand, Eichler-Shimura correspondence allows us to interpret this quaternionic automorphic form as a cocycle in higher cohomology spaces of certain arithmetic groups. In this way we can realize the corresponding automorphic representation in the etale cohomology of certain Shimura varieties. In this work we find a formula, analogous to that of Waldspurger, which relates cap-products of this cocycle and fundamental classes associated with maximal torus with special values of Rankin-Selberg L-functions."
2201.00525,The gravitational potential energy of the Great Pyramid,['Charles Hirlimann'],ARXIV,http://arxiv.org/pdf/2201.00525v2,2022-01-03T08:54:25Z,2022-02-08T16:02:40Z,['10.48550/arXiv.2201.00525'],"The calculation of the energy required to raise a constituent block of the Khufu pyramid and the knowledge of the mechanical energy that a worker in charge of the lifting of the blocks can produce per working day allows an estimate of the minimum number of workers. necessary for the establishment of a base of the pyramid. It emerges that this number is limited to a maximum of less than 2,000 workers over a working season, ie less than 200 present each day simultaneously on the site. In addition, the calculation of the flow of blocks leads to the ineluctable conclusion that the construction could only be done in a massively parallel working mode, undermining the hypothesis very often put forward of the use of ramps to convey the blocks to their final destination."
2201.00526,On coherence of quantum operations by using Choi-Jamiołkowski isomorphism,"['Xiaorong Wang', 'Ting Gao', 'Fengli Yan']",ARXIV,http://arxiv.org/pdf/2201.00526v1,2022-01-03T09:04:10Z,2022-01-03T09:04:10Z,"['10.48550/arXiv.2201.00526', '10.1088/1612-202X/ac50ad']","In quantum information, most information processing processes involve quantum channels. One manifestation of a quantum channel is quantum operation acting on quantum states. The coherence of quantum operations can be considered as a quantum resource, which can be exploited to perform certain quantum tasks. From the viewpoint of Choi-Jamio{\l}kowski isomorphism, we study the coherence of quantum operations in the framework of resource theory. We define the phase-out superoperation and give the operation which transforms the Choi-Jamio{\l}kowski state of a quantum operation to the Choi-Jamio{\l}kowski state of the another quantum operation obtained by using the phase-out superoperation to act on the quantum operation. The set of maximally incoherent superoperations, the set of nonactivating coherent superoperations and the set of de-phase incoherent superoperations are defined and we prove that these sets are closed to compound operation and convex combination of quantum superoperations. Further, we introduce the fidelity coherence measure of quantum operations and obtain the exact form of the fidelity coherence measure of the unitary operations on the single qubit."
2201.00527,Stability of variable-step BDF2 and BDF3 methods,"['Zhaoyi Li', 'Hong-lin Liao']",ARXIV,http://arxiv.org/pdf/2201.00527v1,2022-01-03T09:08:41Z,2022-01-03T09:08:41Z,"['10.48550/arXiv.2201.00527', '10.1137/21M1462398']",We prove that the two-step backward differentiation formula (BDF2) method is stable on arbitrary time grids; while the variable-step BDF3 scheme is stable if almost all adjacent step ratios are less than 2.553. These results relax the severe mesh restrictions in the literature and provide a new understanding of variable-step BDF methods. Our main tools include the discrete orthogonal convolution kernels and an elliptic-type matrix norm.
2201.00528,Vortex pairs and dipoles on closed surfaces,['Björn Gustafsson'],ARXIV,http://arxiv.org/pdf/2201.00528v1,2022-01-03T09:11:29Z,2022-01-03T09:11:29Z,"['10.48550/arXiv.2201.00528', '10.1007/s00332-022-09822-9']","We set up general equations of motion for point vortex systems on closed Riemannian surfaces, allowing for the case that the sum of vorticities is not zero and there hence must be counter-vorticity present. The dynamics of global circulations which is coupled to the dynamics of the vortices is carefully taken into account. Much emphasis is put to the study of vortex pairs, having the Kimura conjecture in focus. This says that vortex pairs move, in the dipole limit, along geodesic curves, and proofs for it have previously been given by S.~Boatto and J.~Koiller by using Gaussian geodesic coordinates. In the present paper we reach the same conclusion by following a slightly different route, leading directly to the geodesic equation with a reparametrized time variable. In a final section we explain how vortex motion in planar domains can be seen as a special case of vortex motion on closed surfaces, and in two appendices we give some necessary background on affine and projective connections."
2201.00529,Cosmic rays from massive star clusters : A close look at Westerlund 1,"['Sourav Bhadra', 'Siddhartha Gupta', 'Biman B. Nath', 'Prateek Sharma']",ARXIV,http://arxiv.org/pdf/2201.00529v1,2022-01-03T09:12:52Z,2022-01-03T09:12:52Z,"['10.48550/arXiv.2201.00529', '10.1093/mnras/stac023']","We study the effect of cosmic ray (CR) acceleration in the massive compact star cluster Westerlund 1 in light of its recent detection in $\gamma$-rays. Recent observations reveal a $1/r$ radial distribution of the CR energy density. Here we theoretically investigate whether or not this profile can help to distinguish between (1) continuous CR acceleration in the star cluster stellar wind-driven shocks and (2) discrete CR acceleration in multiple supernovae shocks -- which are often debated in the literature. Using idealized two-fluid simulations and exploring different acceleration sites and diffusion coefficients, we obtain the CR energy density profile and luminosity to find the best match for the $\gamma$-ray observations. We find that the inferred CR energy density profiles from observations of $\gamma$-ray luminosity and mass can be much different from the true radial profile. CR acceleration at either the cluster core region or the wind termination shock can explain the observations, if the diffusion coefficient is $\kappa_{\rm cr}\sim 10^{27}$ cm$^2$ s$^{-1}$ and a fraction of $\approx 10\%-20\%$ of the shock power/post-shock pressure is deposited into the CR component. We also study the possibility of discrete supernovae (SN) explosions being responsible for CR acceleration and find that with an injection rate of 1 SN in every $\sim 0.03$ Myr, one can explain the observed $\gamma$-ray profile. This multiple SN scenario is consistent with X-ray observations only if the thermal conductivity is close to the Spitzer value."
2201.00530,Non-equilibrium Ensembles for the three-dimensional Navier-Stokes Equations,"['Georgios Margazoglou', 'Luca Biferale', 'Massimo Cencini', 'Giovanni Gallavotti', 'Valerio Lucarini']",ARXIV,http://arxiv.org/pdf/2201.00530v2,2022-01-03T09:23:52Z,2022-06-23T20:57:34Z,"['10.48550/arXiv.2201.00530', '10.1103/PhysRevE.105.065110']","At the molecular level fluid motions are, by first principles, described by time reversible laws. On the other hand, the coarse grained macroscopic evolution is suitably described by the Navier-Stokes equations, which are inherently irreversible, due to the dissipation term. Here, a reversible version of three-dimensional Navier-Stokes is studied, by introducing a fluctuating viscosity constructed in such a way that enstrophy is conserved, along the lines of the paradigm of microcanonical versus canonical treatment in equilibrium statistical mechanics. Through systematic simulations we attack two important questions: (a) What are the conditions that must be satisfied in order to have a statistical equivalence between the two non-equilibrium ensembles? (b) What is the empirical distribution of the fluctuating viscosity observed by changing the Reynolds number and the number of modes used in the discretization of the evolution equation? The latter point is important also to establish regularity conditions for the reversible equations. We find that the probability to observe negative values of the fluctuating viscosity becomes very quickly extremely small when increasing the effective Reynolds number of the flow in the fully resolved hydro dynamical regime, at difference from what was observed previously."
2201.00531,Novelty-based Generalization Evaluation for Traffic Light Detection,"['Arvind Kumar Shekar', 'Laureen Lake', 'Liang Gou', 'Liu Ren']",ARXIV,http://arxiv.org/pdf/2201.00531v1,2022-01-03T09:23:56Z,2022-01-03T09:23:56Z,"['10.48550/arXiv.2201.00531', '10.1109/ICMLA52953.2021.00032']","The advent of Convolutional Neural Networks (CNNs) has led to their application in several domains. One noteworthy application is the perception system for autonomous driving that relies on the predictions from CNNs. Practitioners evaluate the generalization ability of such CNNs by calculating various metrics on an independent test dataset. A test dataset is often chosen based on only one precondition, i.e., its elements are not a part of the training data. Such a dataset may contain objects that are both similar and novel w.r.t. the training dataset. Nevertheless, existing works do not reckon the novelty of the test samples and treat them all equally for evaluating generalization. Such novelty-based evaluations are of significance to validate the fitness of a CNN in autonomous driving applications. Hence, we propose a CNN generalization scoring framework that considers novelty of objects in the test dataset. We begin with the representation learning technique to reduce the image data into a low-dimensional space. It is on this space we estimate the novelty of the test samples. Finally, we calculate the generalization score as a combination of the test data prediction performance and novelty. We perform an experimental study of the same for our traffic light detection application. In addition, we systematically visualize the results for an interpretable notion of novelty."
2201.00532,Abundance of beryllium in the Sun and stars: The role of non-local thermodynamic equilibrium effects,"['S. Korotin', 'A. Kučinskas']",ARXIV,http://arxiv.org/pdf/2201.00532v1,2022-01-03T09:24:07Z,2022-01-03T09:24:07Z,"['10.48550/arXiv.2201.00532', '10.1051/0004-6361/202142789']","Earlier studies have suggested that deviations from the local thermodynamic equilibrium (LTE) play a minor role in the formation of Be II 313 nm resonance lines in solar and stellar atmospheres. Recent improvements in the atomic data allow a more complete model atom of Be to be constructed and the validity of these claims to be reassessed using more up-to-date atomic physics. The main goal of this study therefore is to refocus on the role of non-local thermodynamic equilibrium (NLTE) effects in the formation of Be II 313.04 and 313.11 nm resonance lines in solar and stellar atmospheres. For this, we constructed a model atom of Be using new atomic data that recently became available. The model atom contains 98 levels and 383 radiative transitions of Be I and Be II and uses the most up-to-date collision rates with electrons and hydrogen. This makes it the most complete model atom used to determine 1D NLTE solar Be abundance and to study the role of NLTE effects in the formation of Be II 313 nm resonance lines. We find that deviations from LTE have a significant influence on the strength of the Be II 313 nm line in solar and stellar atmospheres. For the Sun, we obtained the 1D NLTE Be abundance of A(Be)_NLTE = 1.32+/-0.05, which is in excellent agreement with the meteoritic value of A(Be)=1.31+/-0.04. Importantly, we find that NLTE effects become significant in FGK stars. Moreover, there is a pronounced variation in 1D NLTE-LTE abundance corrections with the effective temperature and metallicity. Therefore, contrary to our previous understanding, the obtained results indicate that NLTE effects play an important role in Be line formation in stellar atmospheres and have to be properly taken into account in Be abundance studies, especially in metal-poor stars."
2201.00533,Realizations of Rigid Graphs,['Christoph Koutschan'],ARXIV,http://arxiv.org/pdf/2201.00533v1,2022-01-03T09:24:17Z,2022-01-03T09:24:17Z,"['10.48550/arXiv.2201.00533', '10.4204/EPTCS.352.2']","A minimally rigid graph, also called Laman graph, models a planar framework which is rigid for a general choice of distances between its vertices. In other words, there are finitely many ways, up to isometries, to realize such a graph in the plane. Using ideas from algebraic and tropical geometry, we derive a recursive formula for the number of such realizations. Combining computational results with the construction of new rigid graphs via gluing techniques, we can give a new lower bound on the maximal possible number of realizations for graphs with a given number of vertices."
2201.00534,On Automating Triangle Constructions in Absolute and Hyperbolic Geometry,"['Vesna Marinković', 'Tijana Šukilović', 'Filip Marić']",ARXIV,http://arxiv.org/pdf/2201.00534v1,2022-01-03T09:24:34Z,2022-01-03T09:24:34Z,"['10.48550/arXiv.2201.00534', '10.4204/EPTCS.352.3']","We describe first steps towards a system for automated triangle constructions in absolute and hyperbolic geometry. We discuss key differences between constructions in Euclidean, absolute and hyperbolic geometry, compile a list of primitive constructions and lemmas used for constructions in absolute and hyperbolic geometry, build an automated system for solving construction problems and test it on a corpus of triangle-construction problems. We also provide an online compendium containing construction descriptions and illustrations."
2201.00535,Maximizing the Sum of the Distances between Four Points on the Unit Hemisphere,"['Zhenbing Zeng', 'Jian Lu', 'Yaochen Xu', 'Yuzheng Wang']",ARXIV,http://arxiv.org/pdf/2201.00535v1,2022-01-03T09:24:53Z,2022-01-03T09:24:53Z,"['10.48550/arXiv.2201.00535', '10.4204/EPTCS.352.4']","In this paper, we prove a geometrical inequality which states that for any four points on a hemisphere with the unit radius, the largest sum of distances between the points is 4+4*sqrt(2). In our method, we have constructed a rectangular neighborhood of the local maximum point in the feasible set, which size is explicitly determined, and proved that (1): the objective function is bounded by a quadratic polynomial which takes the local maximum point as the unique critical point in the neighborhood, and (2): the rest part of the feasible set can be partitioned into a finite union of a large number of very small cubes so that on each small cube the conjecture can be verified by estimating the objective function with exact numerical computation."
2201.00536,A New Modeling of Classical Folds in Computational Origami,"['Tetsuo Ida', 'Hidekazu Takahashi']",ARXIV,http://arxiv.org/pdf/2201.00536v1,2022-01-03T09:25:11Z,2022-01-03T09:25:11Z,"['10.48550/arXiv.2201.00536', '10.4204/EPTCS.352.5']",This paper shows a cut along a crease on an origami sheet makes simple modeling of popular traditional basic folds such as a squash fold in computational origami. The cut operation can be applied to other classical folds and significantly simplify their modeling and subsequent implementation in the context of computational origami.
2201.00537,Physical Properties of Brane-World Black Hole Solutions via a Confining Potential,"['İzzet Sakallı', 'Sara Kanzi']",ARXIV,http://arxiv.org/pdf/2201.00537v4,2022-01-03T09:25:37Z,2022-02-23T12:55:03Z,"['10.48550/arXiv.2201.00537', '10.1016/j.aop.2022.168803']","In this paper, we consider two brane-world black holes whose solutions are obtained via a confining potential and study their thermodynamical properties. The modified entropies by taking account of the generalized uncertainty principle (GUP) are obtained. We also determine the scalar effective potentials in order to compute the greybody factors of zero-spin particles (bosons) for both geometries. Finally, using the sixth-order WKB approach, quasi-normal modes (QNMs), which are also known as black hole fingerprints, are derived concerning the brane-world black hole parameters. The results obtained are graphically depicted, tabulated, and interpreted."
2201.00538,The Area Method in the Wolfram Language,['Jack Heimrath'],ARXIV,http://arxiv.org/pdf/2201.00538v1,2022-01-03T09:25:43Z,2022-01-03T09:25:43Z,"['10.48550/arXiv.2201.00538', '10.4204/EPTCS.352.7']",The area method is a decision procedure for geometry developed by Chou et al. in the 1990's. The method aims to reduce the specified hypothesis to an algebraically verifiable form by applying elimination lemmas. The order in which the lemmas are applied is determined by the stated conjecture and the underlying geometric construction. In this paper we present our implementation of the area method for Euclidean geometry as a stand-alone Mathematica package.
2201.00539,"Mechanization of Incidence Projective Geometry in Higher Dimensions, a Combinatorial Approach","['Pascal Schreck', 'Nicolas Magaud', 'David Braun']",ARXIV,http://arxiv.org/pdf/2201.00539v1,2022-01-03T09:26:01Z,2022-01-03T09:26:01Z,"['10.48550/arXiv.2201.00539', '10.4204/EPTCS.352.8']","Several tools have been developed to enhance automation of theorem proving in the 2D plane. However, in 3D, only a few approaches have been studied, and to our knowledge, nothing has been done in higher dimensions. In this paper, we present a few examples of incidence geometry theorems in dimensions 3, 4, and 5. We then prove them with the help of a combinatorial prover based on matroid theory applied to geometry."
2201.00540,Automated Generation of Illustrations for Synthetic Geometry Proofs,"['Predrag Janičić', 'Julien Narboux']",ARXIV,http://arxiv.org/pdf/2201.00540v1,2022-01-03T09:26:18Z,2022-01-03T09:26:18Z,"['10.48550/arXiv.2201.00540', '10.4204/EPTCS.352.9']","We report on a new, simple, modular, and flexible approach for automated generation of illustrations for (readable) synthetic geometry proofs. The underlying proofs are generated using the Larus automated prover for coherent logic, and corresponding illustrations are generated in the GCLC language. Animated illustrations are also supported."
2201.00541,"Spreads and Packings of PG(3,2), Formally!",['Nicolas Magaud'],ARXIV,http://arxiv.org/pdf/2201.00541v1,2022-01-03T09:26:51Z,2022-01-03T09:26:51Z,"['10.48550/arXiv.2201.00541', '10.4204/EPTCS.352.12']","We study how to formalize in the Coq proof assistant the smallest projective space PG(3,2). We then describe formally the spreads and packings of PG(3,2), as well as some of their properties. The formalization is rather straightforward, however as the number of objects at stake increases rapidly, we need to exploit some symmetry arguments as well as smart proof techniques to make proof search and verification faster and thus tractable using the Coq proof assistant. This work can be viewed as a first step towards formalizing projective spaces of higher dimension, e.g. PG(4,2), or larger order, e.g. PG(3,3)."
2201.00542,Formalising Geometric Axioms for Minkowski Spacetime and Without-Loss-of-Generality Theorems,"['Richard Schmoetten', 'Jake Palmer', 'Jacques Fleuriot']",ARXIV,http://arxiv.org/pdf/2201.00542v1,2022-01-03T09:27:06Z,2022-01-03T09:27:06Z,"['10.48550/arXiv.2201.00542', '10.4204/EPTCS.352.13']","This contribution reports on the continued formalisation of an axiomatic system for Minkowski spacetime (as used in the study of Special Relativity) which is closer in spirit to Hilbert's axiomatic approach to Euclidean geometry than to the vector space approach employed by Minkowski. We present a brief overview of the axioms as well as of a formalisation of theorems relating to linear order. Proofs and excerpts of Isabelle/Isar scripts are discussed, with a focus on the use of symmetry and reasoning ""without loss of generality""."
2201.00543,A Method for the Automated Discovery of Angle Theorems,['Philip Todd'],ARXIV,http://arxiv.org/pdf/2201.00543v1,2022-01-03T09:27:57Z,2022-01-03T09:27:57Z,"['10.48550/arXiv.2201.00543', '10.4204/EPTCS.352.17']","The Naive Angle Method, used by Geometry Expressions for solving problems which involve only angle constraints, represents a geometrical configuration as a sparse linear system. Linear systems with the same underlying matrix structure underpin a number of different geometrical theorems. We use a graph theoretical approach to define a generalization of the matrix structure."
2201.00544,Supporting Proving and Discovering Geometric Inequalities in GeoGebra by using Tarski,"['Christopher W. Brown', 'Zoltán Kovács', 'Róbert Vajda']",ARXIV,http://arxiv.org/pdf/2201.00544v1,2022-01-03T09:28:20Z,2022-01-03T09:28:20Z,"['10.48550/arXiv.2201.00544', '10.4204/EPTCS.352.18']","We introduce a system of software tools that can automatically prove or discover geometric inequalities. The system, called GeoGebra Discovery, consisting of an extended version of GeoGebra, a controller web service realgeom, and the computational tool Tarski (with the extensive help of the QEPCAD B system) successfully solves several non-trivial problems in Euclidean planar geometry related to inequalities."
2201.00545,Parametric Root Finding for Supporting Proving and Discovering Geometric Inequalities in GeoGebra,"['Zoltán Kovács', 'Róbert Vajda']",ARXIV,http://arxiv.org/pdf/2201.00545v1,2022-01-03T09:28:42Z,2022-01-03T09:28:42Z,"['10.48550/arXiv.2201.00545', '10.4204/EPTCS.352.19']","We introduced the package/subsystem GeoGebra Discovery to GeoGebra which supports the automated proving or discovering of elementary geometry inequalities. In this case study, for inequality exploration problems related to isosceles and right angle triangle subclasses, we demonstrate how our general real quantifier elimination (RQE) approach could be replaced by a parametric root finding (PRF) algorithm. The general RQE requires the full cell decomposition of a high dimensional space, while the new method can avoid this expensive computation and can lead to practical speedups. To obtain a solution for a 1D-exploration problem, we compute a Groebner basis for the discriminant variety of the 1-dimensional parametric system and solve finitely many nonlinear real (NRA) satisfiability (SAT) problems. We illustrate the needed computations by examples. Since Groebner basis algorithms are available in Giac (the underlying free computer algebra system in GeoGebra) and freely available efficient NRA-SAT solvers (SMT-RAT, Tarski, Z3, etc.) can be linked to GeoGebra, we hope that the method could be easily added to the existing reasoning tool set for educational purposes."
2201.00546,SMART: a Technology Readiness Methodology in the Frame of the NIS Directive,"['Archana Kumari', 'Stefan Schiffner', 'Sandra Schmitz']",ARXIV,http://arxiv.org/pdf/2201.00546v1,2022-01-03T09:31:59Z,2022-01-03T09:31:59Z,['10.48550/arXiv.2201.00546'],"An ever shorter technology lifecycle engendered the need for assessing new technologies w.r.t. their market readiness. Knowing the Technology readiness level (TRL) of a given target technology proved to be useful to mitigate risks such as cost overrun, product roll out delays, or early launch failures. Originally developed for space programmes by NASA, TRL became a de facto standard among technology and manufacturing companies and even among research funding agencies. However, while TRL assessments provide a systematic evaluation process resulting in meaningful metric, they are one dimensional: they only answer the question if a technology can go into production. Hence they leave an inherent gap, i.e., if a technology fulfils requirements with a certain quality. This gap becomes intolerable when this metric is applied software such as technological cybersecurity measures. With legislation such as the General Data Protection Regulation4 (GDPR) and the Network and Information Systems Directive5 (NIS-D) making reference to state of the art when requiring appropriate protection measures, software designers are faced with the question how to measure if a technology is suitable to use. We argue that there is a potential mismatch of legal aim and technological reality which not only leads to a risk of non-compliance, but also might lead to weaker protected systems than possible. In that regard, we aim to address the gaps identified with existing Technology Readiness Assessment (TRA)s and aim to overcome these by developing standardised method which is suitable for assessing software w.r.t. its market readiness and quality (in sum maturity)."
2201.00547,Progress on Local Properties Problems of Difference Sets,['Anqi Li'],ARXIV,http://arxiv.org/pdf/2201.00547v2,2022-01-03T09:34:32Z,2022-08-23T06:17:39Z,['10.48550/arXiv.2201.00547'],"We derive several new bounds for the problem of difference sets with local properties, such as establishing the super-linear threshold of the problem. For our proofs, we develop several new tools, including a variant of higher moment energies and a Ramsey-theoretic approach for the problem."
2201.00548,Hybrid intelligence for dynamic job-shop scheduling with deep reinforcement learning and attention mechanism,"['Yunhui Zeng', 'Zijun Liao', 'Yuanzhi Dai', 'Rong Wang', 'Xiu Li', 'Bo Yuan']",ARXIV,http://arxiv.org/pdf/2201.00548v1,2022-01-03T09:38:13Z,2022-01-03T09:38:13Z,['10.48550/arXiv.2201.00548'],"The dynamic job-shop scheduling problem (DJSP) is a class of scheduling tasks that specifically consider the inherent uncertainties such as changing order requirements and possible machine breakdown in realistic smart manufacturing settings. Since traditional methods cannot dynamically generate effective scheduling strategies in face of the disturbance of environments, we formulate the DJSP as a Markov decision process (MDP) to be tackled by reinforcement learning (RL). For this purpose, we propose a flexible hybrid framework that takes disjunctive graphs as states and a set of general dispatching rules as the action space with minimum prior domain knowledge. The attention mechanism is used as the graph representation learning (GRL) module for the feature extraction of states, and the double dueling deep Q-network with prioritized replay and noisy networks (D3QPN) is employed to map each state to the most appropriate dispatching rule. Furthermore, we present Gymjsp, a public benchmark based on the well-known OR-Library, to provide a standardized off-the-shelf facility for RL and DJSP research communities. Comprehensive experiments on various DJSP instances confirm that our proposed framework is superior to baseline algorithms with smaller makespan across all instances and provide empirical justification for the validity of the various components in the hybrid framework."
2201.00549,Efficient Enumeration Algorithms for Annotated Grammars,"['Antoine Amarilli', 'Louis Jachiet', 'Martín Muñoz', 'Cristian Riveros']",ARXIV,http://arxiv.org/pdf/2201.00549v2,2022-01-03T09:41:09Z,2022-05-17T16:00:55Z,"['10.48550/arXiv.2201.00549', '10.1145/3517804.3526232']","We introduce annotated grammars, an extension of context-free grammars which allows annotations on terminals. Our model extends the standard notion of regular spanners, and is more expressive than the extraction grammars recently introduced by Peterfreund. We study the enumeration problem for annotated grammars: fixing a grammar, and given a string as input, enumerate all annotations of the string that form a word derivable from the grammar. Our first result is an algorithm for unambiguous annotated grammars, which preprocesses the input string in cubic time and enumerates all annotations with output-linear delay. This improves over Peterfreund's result, which needs quintic time preprocessing to achieve this delay bound. We then study how we can reduce the preprocessing time while keeping the same delay bound, by making additional assumptions on the grammar. Specifically, we present a class of grammars which only have one derivation shape for all outputs, for which we can enumerate with quadratic time preprocessing. We also give classes that generalize regular spanners for which linear time preprocessing suffices."
2201.00550,On the proportion of vanishing elements in finite groups,"['Yu Zeng', 'Dongfang Yang', 'Silvio Dolfi']",ARXIV,http://arxiv.org/pdf/2201.00550v3,2022-01-03T09:58:01Z,2022-05-12T11:17:12Z,['10.48550/arXiv.2201.00550'],"We prove that the function $\mathrm{P}_{\mathrm{v}}(G)$, measuring the proportion of the elements of a finite group $G$ that are zeros of irreducible characters of $G$, takes very sparse values in a large segment of the $[0,1]$ interval."
2201.00551,Bootstrapping the deuteron,['Dong Bai'],ARXIV,http://arxiv.org/pdf/2201.00551v1,2022-01-03T09:58:07Z,2022-01-03T09:58:07Z,['10.48550/arXiv.2201.00551'],"Bootstrap is a novel and ambitious paradigm for quantum physics. It aims to solve the target problems by exploiting theoretical constraints from general physical principles and self-consistency conditions. The bootstrap philosophy dates back to the 1960s. Its real power has been recognized only recently in, e.g., conformal field theories and relativistic scattering amplitudes. Inspired by [X. Han, S. A. Hartnoll, and J. Kruthoff, Phys. Rev. Lett. 125, 041601 (2020)], we report the first bootstrap results in low-energy nuclear physics, where deuteron, with its Hamiltonian given by pionless effective field theory in harmonic oscillator space, is solved by directly exploiting the most fundamental quantum mechanical requirement that probability should never be negative. Our study shows that the bootstrap method can be helpful in studying realistic nuclear systems."
2201.00552,Canonical interpretation of the $D_{s0}(2590)^{+}$ resonance,"['Zhuo Gao', 'Guan-Ying Wang', 'Qi-Fang Lü', 'Jingya Zhu', 'Gao-Feng Zhao']",ARXIV,http://arxiv.org/pdf/2201.00552v1,2022-01-03T09:59:24Z,2022-01-03T09:59:24Z,['10.48550/arXiv.2201.00552'],"The $D_{s0}(2590)^{+}$ resonance observed by LHCb Collaboration is a strong candidate of the $D_{s}(2^1S_0)$ state according to its spin parity and strong decay mode. However, the measured mass seems relatively lower than the previous theoretical predictions, which interests the coupled channel interpretations in the literature. In this work, we adopt an alternate approach, taking into account the screening effects in the potential model, to describe the $D_{s0}(2590)^{+}$ resonance. The mass spectrum and strong decays of the excited charmed-strange mesons are investigated within the modified relativized quark model and $^3P_0$ model. The calculated mass and width of the $D_{s0}(2590)^{+}$ are consistent with the experimental observations, which indicate that it can be reasonably interpreted as the $D_{s}(2^{1}S_{0})$ state."
2201.00553,Nonlocal pseudospin dynamics in a quantum Ising chain,"['K. L. Zhang', 'Z. Song']",ARXIV,http://arxiv.org/pdf/2201.00553v2,2022-01-03T10:01:22Z,2022-09-15T07:07:39Z,"['10.48550/arXiv.2201.00553', '10.1088/2399-6528/ac9035']","The existence of topological zero modes in nontrivial phase of quantum Ising chain results in not only the Kramers-like degeneracy spectrum, but also dynamic response for non-Hermitian perturbation in the ordered phase (2021 Phys. Rev. Lett. 126 116401). In this work, we investigate the possible response of the degeneracy spectrum for Hermitian perturbations. We provide a single-particle description of the model in the ordered phase, associating with an internal degree of freedom characterized as a pseudospin. The effective magnetic field, arising from both local and nonlocal perturbations in terms of string operators, acts on the pseudospin. We show that the action of string operator can be realized via a quench under the local perturbations. As an application, any ground states and excited states for the Hamiltonian with perturbation can be selected to identify the quantum phase, by adding the other perturbations to trigger a quench and measuring the Loschmidt echo."
2201.00554,Efficient Steering Mechanism for Mobile Network-enabled UAVs,"['H. Hellaoui', 'A. Chelli', 'M. Bagaa', 'T. Taleb']",ARXIV,http://arxiv.org/pdf/2201.00554v1,2022-01-03T10:03:57Z,2022-01-03T10:03:57Z,['10.48550/arXiv.2201.00554'],"HTTP Adaptive Streaming (HAS) is becoming the de-facto video delivery technology over best-effort networks nowadays, thanks to the myriad advantages it brings. However, many studies have shown that HAS suffers from many Quality of Experience (QoE)-related issues in the presence of competing players. This is mainly caused by the selfishness of the players resulting from the decentralized intelligence given to the player. Another limitation is the bottleneck link that could happen at any time during the streaming session and anywhere in the network. These issues may result in wobbling bandwidth perception by the players and could lead to missing the deadline for chunk downloads, which result in the most annoying issue consisting of rebuffering events. In this paper, we leverage the SoftwareDefined Networking paradigm to take advantage of the global view of the network and its powerful intelligence that allows reacting to the network changing conditions. Ultimately, we aim at preventing the re-buffering events, resulting from deadline misses, and ensuring high QoE for the accepted clients in the system. To this end, we use Deterministic Network Calculus (DNC) to guarantee a maximum delay for the download of the video chunks while maximizing the perceived video quality. Simulation results show that the proposed solution ensures high efficiency for the accepted clients without any rebuffering events which result in high user QoE. Consequently, it might be highly useful for scenarios where video chunks should be strictly downloaded on-time or ensuring low delay with high user QoE such as serving video premium subscribers or remote control/driving of an autonomous vehicle in future 5G mobile networks."
2201.00555,Deterministic Service Function Chaining over Beyond 5G Edge Fabric,"['H. Yu', 'T. Taleb', 'J. Zhang']",ARXIV,http://arxiv.org/pdf/2201.00555v1,2022-01-03T10:04:15Z,2022-01-03T10:04:15Z,['10.48550/arXiv.2201.00555'],"Along with the increasing demand for latencysensitive services and applications, Deterministic Network (DetNet) concept has been recently proposed to investigate deterministic latency assurance for services featured with bounded latency requirements in 5G edge networks. The Network Function Virtualization (NFV) technology enables Internet Service Providers (ISPs) to flexibly place Virtual Network Functions (VNFs) achieving performance and cost benefits. Then, Service Function Chains (SFC) are formed by steering traffic through a series of VNF instances in a predefined order. Moreover, the required network resources and placement of VNF instances along SFC should be optimized to meet the deterministic latency requirements. Therefore, it is significant for ISPs to determine an optimal SFC deployment strategy to ensure network performance while improving the network revenue. In this paper, we jointly investigate the resource allocation and SFC placement in 5G edge networks for deterministic latency assurance. We formulate this problem as a mathematic programming model with the objective of maximizing the overall network profit for ISP. Furthermore, a novel Deterministic SFC deployment (Det-SFCD) algorithm is proposed to efficiently embed SFC requests with deterministic latency assurance. The performance evaluation results show that the proposed algorithm can provide better performance in terms of SFC request acceptance rate, network cost reduction, and network resource efficiency compared with benchmark strategy."
2201.00556,Topological order in random interacting Ising-Majorana chains stabilized by many-body localization,"['Nicolas Laflorencie', 'Gabriel Lemarié', 'Nicolas Macé']",ARXIV,http://arxiv.org/pdf/2201.00556v3,2022-01-03T10:04:52Z,2022-08-04T14:12:12Z,"['10.48550/arXiv.2201.00556', '10.1103/PhysRevResearch.4.L032016']","We numerically explore $\mathbb Z_2$-symmetric random interacting Ising-Majorana chains at high energy. A very rich phase diagram emerges with two topologically distinct many-body localization (MBL) regimes separated by a much broader thermal phase than previously found. This is a striking consequence of the avalanche theory. We further find MBL spin-glass order always associated to a many-body spectral pairing, presumably signaling a strong zero mode operator which opens fascinating perspectives for MBL-protected topological qubits."
2201.00557,Scattering of a plane wave by an inhomogeneous 1D dielectric layer with gradient refractive index,"['N. A. Vanyushkin', 'A. H. Gevorgyan', 'S. S. Golik']",ARXIV,http://arxiv.org/pdf/2201.00557v1,2022-01-03T10:06:48Z,2022-01-03T10:06:48Z,"['10.48550/arXiv.2201.00557', '10.1016/j.optmat.2022.112306']","We propose a new method for calculating reflection and transmission coefficients for an arbitrarily polarized electromagnetic plane wave incident on a one-dimensional dielectric medium of finite thickness and with dielectric permittivity being an arbitrary continuous function of the coordinate. We have shown that the problem of plane wave scattering by an inhomogeneous layer is reduced to a system of first order differential equations that contain the derivative of the refractive index or dielectric permittivity of the layer, which can be used, for example, when searching for an analytical solution. This method also makes it easy to obtain the distribution of the field strength within the layer. The reflection spectra and field distribution obtained using this method were compared with the analytical solution based on Mathieu functions."
2201.00558,Which Student is Best? A Comprehensive Knowledge Distillation Exam for Task-Specific BERT Models,"['Made Nindyatama Nityasya', 'Haryo Akbarianto Wibowo', 'Rendi Chevi', 'Radityo Eko Prasojo', 'Alham Fikri Aji']",ARXIV,http://arxiv.org/pdf/2201.00558v1,2022-01-03T10:07:13Z,2022-01-03T10:07:13Z,['10.48550/arXiv.2201.00558'],"We perform knowledge distillation (KD) benchmark from task-specific BERT-base teacher models to various student models: BiLSTM, CNN, BERT-Tiny, BERT-Mini, and BERT-Small. Our experiment involves 12 datasets grouped in two tasks: text classification and sequence labeling in the Indonesian language. We also compare various aspects of distillations including the usage of word embeddings and unlabeled data augmentation. Our experiments show that, despite the rising popularity of Transformer-based models, using BiLSTM and CNN student models provide the best trade-off between performance and computational resource (CPU, RAM, and storage) compared to pruned BERT models. We further propose some quick wins on performing KD to produce small NLP models via efficient KD training mechanisms involving simple choices of loss functions, word embeddings, and unlabeled data preparation."
2201.00559,Hida theory for special orders,"[""Luca Dall'Ava""]",ARXIV,http://arxiv.org/pdf/2201.00559v2,2022-01-03T10:08:07Z,2022-06-18T09:34:37Z,['10.48550/arXiv.2201.00559'],"This note is devoted to the study of families of quaternionic modular forms arising from orders defined by Pizer. In this situation, the Hecke-eigenspaces are 2-dimensional contrary to the classical case of Eichler orders. The main result is a Control Theorem in the spirit of Hida, interpolating these 2-dimensional Hecke-eigenspaces. We restrict our attention to a definite rational quaternion algebra ramified at a single odd prime $\ell$."
2201.00560,Cosmology of Supercooled Universe,['Kiyoharu Kawana'],ARXIV,http://arxiv.org/pdf/2201.00560v2,2022-01-03T10:11:24Z,2022-06-25T10:33:31Z,"['10.48550/arXiv.2201.00560', '10.1103/PhysRevD.105.103515']","First-order phase transitions (FOPTs) are ubiquitous in physics beyond the Standard Model (SM). Recently, models with no dimensionful parameters in the tree-level action have been attracting much attention because they can predict a very strong FOPT with ultra-supercooling. In this paper, we study the cosmological signatures of such a supercooling model. As a concrete model, we consider the SM with two additional real scalars $\phi$ and $S$, which can realize the electroweak symmetry breaking via Coleman-Weinberg mechanism. One of the additional scalars $S$ can naturally become a Dark Matter (DM) candidate due to the $Z_2^{}$ symmetry of the action. We study the FOPT of this model and calculate the Gravitational Wave (GW) signals and the thermal relic abundance of $S$ taking the filtered effects into account. Within the envelope approximation, we find that the GW peak amplitude can reach $\sim 10^{-10}$ around the frequency $f\sim 10^{-3}~$Hz for model parameters $(v_\phi^{},\lambda_{\phi S}^{})\sim (200~{\rm TeV},1.6)$ where $v_\phi^{}$ is the vacuum expectation value of $\phi$ and $\lambda_{\phi S}^{}$ is the scalar mixing coupling. On the other hand, the filtered DM mechanism only works for $0.8\lesssim \lambda_{\phi S}^{}\lesssim 1$, where the GW peak amplitude is found to be quite small $\lesssim 10^{-17}$."
2201.00561,Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction,"['Benjamin Hilprecht', 'Carsten Binnig']",ARXIV,http://arxiv.org/pdf/2201.00561v1,2022-01-03T10:11:35Z,2022-01-03T10:11:35Z,['10.48550/arXiv.2201.00561'],"In this paper, we introduce zero-shot cost models which enable learned cost estimation that generalizes to unseen databases. In contrast to state-of-the-art workload-driven approaches which require to execute a large set of training queries on every new database, zero-shot cost models thus allow to instantiate a learned cost model out-of-the-box without expensive training data collection. To enable such zero-shot cost models, we suggest a new learning paradigm based on pre-trained cost models. As core contributions to support the transfer of such a pre-trained cost model to unseen databases, we introduce a new model architecture and representation technique for encoding query workloads as input to those models. As we will show in our evaluation, zero-shot cost estimation can provide more accurate cost estimates than state-of-the-art models for a wide range of (real-world) databases without requiring any query executions on unseen databases. Furthermore, we show that zero-shot cost models can be used in a few-shot mode that further improves their quality by retraining them just with a small number of additional training queries on the unseen database."
2201.00562,Q-curvature and Path Integral Complexity,"['Hugo A. Camargo', 'Pawel Caputa', 'Pratik Nandy']",ARXIV,http://arxiv.org/pdf/2201.00562v2,2022-01-03T10:20:40Z,2022-04-15T13:08:41Z,"['10.48550/arXiv.2201.00562', '10.1007/JHEP04(2022)081']","We discuss the interpretation of path integral optimization as a uniformization problem in even dimensions. This perspective allows for a systematical construction of the higher-dimensional path integral complexity in holographic conformal field theories in terms of Q-curvature actions. We explore the properties and consequences of these actions from the perspective of the optimization programme, tensor networks and penalty factors. Moreover, in the context of recently proposed holographic path integral optimization, we consider higher curvature contributions on the Hartle-Hawking bulk slice and study their impact on the optimization as well as their relation to Q-curvature actions and finite cut-off holography."
2201.00563,Using Fitness Dependent Optimizer for Training Multi-layer Perceptron,"['Dosti Kh. Abbas', 'Tarik A. Rashid', 'Karmand H. Abdallaand Nebojsa Bacanin', 'Abeer Alsadoon']",ARXIV,http://arxiv.org/pdf/2201.00563v1,2022-01-03T10:23:17Z,2022-01-03T10:23:17Z,"['10.48550/arXiv.2201.00563', '10.53106/160792642021122207011']","This study presents a novel training algorithm depending upon the recently proposed Fitness Dependent Optimizer (FDO). The stability of this algorithm has been verified and performance-proofed in both the exploration and exploitation stages using some standard measurements. This influenced our target to gauge the performance of the algorithm in training multilayer perceptron neural networks (MLP). This study combines FDO with MLP (codename FDO-MLP) for optimizing weights and biases to predict outcomes of students. This study can improve the learning system in terms of the educational background of students besides increasing their achievements. The experimental results of this approach are affirmed by comparing with the Back-Propagation algorithm (BP) and some evolutionary models such as FDO with cascade MLP (FDO-CMLP), Grey Wolf Optimizer (GWO) combined with MLP (GWO-MLP), modified GWO combined with MLP (MGWO-MLP), GWO with cascade MLP (GWO-CMLP), and modified GWO with cascade MLP (MGWO-CMLP). The qualitative and quantitative results prove that the proposed approach using FDO as a trainer can outperform the other approaches using different trainers on the dataset in terms of convergence speed and local optima avoidance. The proposed FDO-MLP approach classifies with a rate of 0.97."
2201.00564,Hausdorff dimension bounds for the ABC sum-product problem,['Tuomas Orponen'],ARXIV,http://arxiv.org/pdf/2201.00564v1,2022-01-03T10:23:20Z,2022-01-03T10:23:20Z,['10.48550/arXiv.2201.00564'],"The purpose of this paper is to complete the proof of the following result. Let $0 < \beta \leq \alpha < 1$ and $\kappa > 0$. Then, there exists $\eta > 0$ such that whenever $A,B \subset \mathbb{R}$ are Borel sets with $\dim_{\mathrm{H}} A = \alpha$ and $\dim_{\mathrm{H}} B = \beta$, then $$\dim_{\mathrm{H}} \{c \in \mathbb{R} : \dim_{\mathrm{H}} (A + cB) \leq \alpha + \eta\} \leq \tfrac{\alpha - \beta}{1 - \beta} + \kappa.$$ This extends a result of Bourgain from 2010, which contained the case $\alpha = \beta$. This paper is a sequel to the author's previous work from 2021 which, roughly speaking, established the same result with $\dim_{\mathrm{H}} (A + cB)$ replaced by $\dim_{\mathrm{B}}(A + cB)$, the box dimension of $A + cB$. It turns out that, at the level of $\delta$-discretised statements, the superficially weaker box dimension result formally implies the Hausdorff dimension result."
2201.00565,Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional Knowledge Graph Embeddings,"['Kai Wang', 'Yu Liu', 'Quan Z. Sheng']",ARXIV,http://arxiv.org/pdf/2201.00565v2,2022-01-03T10:25:10Z,2022-05-24T07:06:21Z,['10.48550/arXiv.2201.00565'],"Knowledge graph embedding (KGE) has shown great potential in automatic knowledge graph (KG) completion and knowledge-driven tasks. However, recent KGE models suffer from high training cost and large storage space, thus limiting their practicality in real-world applications. To address this challenge, based on the latest findings in the field of Contrastive Learning, we propose a novel KGE training framework called Hardness-aware Low-dimensional Embedding (HaLE). Instead of the traditional Negative Sampling, we design a new loss function based on query sampling that can balance two important training targets, Alignment and Uniformity. Furthermore, we analyze the hardness-aware ability of recent low-dimensional hyperbolic models and propose a lightweight hardness-aware activation mechanism. The experimental results show that in the limited training time, HaLE can effectively improve the performance and training speed of KGE models on five commonly-used datasets. After training just a few minutes, the HaLE-trained models are competitive compared to the state-of-the-art models in both low- and high-dimensional conditions."
2201.00566,The multifarious ionization sources and disturbed kinematics of extraplanar gas in five low-mass galaxies,"['R. P. V. Rautio', 'A. E. Watkins', 'S. Comerón', 'H. Salo', 'S. Díaz-García', 'J. Janz']",ARXIV,http://arxiv.org/pdf/2201.00566v1,2022-01-03T10:28:02Z,2022-01-03T10:28:02Z,"['10.48550/arXiv.2201.00566', '10.1051/0004-6361/202142440']","We investigate the origin of the extraplanar diffuse ionized gas (eDIG) and its predominant ionization mechanisms in five nearby (17-46 Mpc) low-mass ($10^9\text{-}10^{10}$ $M_{\odot}$) edge-on disk galaxies: ESO 157-49, ESO 469-15, ESO 544-27, IC 217, and IC 1553. We acquired Multi Unit Spectroscopic Explorer (MUSE) integral field spectroscopy and deep narrowband H$\alpha$ imaging of our sample galaxies. To investigate the connection between in-plane star formation and eDIG, we perform a photometric analysis of our narrowband H$\alpha$ imaging. We measure eDIG scale heights of $h_{z\text{eDIG}} = 0.59 \text{-} 1.39$ kpc and find a positive correlation between them and specific star formation rates. In all galaxies, we also find a strong correlation between extraplanar and midplane radial H$\alpha$ profiles. Using our MUSE data, we investigate the origin of eDIG via kinematics. We find ionized gas rotation velocity lags above the midplane with values between 10 and 27 km s$^{-1}$ kpc$^{-1}$. While we do find hints of an accretion origin for the ionized gas in ESO 157-49, IC 217, and IC 1553, overall the ionized gas kinematics of our galaxies do not match a steady galaxy model or any simplistic model of accretion or internal origin for the gas. We also construct standard diagnostic diagrams and emission-line maps (EW(H$\alpha$), [NII]/H$\alpha$, [SII]//H$\alpha$, [OIII]/H$\beta$) and find regions consistent with mixed OB star and hot low-mass evolved stars (HOLMES) ionization, and mixed OB-shock ionization. Our results suggest that OB stars are the primary driver of eDIG ionization, while both HOLMES and shocks may locally contribute to the ionization of eDIG to a significant degree. Despite our galaxies' similar structures and masses, we find a surprisingly composite image of ionization mechanisms and a multifarious origin for the eDIG."
2201.00567,Ant colonization processed algorithm for design of a toroidal shaped mobile 5G antenna,['Sunit Shantanu Digamber Fulari'],ARXIV,http://arxiv.org/pdf/2201.00567v3,2022-01-03T10:28:08Z,2023-05-08T06:02:54Z,['10.48550/arXiv.2201.00567'],"There is great potential if we understand how nature functions, particularly the animals taking down from the ant to the larger animals. In this paper we will make an attempt to learn about ants colonization processing by studying their behaviour. Earlier there was particle swarm optimization which helped to solve many scientific problems. Ants communication with each other, their peculiar behaviour of working, colonization, their movements from one place to another, there is large potential in understanding their entire life to design a better 5G antenna."
2201.00568,Deep Learning for GPS Spoofing Detection in Cellular Enabled Unmanned Aerial Vehicle Systems,"['Y. Dang', 'C. Benzaid', 'B. Yang', 'T. Taleb']",ARXIV,http://arxiv.org/pdf/2201.00568v1,2022-01-03T10:31:20Z,2022-01-03T10:31:20Z,['10.48550/arXiv.2201.00568'],"Cellular-based Unmanned Aerial Vehicle (UAV) systems are a promising paradigm to provide reliable and fast Beyond Visual Line of Sight (BVLoS) communication services for UAV operations. However, such systems are facing a serious GPS spoofing threat for UAV's position. To enable safe and secure UAV navigation BVLoS, this paper proposes a cellular network assisted UAV position monitoring and anti-GPS spoofing system, where deep learning approach is used to live detect spoofed GPS positions. Specifically, the proposed system introduces a MultiLayer Perceptron (MLP) model which is trained on the statistical properties of path loss measurements collected from nearby base stations to decide the authenticity of the GPS position. Experiment results indicate the accuracy rate of detecting GPS spoofing under our proposed approach is more than 93% with three base stations and it can also reach 80% with only one base station."
2201.00569,Simulating the gravity in S11 parameters and friis transmission equation,['Sunit Shantanu Digamber Fulari'],ARXIV,http://arxiv.org/pdf/2201.00569v3,2022-01-03T10:32:17Z,2023-05-08T06:13:23Z,['10.48550/arXiv.2201.00569'],"Antennas are taking design shapes by the orientation of its material and the final structural design they take. Irrespective of the shape, the function and efficiency they produce does not change and vary to much extent. We are trying to simulate a design of antenna which is using the artificial intelligence model to Specific absorption rate minimization. We have successfully used antenna magus and CST suite to produce our improved simulation results. Motion models such as optical flow is used to smartly detect communicating devices inorder to connect and link the devices. The algorithm used by us is closest neighbour algorithm which is connected with antenna to apply it in object detection of mobile devices and antennas. We are trying to have a six second break in which the antenna will operate at minimum frequency but at the same time operating in its functioning. After every six seconds the antenna will radiate its frequency of vibration to detect if there is any new object or mobile device in sight."
2201.00570,3DPG: Distributed Deep Deterministic Policy Gradient Algorithms for Networked Multi-Agent Systems,"['Adrian Redder', 'Arunselvan Ramaswamy', 'Holger Karl']",ARXIV,http://arxiv.org/pdf/2201.00570v2,2022-01-03T10:33:52Z,2022-11-02T15:14:00Z,['10.48550/arXiv.2201.00570'],"We present Distributed Deep Deterministic Policy Gradient (3DPG), a multi-agent actor-critic (MAAC) algorithm for Markov games. Unlike previous MAAC algorithms, 3DPG is fully distributed during both training and deployment. 3DPG agents calculate local policy gradients based on the most recently available local data (states, actions) and local policies of other agents. During training, this information is exchanged using a potentially lossy and delaying communication network. The network therefore induces Age of Information (AoI) for data and policies. We prove the asymptotic convergence of 3DPG even in the presence of potentially unbounded Age of Information (AoI). This provides an important step towards practical online and distributed multi-agent learning since 3DPG does not assume information to be available deterministically. We analyze 3DPG in the presence of policy and data transfer under mild practical assumptions. Our analysis shows that 3DPG agents converge to a local Nash equilibrium of Markov games in terms of utility functions expressed as the expected value of the agents local approximate action-value functions (Q-functions). The expectations of the local Q-functions are with respect to limiting distributions over the global state-action space shaped by the agents' accumulated local experiences. Our results also shed light on the policies obtained by general MAAC algorithms. We show through a heuristic argument and numerical experiments that 3DPG improves convergence over previous MAAC algorithms that use old actions instead of old policies during training. Further, we show that 3DPG is robust to AoI; it learns competitive policies even with large AoI and low data availability."
2201.00571,Powers of monomial ideals with characteristic-dependent Betti numbers,"['Davide Bolognini', 'Antonio Macchia', 'Francesco Strazzanti', 'Volkmar Welker']",ARXIV,http://arxiv.org/pdf/2201.00571v1,2022-01-03T10:35:26Z,2022-01-03T10:35:26Z,['10.48550/arXiv.2201.00571'],"We explore the dependence of the Betti numbers of monomial ideals on the characteristic of the field. A first observation is that for a fixed prime $p$ either the $i$-th Betti number of all high enough powers of a monomial ideal differs in characteristic $0$ and in characteristic $p$ or it is the same for all high enough powers. In our main results we provide constructions and explicit examples of monomial ideals all of whose powers have some characteristic-dependent Betti numbers or whose asymptotic regularity depends on the field. We prove that, adding a monomial on new variables to a monomial ideal, allows to spread the characteristic dependence to all powers. For any given prime $p$, this produces an edge ideal such that the Betti numbers of all its powers over $\mathbb{Q}$ and over $\mathbb{Z}_p$ are different. Moreover, we show that, for every $r \geq 0$ and $i \geq 3$ there is a monomial ideal $I$ such that some coefficient in a degree $\geq r$ of the Kodiyalam polynomials $\mathfrak P_3(I),\ldots,\mathfrak P_{i+r}(I)$ depends on the characteristic. We also provide a summary of related results and speculate about the behaviour of other combinatorially defined ideals."
2201.00572,Enabling Verification of Deep Neural Networks in Perception Tasks Using Fuzzy Logic and Concept Embeddings,"['Gesina Schwalbe', 'Christian Wirth', 'Ute Schmid']",ARXIV,http://arxiv.org/pdf/2201.00572v2,2022-01-03T10:35:47Z,2022-03-13T17:32:08Z,['10.48550/arXiv.2201.00572'],"One major drawback of deep convolutional neural networks (CNNs) for use in safety critical applications is their black-box nature. This makes it hard to verify or monitor complex, symbolic requirements on already trained computer vision CNNs. In this work, we present a simple, yet effective, approach to verify that a CNN complies with symbolic predicate logic rules which relate visual concepts. It is the first that (1) does not modify the CNN, (2) may use visual concepts that are no CNN in- or output feature, and (3) can leverage continuous CNN confidence outputs. To achieve this, we newly combine methods from explainable artificial intelligence and logic: First, using supervised concept embedding analysis, the output of a CNN is post-hoc enriched by concept outputs. Second, rules from prior knowledge are modelled as truth functions that accept the CNN outputs, and can be evaluated with little computational overhead. We here investigate the use of fuzzy logic, i.e., continuous truth values, and of proper output calibration, which both theoretically and practically show slight benefits. Applicability is demonstrated on state-of-the-art object detectors for three verification use-cases, where monitoring of rule breaches can reveal detection errors."
2201.00573,Antenna parameterization for effectiveness in horn shaped antenna for 5G communication,['Sunit Shantanu Digamber Fulari'],ARXIV,http://arxiv.org/pdf/2201.00573v3,2022-01-03T10:36:46Z,2023-02-04T05:08:59Z,['10.48550/arXiv.2201.00573'],Horn antenna is well documented in our research in this paper. We are trying our latent method of radiation by antennas which we suppose to reduce to a significant extent. Why we chose horn antenna is it resonates the sound to explosion as done by horn shaped matter. Horn by its shape makes the sent signals to maximum capability by its shape which is required by the receiver due to the distance separation from sender and receiver. Our research will contain various implementations leading to improvement of previous designs. We will use the traditional methods of Bergen to make the antenna behave smartly in its functioning.
2201.00574,Theoretical aspects of $D^0-\bar{D}^0$ mixing,['Hiroyuki Umeeda'],ARXIV,http://arxiv.org/pdf/2201.00574v2,2022-01-03T10:38:19Z,2022-01-13T03:00:11Z,['10.48550/arXiv.2201.00574'],"Observables in the $D^0-\bar{D}^0$ mixing can be theoretically analyzed by the operator product expansion (OPE), in which $1/m_c$ is regarded as an expansion parameter. Since the contributions of four-quark operators are strongly suppressed by the Glashow-Iliopoulos-Maiani (GIM) mechanism, the order of magnitude of the width difference is still not reproduced in the OPE analysis. In view of this issue, quark-hadron duality, an assumption that is tacitly made in the OPE, is studied for the $D^0-\bar{D}^0$ mixing. In particular, the exclusive width difference and the inclusive counterpart can be compared within the 't Hooft model, two-dimensional QCD in the large-$N_c$ limit. It is shown that the order of magnitude of the exclusive width difference is enhanced relative to the 4D-like inclusive contributions of the four-quark operators, that is qualitatively consistent with the realistic observation of the $D^0-\bar{D}^0$ mixing."
2201.00575,A Queuing based Dynamic Auto Scaling Algorithm for the LTE EPC Control Plane,"['J. Prados', 'A. Laghrissi', 'M. Bagaa', 'T. Taleb']",ARXIV,http://arxiv.org/pdf/2201.00575v1,2022-01-03T10:40:33Z,2022-01-03T10:40:33Z,['10.48550/arXiv.2201.00575'],"Network Slicing (NS) is expected to be a key functionality of the upcoming 5G systems. Coupled with Software Defined Networking (SDN) and Network Function Virtualization (NFV),NS will enable a flexible deployment of Network Functions belonging to multiple Service Function Chains (SFC) over a shared infrastructure. To address the complexities that arise from this new environment, we formulate a MILP optimization model that enables a cost-optimal deployment of network slices, allowing a Mobile Network Operator to efficiently allocate the underlying layer resources according to the users' requirements. For each network slice, the proposed solution guarantees the required delay and the bandwidth, while efficiently handling the usage of underlying nodes, which leads to reduced cost. The obtained results show the efficiency of the proposed solution in terms of cost and execution time for small-scale networks, while it shows an interesting behavior in the large-scale topologies."
2201.00576,An accelerator experiment for junior and senior high school students to improve students' involvement in fundamental physics,"['K. S. Tanaka', 'K. Harada', 'T. Hayamizu', 'R. Kita', 'R. Kono', 'K. Maruta', 'H. Nagahama', 'N. Ozawa', 'Y. Sakemi', 'R. Sugimori']",ARXIV,http://arxiv.org/pdf/2201.00576v1,2022-01-03T10:41:55Z,2022-01-03T10:41:55Z,"['10.48550/arXiv.2201.00576', '10.1088/1361-6552/ac510a']","In Japan, research activities by junior and senior high school students show an upward trend. However, there are limited examples of research activities in the field of elementary particles and atoms. This is due to the difficulty associated with procuring research tools such as accelerators or particle detectors. Therefore, we hosted the ""Accel Kitchen"" in 2018 and 2019 at Cyclotron and Radioisotope Center (CYRIC) in Tohoku University where junior and senior high school students could participate in ongoing research of particle and atomic physics. At each workshop, 12 junior and senior high school students participated in the beam experiment, including the production of francium atoms (Fr) by the fusion reaction of oxygen and gold, optimizing the transport of the ion beam and identifying the alpha decay nuclei, and laser trapping of Fr for two days. Each group that was involved in the experiment was supported by researchers and university students who acted as mentors. This was the first opportunity for junior and senior high school students to know about the particle beam experiment in Japan."
2201.00577,Semantically Grounded Visual Embeddings for Zero-Shot Learning,"['Shah Nawaz', 'Jacopo Cavazza', 'Alessio Del Bue']",ARXIV,http://arxiv.org/pdf/2201.00577v2,2022-01-03T10:43:15Z,2022-04-10T13:58:35Z,['10.48550/arXiv.2201.00577'],"Zero-shot learning methods rely on fixed visual and semantic embeddings, extracted from independent vision and language models, both pre-trained for other large-scale tasks. This is a weakness of current zero-shot learning frameworks as such disjoint embeddings fail to adequately associate visual and textual information to their shared semantic content. Therefore, we propose to learn semantically grounded and enriched visual information by computing a joint image and text model with a two-stream network on a proxy task. To improve this alignment between image and textual representations, provided by attributes, we leverage ancillary captions to provide grounded semantic information. Our method, dubbed joint embeddings for zero-shot learning is evaluated on several benchmark datasets, improving the performance of existing state-of-the-art methods in both standard ($+1.6$\% on aPY, $+2.6\%$ on FLO) and generalized ($+2.1\%$ on AWA$2$, $+2.2\%$ on CUB) zero-shot recognition."
2201.00578,'Moving On' -- Investigating Inventors' Ethnic Origins Using Supervised Learning,['Matthias Niggli'],ARXIV,http://arxiv.org/pdf/2201.00578v1,2022-01-03T10:47:47Z,2022-01-03T10:47:47Z,['10.48550/arXiv.2201.00578'],"Patent data provides rich information about technical inventions, but does not disclose the ethnic origin of inventors. In this paper, I use supervised learning techniques to infer this information. To do so, I construct a dataset of 95'202 labeled names and train an artificial recurrent neural network with long-short-term memory (LSTM) to predict ethnic origins based on names. The trained network achieves an overall performance of 91% across 17 ethnic origins. I use this model to classify and investigate the ethnic origins of 2.68 million inventors and provide novel descriptive evidence regarding their ethnic origin composition over time and across countries and technological fields. The global ethnic origin composition has become more diverse over the last decades, which was mostly due to a relative increase of Asian origin inventors. Furthermore, the prevalence of foreign-origin inventors is especially high in the USA, but has also increased in other high-income economies. This increase was mainly driven by an inflow of non-western inventors into emerging high-technology fields for the USA, but not for other high-income countries."
2201.00579,European Aerosol Phenomenology -- 8: Harmonised Source Apportionment of Organic Aerosol using 22 Year-long ACSM/AMS Datasets,"['Gang Chen', 'Francesco Canonaco', 'Anna Tobler', 'Wenche Aas', 'Andres Alastuey', 'James Allan', 'Samira Atabakhsh', 'Minna Aurela', 'Urs Baltensperger', 'Aikaterini Bougiatioti', 'Joel F. De Brito', 'Darius Ceburnis', 'Benjamin Chazeau', 'Hasna Chebaicheb', 'Kaspar R. Daellenbach', 'Mikael Ehn', 'Imad El Haddad', 'Konstantinos Eleftheriadis', 'Olivier Favez', 'Harald Flentje', 'Anna Font', 'Kirsten Fossum', 'Evelyn Freney', 'Maria Gini', 'David C Green', 'Liine Heikkinen', 'Hartmut Herrmann', 'Athina-Cerise Kalogridis', 'Hannes Keernik', 'Radek Lhotka', 'Chunshui Lin', 'Chris Lunder', 'Marek Maasikmets', 'Manousos I. Manousakas', 'Nicolas Marchand', 'Cristina Marin', 'Luminita Marmureanu', 'Nikolaos Mihalopoulos', 'Griša Močnik', 'Jaroslaw Nęcki', ""Colin O'Dowd"", 'Jurgita Ovadnevaite', 'Thomas Peter', 'Jean-Eudes Petit', 'Michael Pikridas', 'Stephen Matthew Platt', 'Petra Pokorná', 'Laurent Poulain', 'Max Priestman', 'Véronique Riffault', 'Matteo Rinaldi', 'Kazimierz Różański', 'Jaroslav Schwarz', 'Jean Sciare', 'Leïla Simon', 'Alicja Skiba', 'Jay G. Slowik', 'Yulia Sosedova', 'Iasonas Stavroulas', 'Katarzyna Styszko', 'Erik Teinemaa', 'Hilkka Timonen', 'Anja Tremper', 'Jeni Vasilescu', 'Marta Via', 'Petr Vodička', 'Alfred Wiedensohler', 'Olga Zografou', 'María Cruz Minguillón', 'André S. H. Prévôt']",ARXIV,http://arxiv.org/pdf/2201.00579v2,2022-01-03T10:50:56Z,2022-01-04T12:58:05Z,"['10.48550/arXiv.2201.00579', '10.1016/j.envint.2022.107325']","Organic aerosol (OA) is a key component to total submicron particulate matter (PM1), and comprehensive knowledge of OA sources across Europe is crucial to mitigate PM1 levels. Europe has a well-established air quality research infrastructure from which yearlong datasets using 21 aerosol chemical speciation monitors (ACSMs) and 1 aerosol mass spectrometer (AMS) were gathered during 2013-2019. It includes 9 non-urban and 13 urban sites. This study developed a state-of-the-art source apportionment protocol to analyse long-term OA mass spectrum data by applying the most advanced source apportionment strategies (i.e., rolling PMF, ME-2, and bootstrap). This harmonised protocol enables the quantifications of the most common OA components such as hydrocarbon-like OA (HOA), biomass burning OA (BBOA), cooking-like OA (COA), more oxidised-oxygenated OA (MO-OOA), and less oxidised-oxygenated OA (LO-OOA). Other components such as coal combustion OA (CCOA), solid fuel OA (SFOA: mainly mixture of coal and peat combustion), cigarette smoke OA (CSOA), sea salt (mostly inorganic but part of the OA mass spectrum), coffee OA, and ship industry OA could also be separated at a few specific sites. Oxygenated OA (OOA) components make up most of the submicron OA mass (average = 71.1%, a range of 43.7-100%). Solid fuel combustion-related OA components (i.e., BBOA, CCOA, and SFOA) are still considerable with in total 16.0% yearly contribution to the OA, yet mainly during winter months (21.4%). Overall, this comprehensive protocol works effectively across all sites governed by different sources and generates robust and consistent source apportionment results. Our work presents a comprehensive overview of OA sources in Europe with a unique combination of high time resolution and long-term data coverage (9-36 months), providing essential information to improve/validate air quality, health impact, and climate models."
2201.00580,Identification of source terms in wave equation with dynamic boundary conditions,"['S. E. Chorfi', 'G. El Guermai', 'L. Maniar', 'W. Zouhair']",ARXIV,http://arxiv.org/pdf/2201.00580v1,2022-01-03T10:55:17Z,2022-01-03T10:55:17Z,"['10.48550/arXiv.2201.00580', '10.1002/mma.8556']","This paper studies an inverse hyperbolic problem for the wave equation with dynamic boundary conditions. It consists of determining some forcing terms from the final overdetermination of the displacement. First, the Fr\'echet differentiability of the Tikhonov functional is studied, and a gradient formula is obtained via the solution of an associated adjoint problem. Then, the Lipschitz continuity of the gradient is proved. Furthermore, the existence and the uniqueness for the minimization problem are discussed. Finally, some numerical experiments for the reconstruction of an internal wave force are implemented via a conjugate gradient algorithm."
2201.00581,Casimir interactions from infinite range and dilation symmetry,"['Venkat Abhignan', 'R. Sankaranarayanan']",ARXIV,http://arxiv.org/pdf/2201.00581v1,2022-01-03T10:55:40Z,2022-01-03T10:55:40Z,['10.48550/arXiv.2201.00581'],"The Casimir interaction energy for a class of discrete self-similar configuration of parallel plates is evaluated using existing methods. The similarities to characteristics of an attractive Casimir force is deduced only at infinite range of configuration. Further, the emergence of Casimir-like energy is qualitatively described for a Gaussian model of Landau-Ginzburg scalar field. Its relevance to self-similarity in the statistical field is shown at infinite range of fluctuations."
2201.00582,Graph-combinatorial approach for large deviations of Markov chains,"['Giorgio Carugno', 'Pierpaolo Vivo', 'Francesco Coghi']",ARXIV,http://arxiv.org/pdf/2201.00582v2,2022-01-03T10:55:53Z,2022-06-02T16:26:13Z,"['10.48550/arXiv.2201.00582', '10.1088/1751-8121/ac79e6']","We consider discrete-time Markov chains and study large deviations of the pair empirical occupation measure, which is useful to compute fluctuations of pure-additive and jump-type observables. We provide an exact expression for the finite-time moment generating function, which is split in cycles and paths contributions, and scaled cumulant generating function of the pair empirical occupation measure via a graph-combinatorial approach. The expression obtained allows us to give a physical interpretation of interaction and entropic terms, and of the Lagrange multipliers, and may serve as a starting point for sub-leading asymptotics. We illustrate the use of the method for a simple two-state Markov chain."
2201.00583,Evaluation and comparison of SEA torque controllers in a unified framework,"['Wolfgang Rampeltshammer', 'Arvid Keemink', 'Menno Sytsma', 'Edwin van Asseldonk', 'Herman van der Kooij']",ARXIV,http://arxiv.org/pdf/2201.00583v1,2022-01-03T11:02:01Z,2022-01-03T11:02:01Z,['10.48550/arXiv.2201.00583'],"Series elastic actuators (SEA) with their inherent compliance offer a safe torque source for robots that are interacting with various environments, including humans. These applications have high requirements for the SEA torque controllers, both in the torque response as well as interaction behavior with its the environment. To differentiate state of the art torque controllers, this work is introducing a unifying theoretical and experimental framework that compares controllers based on their torque transfer behavior, their apparent impedance behavior, and especially the passivity of the apparent impedance, i.e. their interaction stability, as well as their sensitivity to sensor noise. We compare classical SEA control approaches such as cascaded PID controllers and full state feedback controllers with advanced controllers using disturbance observers, acceleration feedback and adaptation rules. Simulations and experiments demonstrate the trade-off between stable interactions, high bandwidths and low noise levels. Based on these tradeoffs, an application specific controller can be designed and tuned, based on desired interaction with the respective environment."
2201.00584,Feature Selection-based Intrusion Detection System Using Genetic Whale Optimization Algorithm and Sample-based Classification,"['Amir Mojtahedi', 'Farid Sorouri', 'Alireza Najafi Souha', 'Aidin Molazadeh', 'Saeedeh Shafaei Mehr']",ARXIV,http://arxiv.org/pdf/2201.00584v1,2022-01-03T11:05:02Z,2022-01-03T11:05:02Z,['10.48550/arXiv.2201.00584'],"Preventing and detecting intrusions and attacks on wireless networks has become an important and serious challenge. On the other hand, due to the limited resources of wireless nodes, the use of monitoring nodes for permanent monitoring in wireless sensor networks in order to prevent and detect intrusion and attacks in this type of network is practically non-existent. Therefore, the solution to overcome this problem today is the discussion of remote-control systems and has become one of the topics of interest in various fields. Remote monitoring of node performance and behavior in wireless sensor networks, in addition to detecting malicious nodes within the network, can also predict malicious node behavior in future. In present research, a network intrusion detection system using feature selection based on a combination of Whale optimization algorithm (WOA) and genetic algorithm (GA) and sample-based classification is proposed. In this research, the standard data set KDDCUP1999 has been used in which the characteristics related to healthy nodes and types of malicious nodes are stored based on the type of attacks in the network. The proposed method is based on the combination of feature selection based on Whale optimization algorithm and genetic algorithm with KNN classification in terms of accuracy criteria, has better results than other previous methods. Based on this, it can be said that the Whale optimization algorithm and the genetic algorithm have extracted the features related to the class label well, and the KNN method has been able to well detect the misconduct nodes in the intrusion detection data set in wireless networks."
2201.00585,Multiplicative Properties of Hilbert Cubes,['Igor E. Shparlinski'],ARXIV,http://arxiv.org/pdf/2201.00585v2,2022-01-03T11:06:05Z,2022-03-11T21:11:24Z,['10.48550/arXiv.2201.00585'],"We obtain upper bounds on the cardinality of Hilbert cubes in finite fields, which avoid large product sets and reciprocals of sum sets. In particular, our results replace recent estimates of N. Hegyv\'ari and P. P. Pach (2020), which appear to be void for all admissible parameters. Our approach is different from that of N. Hegyv\'ari and P. P. Pach and is based on some well-known bounds of double character and exponential sums over arbitrary sets, due to A. A. Karatsuba (1991) and N. G. Moshchevitin (2007), respectively."
2201.00586,Diffuse flux of PeV neutrinos from centrifugally accelerated protons in active galactic nuclei,"['Rajat K. Dey', 'Animesh Basak', 'Sabyasachi Ray']",ARXIV,http://arxiv.org/pdf/2201.00586v1,2022-01-03T11:21:05Z,2022-01-03T11:21:05Z,"['10.48550/arXiv.2201.00586', '10.1209/0295-5075/ac35bc']","Evidence for high-energy astrophysical PeV neutrinos has been found in the IceCube experiment from an analysis with a 7.5 year (2010 - 2017) data. Active galactic nuclei (AGN) are among the most prominent objects in the universe, and are widely speculated to be emitters of ultra-high-energy (UHE) cosmic rays with proton domination. Based on the standard two-step LLCD mechanism of particle acceleration, a transformation of energy occurs from AGN's central super-massive black hole (SMBH) rotation to high-energy protons. Protons can be accelerated up to $\sim 0.1$ EeV energies and above, and might generate PeV neutrinos in the energy range $1$--$10$~ PeV through plausible hadronic interactions. The theoretically estimated revised extragalactic diffuse muon neutrino flux employing the ""luminosity-dependent density evolution (LDDE)"" model for the AGN luminosity function (LF) is found consistent with the IceCube level if only a fraction, $6.56\%$ of the total bolometric luminosity (BL) of AGN is being realizable to power the PeV neutrinos. In the $\Lambda$~CDM cosmological framework with the LDDE modeled LF and photon index distribution, about $5.18\%$ of the total BL is enough to power the IceCube neutrinos."
2201.00587,A New Algorithm for Pyramidal Clipping of Line Segments in E3,"['Vaclav Skala', 'Duc Huy Bui']",ARXIV,http://arxiv.org/pdf/2201.00587v1,2022-01-03T11:22:16Z,2022-01-03T11:22:16Z,['10.48550/arXiv.2201.00587'],"A new algorithm for clipping a line segment against a pyramid in E3 is presented. This algorithm avoids computation of intersection points which are not end-points of the output line segment. It also allows solving all cases more effectively. The performance of this algorithm is shown to be consistently better than existing algorithms, including the Cohen-Sutherland, Liang-Barsky and Cyrus-Beck algorithms."
2201.00588,Background independence of effective actions at critical dimension,['Mohammad R. Garousi'],ARXIV,http://arxiv.org/pdf/2201.00588v2,2022-01-03T11:27:19Z,2022-05-17T05:04:03Z,"['10.48550/arXiv.2201.00588', '10.1103/PhysRevD.105.106021']","Recently, by explicit calculations at orders $\alpha',\alpha'^2,\alpha'^3$, it has been observed that the effective action of string theory at the critical dimension is independent of the background for the closed spacetime manifolds. In this paper we speculate that for the open spacetime manifolds, the effective action is even independent of the character of the boundary, \ie the boundary couplings for timelike and spacelike boundaries are the same. We support this proposal by calculating the boundary couplings in the bosonic string theory at order $\alpha'$ for the spacelike boundary and show that they are the same as the couplings for the timelike boundary that have been recently found."
2201.00589,Secure Time-Sensitive Software-Defined Networking in Vehicles,"['Timo Häckel', 'Philipp Meyer', 'Franz Korf', 'Thomas C. Schmidt']",ARXIV,http://arxiv.org/pdf/2201.00589v2,2022-01-03T11:27:28Z,2022-08-26T10:05:55Z,"['10.48550/arXiv.2201.00589', '10.1109/TVT.2022.3202368']","Current designs of future In-Vehicle Networks (IVN) prepare for switched Ethernet backbones, which can host advanced LAN technologies such as IEEE Time-Sensitive Networking (TSN) and Software-Defined Networking (SDN). In this paper, we present an integrated Time-Sensitive Software-Defined Networking (TSSDN) architecture that simultaneously enables control of synchronous and asynchronous real-time and best-effort communication for all IVN traffic classes. Despite the central SDN controller, we can validate that control can operate without a delay penalty for TSN traffic, provided protocols are properly mapped. We demonstrate how TSSDN adaptably and reliably enhances network security for in-vehicle communication. A systematic investigation of the possible control flow integrations with switched Ether-networks reveals that these strategies allow for shaping the attack surface of a software-defined IVN. We discuss embeddings of control flow identifiers on different layers, covering the range from a fully exposed mapping to deep encapsulation. We experimentally evaluate these strategies in a production vehicle, which we map to a modern Ethernet topology. Our findings indicate that visibility of automotive control flows on lower network layers enables isolation and access control throughout the network infrastructure. Such a TSSDN backbone can establish and survey trust zones within the IVN and reduce the attack surface of connected cars in various attack scenarios."
2201.00590,Two New Algorithms for Line Clipping in E2 and Their Comparison,"['Vaclav Skala', 'Duc Huy Bui']",ARXIV,http://arxiv.org/pdf/2201.00590v1,2022-01-03T11:28:05Z,2022-01-03T11:28:05Z,['10.48550/arXiv.2201.00590'],"Many algorithms for clipping a line by a rectangular area or a convex polygon in E2 or by a non-convex or convex polyhedron in E3 have been published. The line segment clipping by the rectangular window in E2 is often restricted to the use of the Cohen-Sutherland (CS) algorithm or its modifications based on some presumptions like small clipping window or more sophisticated coding technique, etc. The line clipping problem solution is a bottleneck of many packages and applications and, therefore, it would be desirable to use the fastest algorithm even though it is more complex."
2201.00591,Observational constraints on nonlinear matter extensions of general relativity,"['E. -A. Kolonia', 'C. J. A. P. Martins']",ARXIV,http://arxiv.org/pdf/2201.00591v1,2022-01-03T11:29:29Z,2022-01-03T11:29:29Z,['10.48550/arXiv.2201.00591'],"We present a phenomenological analysis of current observational constraints on classes of FLRW cosmological models in which the matter side of Einstein's equations includes, in addition to the canonical term, a term proportional to some function of the energy-momentum tensor ($T^2=T_{\alpha\beta}T^{\alpha\beta}=\rho^2+3p^2$), or of its trace ($T=\rho-3p$). Qualitatively, one may think of these models as extensions of general relativity with a nonlinear matter Lagrangian. As such they are somewhat different from the usual dynamical dark energy or modified gravity models: in the former class of models one adds further dynamical degrees of freedom to the Lagrangian (often in the form of scalar fields), while in the latter the gravitational part of the Lagrangian is changed. We study both of these models under two different scenarios: (1) as phenomenological two-parameter or three-parameter extensions of the standard $\Lambda$CDM, in which case the model still has a cosmological constant but the nonlinear matter Lagrangian leads to additional terms in Einstein's equations, which cosmological observations tightly constrain, and (2) as alternatives to $\Lambda$CDM, where there is no cosmological constant, and the nonlinear matter term would have to provide the acceleration (which would be somewhat closer in spirit to the usual modified gravity models). A comparative analysis of the observational constraints obtained in the various cases provides some insight on the level of robustness of the $\Lambda$ model and on the parameter space still available for phenomenological alternatives."
2201.00592,Line Clipping in E3 with Expected Complexity O(1),['Vaclav Skala'],ARXIV,http://arxiv.org/pdf/2201.00592v1,2022-01-03T11:33:09Z,2022-01-03T11:33:09Z,['10.48550/arXiv.2201.00592'],A new line clipping algorithm against convex polyhedron in E3 with an expected complexity O(1) is presented. The suggested approach is based on two orthogonal projections to E2 co-ordinate system and on pre-processing of the given polyhedron. The pre-processing enables to speed up solution significantly. The proposed method is convenient for those applications when many lines are clipped against constant convex polyhedron. Theoretical considerations and experimental results are also presented.
2201.00593,Gas distribution from clusters to filaments in IllustrisTNG,"['C. Gouin', 'S. Gallo', 'N. Aghanim']",ARXIV,http://arxiv.org/pdf/2201.00593v2,2022-01-03T11:35:52Z,2022-06-06T07:03:00Z,"['10.48550/arXiv.2201.00593', '10.1051/0004-6361/202243032']","Matter distribution in the environment of galaxy clusters, from their cores to their connected cosmic filaments, must be in principle related to the underlying cluster physics and it evolutionary state. We aim to investigate how radial and azimuthal distribution of gas is affected by cluster environments, and how it can be related to cluster mass assembly history. Radial physical properties of gas (velocity, temperature, and density) is first analysed around 415 galaxy cluster environments from IllustrisTNG simulation at z = 0 (TNG300-1). Whereas hot plasma is virialised inside clusters (< R200), the dynamics of warm hot inter-galactic medium (WHIM) can be separated in two regimes: accumulating and slowly infalling gas at cluster peripheries and fast infalling motions outside clusters (> 1.5R200). The azimuthal distribution of dark matter (DM), hot and warm gas phases is secondly statistically probed by decomposing their 2-D distribution in harmonic space. Inside clusters, the azimuthal symmetries of DM and hot gas are well tracing cluster structural properties, such as their center offsets, substructure fractions and elliptical shapes. Beyond cluster virialised regions, we find that WHIM gas follows the azimuthal distribution of DM thus tracing cosmic filament patterns. Azimuthal symmetries of hot and warm gas distribution are finally shown to be imprints of cluster mass assembly history, strongly correlated with the formation time, mass accretion rate, and dynamical state of clusters. Azimuthal mode decomposition of 2-D gas distribution is a promising probe to assess the 3-D physical and dynamical cluster properties up to their connected cosmic filaments."
2201.00594,A Priority-Aware Multiqueue NIC Design,"['Ilja Behnke', 'Philipp Wiesner', 'Robert Danicki', 'Lauritz Thamsen']",ARXIV,http://arxiv.org/pdf/2201.00594v1,2022-01-03T11:39:46Z,2022-01-03T11:39:46Z,"['10.48550/arXiv.2201.00594', '10.1145/3477314.3507165']","Low-level embedded systems are used to control cyber-phyiscal systems in industrial and autonomous applications. They need to meet hard real-time requirements as unanticipated controller delays on moving machines can have devastating effects. Modern developments such as the industrial Internet of Things and autonomous machines require these devices to connect to large IP networks. Since Network Interface Controllers (NICs) trigger interrupts for incoming packets, real-time embedded systems are subject to unpredictable preemptions when connected to such networks. In this work, we propose a priority-aware NIC design to moderate network-generated interrupts by mapping IP flows to processes and based on that, consolidates their packets into different queues. These queues apply priority-dependent interrupt moderation. First experimental evaluations show that 93% of interrupts can be saved leading to an 80% decrease of processing delay of critical tasks in the configurations investigated."
2201.00595,From the lattice of torsion classes to the posets of wide subcategories and ICE-closed subcategories,['Haruhisa Enomoto'],ARXIV,http://arxiv.org/pdf/2201.00595v1,2022-01-03T11:51:44Z,2022-01-03T11:51:44Z,['10.48550/arXiv.2201.00595'],"In this paper, we compute the posets of wide subcategories and ICE-closed subcategories from the lattice of torsion classes in an abelian length category in a purely lattice-theoretical way, by using the kappa map in a completely semidistributive lattice. As for the poset of wide subcategories, we give two more simple constructions via a bijection between wide subcategories and torsion classes with canonical join representations. More precisely, for a completely semidistributive lattice, we give two poset structures on the set of elements with canonical join representations: the kappa order (defined using the extended kappa map of Barnard--Todorov--Zhu), and the core label order (generalizing the shard intersection order for congruence-uniform lattices). Then we show that these posets for the lattice of torsion classes coincide and are isomorphic to the poset of wide subcategories. As a byproduct, we give a simple description of the shard intersection order on a finite Coxeter group using the extended kappa map."
2201.00596,LiDAR Point--to--point Correspondences for Rigorous Registration of Kinematic Scanning in Dynamic Networks,"['Aurélien Brun', 'Davide Antonio Cucci', 'Jan Skaloud']",ARXIV,http://arxiv.org/pdf/2201.00596v1,2022-01-03T11:53:55Z,2022-01-03T11:53:55Z,['10.48550/arXiv.2201.00596'],"With the objective of improving the registration of LiDAR point clouds produced by kinematic scanning systems, we propose a novel trajectory adjustment procedure that leverages on the automated extraction of selected reliable 3D point--to--point correspondences between overlapping point clouds and their joint integration (adjustment) together with all raw inertial and GNSS observations. This is performed in a tightly coupled fashion using a Dynamic Network approach that results in an optimally compensated trajectory through modeling of errors at the sensor, rather than the trajectory, level. The 3D correspondences are formulated as static conditions within this network and the registered point cloud is generated with higher accuracy utilizing the corrected trajectory and possibly other parameters determined within the adjustment. We first describe the method for selecting correspondences and how they are inserted into the Dynamic Network as new observation models. We then describe the experiments conducted to evaluate the performance of the proposed framework in practical airborne laser scanning scenarios with low-cost MEMS inertial sensors. In the conducted experiments, the method proposed to establish 3D correspondences is effective in determining point--to--point matches across a wide range of geometries such as trees, buildings and cars. Our results demonstrate that the method improves the point cloud registration accuracy, that is otherwise strongly affected by errors in the determined platform attitude or position (in nominal and emulated GNSS outage conditions), and possibly determine unknown boresight angles using only a fraction of the total number of 3D correspondences that are established."
2201.00597,Do blue galaxy-clusters have hot intracluster gas?,"['Rana Misato', 'Yoshiki Toba', 'Naomi Ota', 'Naoaki Yamamoto', 'Tadayuki Kodama', 'Nobuhiro Okabe', 'Masamune Oguri', 'Ikuyuki Mitsuishi']",ARXIV,http://arxiv.org/pdf/2201.00597v1,2022-01-03T11:59:01Z,2022-01-03T11:59:01Z,"['10.48550/arXiv.2201.00597', '10.1093/pasj/psac002']","We present herein a systematic X-ray analysis of blue galaxy-clusters at $z=0.84$ discovered by the Subaru telescope. The sample consisted of 43 clusters identified by combining red-sequence and blue-cloud surveys, covering a wide range of emitter fractions (i.e., 0.3--0.8). The spatial extent of the over-density region of emitter galaxies was approximately 1~Mpc in radius. The average cluster mass was estimated as $0.6 (<1.5)\times10^{14}~{\rm M_\odot}$ from the stacked weak-lensing measurement. We analyzed the XMM-Newton archival data, and measured the X-ray luminosity of the hot intracluster medium. As a result, diffuse X-ray emission was marginally detected in 14 clusters, yielding an average luminosity of $5\times 10^{42}~{\rm erg\,s^{-1}}$. On the contrary, it was not significant in 29 clusters. The blue clusters were significantly fainter than the red-dominated clusters, and the X-ray luminosity did not show any meaningful correlation either with emitter fraction or richness. The X-ray surface brightness was low, but the amount of gas mass was estimated to be comparable to that observed in the $10^{13-14}~{\rm M_{\odot}}$ cluster. Based on the results, we suggest that the blue clusters are at the early formation stage, and the gas is yet to be compressed and heated up to produce appreciable X-rays. Follow-up spectroscopic measurements are essential to clarify the dynamical status and co-evolution of galaxies and hot gas in the blue clusters."
2201.00598,Toxicity Detection for Indic Multilingual Social Media Content,"['Manan Jhaveri', 'Devanshu Ramaiya', 'Harveen Singh Chadha']",ARXIV,http://arxiv.org/pdf/2201.00598v1,2022-01-03T12:01:47Z,2022-01-03T12:01:47Z,['10.48550/arXiv.2201.00598'],"Toxic content is one of the most critical issues for social media platforms today. India alone had 518 million social media users in 2020. In order to provide a good experience to content creators and their audience, it is crucial to flag toxic comments and the users who post that. But the big challenge is identifying toxicity in low resource Indic languages because of the presence of multiple representations of the same text. Moreover, the posts/comments on social media do not adhere to a particular format, grammar or sentence structure; this makes the task of abuse detection even more challenging for multilingual social media platforms. This paper describes the system proposed by team 'Moj Masti' using the data provided by ShareChat/Moj in \emph{IIIT-D Multilingual Abusive Comment Identification} challenge. We focus on how we can leverage multilingual transformer based pre-trained and fine-tuned models to approach code-mixed/code-switched classification tasks. Our best performing system was an ensemble of XLM-RoBERTa and MuRIL which achieved a Mean F-1 score of 0.9 on the test data/leaderboard. We also observed an increase in the performance by adding transliterated data. Furthermore, using weak metadata, ensembling and some post-processing techniques boosted the performance of our system, thereby placing us 1st on the leaderboard."
2201.00599,The effect of quantum correction on Hawking radiation for Schwarzschild black holes,['Yang Liu'],ARXIV,http://arxiv.org/pdf/2201.00599v1,2022-01-03T12:02:32Z,2022-01-03T12:02:32Z,['10.48550/arXiv.2201.00599'],"We investigate the effect of quantum correction on Hawking radiation for Schwarzschild black holes. We consider Hawking temperature and entropy to order G^2 and find that the area law of black holes should be modified. We think of Hawking radiation as tunneling and find that at certain frequency {\omega} the radiation spectrum of black holes can be pure blackbody spectrum. Therefore, it is possible to break down information conservation. In order to ensure information conservation at any energy scales, we suggest that black holes cannot release all information they have. We briefly discuss the bound on greybody factors for Schwarzschild black holes as well. Since the modification of horizon is very tiny, the bound on greybody factors has a very small difference between classical metric and quantum corrected metric."
