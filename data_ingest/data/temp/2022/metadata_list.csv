arxiv_id,title,authors,src,url,pub_date,upd_date,doi,abstract
2201.01200,The spatially homogeneous Hopf bifurcation induced jointly by memory and general delays in a diffusive system,['Yehu Lv'],ARXIV,http://arxiv.org/pdf/2201.01200v3,2022-01-04T15:28:39Z,2022-03-20T01:25:40Z,"['10.48550/arXiv.2201.01200', '10.1016/j.chaos.2022.111826']","In this paper, by incorporating the general delay to the reaction term in the memory-based diffusive system, we propose a diffusive system with memory delay and general delay (e.g., digestion, gestation, hunting, migration and maturation delays, etc.). We first derive an algorithm for calculating the normal form of Hopf bifurcation in the proposed system. The developed algorithm for calculating the normal form of Hopf bifurcation can be used to investigate the direction and stability of Hopf bifurcation. As a real application, we consider a diffusive predator-prey model with ratio-dependent Holling type-3 functional response, which includes with memory and gestation delays. The Hopf bifurcation analysis without gestation delay is first studied, then the Hopf bifurcation analysis with memory and gestation delays is studied. By using the developed algorithm for calculating the normal form of Hopf bifurcation, the supercritical and stable spatially homogeneous periodic solutions induced jointly by memory and general delays are found. The stable spatially homogeneous periodic solutions are also found by the numerical simulations which confirms our analytic result."
2201.01201,The Mnemosyne Number and the Rheology of Remembrance,"['Safa Jamali', 'Gareth H. McKinley']",ARXIV,http://arxiv.org/pdf/2201.01201v1,2022-01-04T15:29:07Z,2022-01-04T15:29:07Z,"['10.48550/arXiv.2201.01201', '10.1122/8.0000432']","The concept of a Deborah number is widely used in study of viscoelastic materials and to represent the ratio of a material relaxation time to the timescale of observation, and to demarcate transitions between predominantly viscous or elastic material responses. However, this construct does not help quantify the importance of long transients and non-monotonic stress jumps that are often observed in more complex time-varying systems. Many of these non-intuitive effects are lumped collectively under the term thixotropy; however, no proper nouns are associated with the key phenomena observed in such materials. Thixotropy arises from the ability of a complex structured fluid to remember its prior deformation history, so it is natural to name the dimensionless group representing such behavior with respect to the ability to remember. In Greek mythology, Mnemosyne was mother of the nine Muses and the goddess of memory. We thus propose the definition of a Mnemosyne number as the dimensionless product of the thixotropic time scale and the imposed rate of deformation. The Mnemosyne number is thus a measure of the flow strength compared to the thixotropic timescale. Since long transients responses are endemic to thixotropic materials, one also needs to consider the duration of flow. The relevant dimensionless measure of this duration can be represented in terms of a mutation number which compares the timescale of experiment/observation to the thixotropic timescale. Collating the mutation number and the Mnemosyne number, we construct a general two-dimensional map of thixotropic behavior, and quantify these ideas using canonical thixotropic models."
2201.01202,On the Log Abundance for Compact Kähler $3$-folds,"['Omprokash Das', 'Wenhao Ou']",ARXIV,http://arxiv.org/pdf/2201.01202v3,2022-01-04T15:29:52Z,2023-02-21T17:19:41Z,['10.48550/arXiv.2201.01202'],"In this article we show that if $(X, \Delta)$ is a log canonical compact K\""ahler $3$-fold such that $K_X+\Delta$ is nef and the numerical dimension $\nu(K_X+\Delta)\neq 2$, then $K_X+\Delta$ is semi-ample."
2201.01203,Quantifying Uncertainty in Deep Learning Approaches to Radio Galaxy Classification,"['Devina Mohan', 'Anna M. M. Scaife', 'Fiona Porter', 'Mike Walmsley', 'Micah Bowles']",ARXIV,http://arxiv.org/pdf/2201.01203v2,2022-01-04T15:31:18Z,2022-01-24T12:55:42Z,"['10.48550/arXiv.2201.01203', '10.1093/mnras/stac223']","In this work we use variational inference to quantify the degree of uncertainty in deep learning model predictions of radio galaxy classification. We show that the level of model posterior variance for individual test samples is correlated with human uncertainty when labelling radio galaxies. We explore the model performance and uncertainty calibration for different weight priors and suggest that a sparse prior produces more well-calibrated uncertainty estimates. Using the posterior distributions for individual weights, we demonstrate that we can prune 30% of the fully-connected layer weights without significant loss of performance by removing the weights with the lowest signal-to-noise ratio. A larger degree of pruning can be achieved using a Fisher information based ranking, but both pruning methods affect the uncertainty calibration for Fanaroff-Riley type I and type II radio galaxies differently. Like other work in this field, we experience a cold posterior effect, whereby the posterior must be down-weighted to achieve good predictive performance. We examine whether adapting the cost function to accommodate model misspecification can compensate for this effect, but find that it does not make a significant difference. We also examine the effect of principled data augmentation and find that this improves upon the baseline but also does not compensate for the observed effect. We interpret this as the cold posterior effect being due to the overly effective curation of our training sample leading to likelihood misspecification, and raise this as a potential issue for Bayesian deep learning approaches to radio galaxy classification in future."
2201.01204,Testing de Broglie's double solution in the mesoscopic regime,['Thomas Durt'],ARXIV,http://arxiv.org/pdf/2201.01204v1,2022-01-04T15:31:37Z,2022-01-04T15:31:37Z,"['10.48550/arXiv.2201.01204', '10.1007/s10701-022-00626-1']",We present here solutions of a non-linear Schroedinger equation in presence of an arbitrary linear external potential. The non-linearity expresses a self-focusing interaction. These solutions are the product of the pilot wave with peaked solitons the velocity of which obeys the guidance equation derived by Louis de Broglie in 1926. The degree of validity of our approximations increases when the size of the soliton decreases and becomes negligible compared to the typical size over which the pilot wave varies. We discuss the possibility to reveal their existence by implementing a humpty-dumpty Stern-Gerlach interferometer in the mesoscopic regime.
2201.01205,Local minimality properties of circular motions in $1/r^α$ potentials and of the figure-eight solution of the 3-body problem,['Marco Fenucci'],ARXIV,http://arxiv.org/pdf/2201.01205v1,2022-01-04T15:34:47Z,2022-01-04T15:34:47Z,['10.48550/arXiv.2201.01205'],"We first take into account variational problems with periodic boundary conditions, and briefly recall some sufficient conditions for a periodic solution of the Euler-Lagrange equation to be either a directional, a weak, or a strong local minimizer. We then apply the theory to circular orbits of the Kepler problem with potentials of type $1/r^\alpha, \, \alpha > 0$. By using numerical computations, we show that circular solutions are strong local minimizers for $\alpha > 1$, while they are saddle points for $\alpha \in (0,1)$. Moreover, we show that for $\alpha \in (1,2)$ the global minimizer of the action over periodic curves with degree $2$ with respect to the origin could be achieved on non-collision and non-circular solutions. After, we take into account the figure-eight solution of the 3-body problem, and we show that it is a strong local minimizer over a particular set of symmetric periodic loops."
2201.01206,Electronic structure of CeIr3 superconductor: DMFT studies,"['Sylwia Gutowska', 'Bartlomiej Wiendlocha']",ARXIV,http://arxiv.org/pdf/2201.01206v1,2022-01-04T15:34:57Z,2022-01-04T15:34:57Z,"['10.48550/arXiv.2201.01206', '10.1016/j.jmmm.2021.168917']","We present the band structure of CeIr$_3$ superconductor calculated within the dynamical mean field theory (DMFT). Standard GGA and GGA+U methods fail to reproduce the experimental electronic specific heat coefficient $\gamma_{\rm expt.}$ due to the underestimated density of states at the Fermi level $N(E_F)$ followed by an overestimated strength of electron-phonon coupling (EPC) calculated as a renormalization of $\gamma_{\rm expt.}$. The DMFT study shows a strong hybridization of $4f$ states of Ce with $5d$-states of Ir, which leads to the larger $N(E_F)$ giving the correct $\gamma_{\rm expt.}$ with a moderate EPC in agreement with the experimental data."
2201.01207,Detailed analysis on the reflection component for the black hole candidate MAXI J1348-630,"['Nan Jia', 'Xueshan Zhao', 'Lijun Gou', 'Javier A. Garcia', 'Zhenxuan Liao', 'Ye Feng', 'Yufeng Li', 'Yuan Wang', 'Huixian Li', 'Jianfeng Wu']",ARXIV,http://arxiv.org/pdf/2201.01207v2,2022-01-04T15:36:43Z,2022-01-13T02:05:22Z,"['10.48550/arXiv.2201.01207', '10.1093/mnras/stac121']","The black hole candidate MAXI J1348-630 was discovered on January 26th, 2019, with the Gas Slit Camera (GSC) on-board \textit{MAXI}. We report a detailed spectral analysis of this source by using the archived data of \textit{NuSTAR}. A total of 9 observations covered the complete outburst evolution of MAXI J1348-630 from the hard state to the soft state and finally back to the hard state. Additionally, the intermediate state is found in the transition from the hard state to the soft state. We use the state-of-art reflection model \verb'relxill' family to fit all the 9 spectra, and the spectra from two focal plane module detectors of \textit{NuSTAR} are jointly fitted for each observation. In particular, we concentrate on the results of the black hole spin parameter and the inclination of the accretion disk. Based on the analysis of the inner radius of the accretion disk, we obtain the spin parameter $a_* =0.78_{-0.04}^{+0.04}$, and the inclination angle of the inner disk $i = 29.2_{-0.5}^{+0.3}$ degrees. Furthermore, we also find that when the black hole is in the hard state, the accretion disk would show a significant truncation. The high iron abundance and ionization of the accretion disk obtained in the fitting results can be possibly explained by the high density of the accretion disk."
2201.01208,Competition between Barrier- and Entropy-Driven Activation in Glasses,"['Matthew R. Carbone', 'Marco Baity-Jesi']",ARXIV,http://arxiv.org/pdf/2201.01208v1,2022-01-04T15:37:29Z,2022-01-04T15:37:29Z,"['10.48550/arXiv.2201.01208', '10.1103/PhysRevE.106.024603']","In simplified models of glasses we clarify the existence of two different kinds of activated dynamics, which coexist, with one of the two dominating over the other. One is the energy barrier hopping that is typically used to picture activation, and the other one, which we call entropic activation, is driven by the scarcity of convenient directions. When entropic activation dominates, the height of the energy barriers is no longer the decisive to describe the system's slowdown. In our analysis, dominance of one mechanism over the other depends on the shape of the density of states and temperature. We also find that at low temperatures a phase transition between the two kinds of activation can occur. Our framework can be used to harmonize the facilitation and thermodynamic pictures of the slowdown of glasses."
2201.01209,Speech-to-SQL: Towards Speech-driven SQL Query Generation From Natural Language Question,"['Yuanfeng Song', 'Raymond Chi-Wing Wong', 'Xuefang Zhao', 'Di Jiang']",ARXIV,http://arxiv.org/pdf/2201.01209v1,2022-01-04T15:38:36Z,2022-01-04T15:38:36Z,['10.48550/arXiv.2201.01209'],"Speech-based inputs have been gaining significant momentum with the popularity of smartphones and tablets in our daily lives, since voice is the most easiest and efficient way for human-computer interaction. This paper works towards designing more effective speech-based interfaces to query the structured data in relational databases. We first identify a new task named Speech-to-SQL, which aims to understand the information conveyed by human speech and directly translate it into structured query language (SQL) statements. A naive solution to this problem can work in a cascaded manner, that is, an automatic speech recognition (ASR) component followed by a text-to-SQL component. However, it requires a high-quality ASR system and also suffers from the error compounding problem between the two components, resulting in limited performance. To handle these challenges, we further propose a novel end-to-end neural architecture named SpeechSQLNet to directly translate human speech into SQL queries without an external ASR step. SpeechSQLNet has the advantage of making full use of the rich linguistic information presented in speech. To the best of our knowledge, this is the first attempt to directly synthesize SQL based on arbitrary natural language questions, rather than a natural language-based version of SQL or its variants with a limited SQL grammar. To validate the effectiveness of the proposed problem and model, we further construct a dataset named SpeechQL, by piggybacking the widely-used text-to-SQL datasets. Extensive experimental evaluations on this dataset show that SpeechSQLNet can directly synthesize high-quality SQL queries from human speech, outperforming various competitive counterparts as well as the cascaded methods in terms of exact match accuracies."
2201.01210,Matrix inequalities and majorizations around Hermite-Hadamard's inequality,"['Jean-Christophe Bourin', 'Eun-Young Lee']",ARXIV,http://arxiv.org/pdf/2201.01210v1,2022-01-04T15:41:35Z,2022-01-04T15:41:35Z,['10.48550/arXiv.2201.01210'],We study an elementary inequality supporting the classical Hermite-Hadamard inequality in the matrix setting. This leads to a number of interesting matrix inequalities such new Schatten p-norm estimates and new majorization
2201.01211,"L-spaces, taut foliations and the Whitehead link",['Diego Santoro'],ARXIV,http://arxiv.org/pdf/2201.01211v3,2022-01-04T15:42:03Z,2023-04-28T14:03:54Z,['10.48550/arXiv.2201.01211'],"We prove that if $M$ is a rational homology sphere that is a Dehn surgery on the Whitehead link, then $M$ is not an $L$-space if and only if $M$ supports a coorientable taut foliation. The left orderability of some of these manifolds is also proved, by determining which of the constructed taut foliations have vanishing Euler class. We also present some more general results about the structure of the $L$-space surgery slopes for links whose components are unknotted and with pairwise linking number zero, and about the existence of taut foliations on the fillings of a $k$-holed torus bundle over the circle with some prescribed monodromy. Our results, combined with some results from Roberts--Shareshian--Stein, also imply that all the rational homology spheres that arise as integer surgeries on the Whitehead link satisfy the L-space conjecture."
2201.01212,AutoBalance: Optimized Loss Functions for Imbalanced Data,"['Mingchen Li', 'Xuechen Zhang', 'Christos Thrampoulidis', 'Jiasi Chen', 'Samet Oymak']",ARXIV,http://arxiv.org/pdf/2201.01212v1,2022-01-04T15:53:23Z,2022-01-04T15:53:23Z,['10.48550/arXiv.2201.01212'],"Imbalanced datasets are commonplace in modern machine learning problems. The presence of under-represented classes or groups with sensitive attributes results in concerns about generalization and fairness. Such concerns are further exacerbated by the fact that large capacity deep nets can perfectly fit the training data and appear to achieve perfect accuracy and fairness during training, but perform poorly during test. To address these challenges, we propose AutoBalance, a bi-level optimization framework that automatically designs a training loss function to optimize a blend of accuracy and fairness-seeking objectives. Specifically, a lower-level problem trains the model weights, and an upper-level problem tunes the loss function by monitoring and optimizing the desired objective over the validation data. Our loss design enables personalized treatment for classes/groups by employing a parametric cross-entropy loss and individualized data augmentation schemes. We evaluate the benefits and performance of our approach for the application scenarios of imbalanced and group-sensitive classification. Extensive empirical evaluations demonstrate the benefits of AutoBalance over state-of-the-art approaches. Our experimental findings are complemented with theoretical insights on loss function design and the benefits of train-validation split. All code is available open-source."
2201.01213,The Mini-EUSO telescope on board the International Space Station: Launch and first results,"['M Casolino', 'D Barghini', 'M Battisti', 'A Belov', 'M Bertaina', 'F Bisconti', 'C Blaksley', 'K Bolmgren', 'F Cafagna', 'G Cambiè', 'F Capel', 'T Ebisuzaki', 'F Fenu', 'A Franceschi', 'C Fuglesang', 'A Golzio', 'P Gorodetzki', 'F Kajino', 'H Kasuga', 'P Klimov', 'V. Kungel', 'M Manfrin', 'W Marszał', 'H Miyamoto', 'M Mignone', 'T Napolitano', 'G Osteria', 'E Parizot', 'P Picozza', 'L W Piotrowski', 'Z Plebaniak', 'G Prévôt', 'E Reali', 'M Ricci', 'N Sakaki', 'K Shinozaki', 'Y Takizawa', 'S Wada', 'L. Wiencke']",ARXIV,http://arxiv.org/pdf/2201.01213v1,2022-01-04T15:54:00Z,2022-01-04T15:54:00Z,['10.48550/arXiv.2201.01213'],"Mini-EUSO is a telescope launched on board the International Space Station in 2019 and currently located in the Russian section of the station. Main scientific objectives of the mission are the search for nuclearites and Strange Quark Matter, the study of atmospheric phenomena such as Transient Luminous Events, meteors and meteoroids, the observation of sea bioluminescence and of artificial satellites and man-made space debris. It is also capable of observing Extensive Air Showers generated by Ultra-High Energy Cosmic Rays with an energy above 10$^{21}$ eV and detect artificial showers generated with lasers from the ground. Mini-EUSO can map the night-time Earth in the UV range (290 - 430 nm), with a spatial resolution of about 6.3 km and a temporal resolution of 2.5 $\mu$s, observing our planet through a nadir-facing UV-transparent window in the Russian Zvezda module. The instrument, launched on 2019/08/22 from the Baikonur cosmodrome, is based on an optical system employing two Fresnel lenses and a focal surface composed of 36 Multi-Anode Photomultiplier tubes, 64 channels each, for a total of 2304 channels with single photon counting sensitivity and an overall field of view of 44$^{\circ}$. Mini-EUSO also contains two ancillary cameras to complement measurements in the near infrared and visible ranges. In this paper we describe the detector and present the various phenomena observed in the first year of operation."
2201.01214,A polynomial time infeasible interior-point arc-search algorithm for convex optimization,['Yaguang Yang'],ARXIV,http://arxiv.org/pdf/2201.01214v2,2022-01-04T15:54:44Z,2022-02-06T22:47:45Z,['10.48550/arXiv.2201.01214'],"This paper proposes an infeasible interior-point algorithm for the convex optimization problem using arc-search techniques. The proposed algorithm simultaneously selects the centering parameter and the step size, aiming at optimizing the performance in every iteration. Analytic formulas for the arc-search are provided to make the arc-search method very efficient. The convergence of the algorithm is proved and a polynomial bound of the algorithm is established. The preliminary numerical test results indicate that the algorithm is efficient and effective."
2201.01215,Liftable automorphisms of right-angled Artin groups,"['Sangrok Oh', 'Donggyun Seo', 'Philippe Tranchida']",ARXIV,http://arxiv.org/pdf/2201.01215v3,2022-01-04T15:57:58Z,2023-12-02T09:03:15Z,['10.48550/arXiv.2201.01215'],"Given a regular covering map $\varphi:\Lambda \to \Gamma$ of graphs, we investigate the subgroup $\operatorname{LAut}(\varphi)$ of the automorphism group $\operatorname{Aut}(A_\Gamma)$ of the right-angled Artin group $A_\Gamma$. This subgroup comprises all automorphisms that can be lifted to automorphisms of $A_\Lambda$. We first show that $\operatorname{LAut}(\varphi)$ is generated by a finite subset of Laurence's elementary automorphisms. For the subgroup $\operatorname{FAut}(\varphi)$ of $\operatorname{Aut}(A_\Lambda)$, which consists of lifts of automorphisms in $\operatorname{LAut}(\varphi)$, there exists a natural homomorphism $\operatorname{FAut}(\varphi)\to\operatorname{LAut}(\varphi)$ induced by $\varphi$. We then show that the kernel of this homomorphism is virtually a subgroup of the Torelli subgroup $\operatorname{IA}(A_\Lambda)$ and deduce a short exact sequence reminiscent of results from the Birman--Hilden theory for surfaces."
2201.01216,Gain/loss effects on spin-orbit coupled ultracold atoms in two-dimensional optical lattices,"['Zhi-Cong Xu', 'Ziyu Zhou', 'Enhong Cheng', 'Li-Jun Lang', 'Shi-Liang Zhu']",ARXIV,http://arxiv.org/pdf/2201.01216v3,2022-01-04T16:00:30Z,2022-06-17T09:37:36Z,"['10.48550/arXiv.2201.01216', '10.1007/s11433-022-1898-7']","Due to the fundamental position of spin-orbit coupled ultracold atoms in the simulation of topological insulators, the gain/loss effects on these systems should be evaluated when considering the measurement or the coupling to the environment. Here, incorporating the mature gain/loss techniques into the experimentally realized spin-orbit coupled ultracold atoms in two-dimensional optical lattices, we investigate the corresponding non-Hermitian tight-binding model and evaluate the gain/loss effects on various properties of the system, revealing the interplay of the non-Hermiticity and the spin-orbit coupling. Under periodic boundary conditions, we analytically obtain the topological phase diagram, which undergoes a non-Hermitian gapless interval instead of a point that the Hermitian counterpart encounters for a topological phase transition. We also unveil that the band inversion is just a necessary but not sufficient condition for a topological phase in two-level spin-orbit coupled non-Hermitian systems. Because the nodal loops of the upper or lower two dressed bands of the Hermitian counterpart can be split into exceptional loops in this non-Hermitian model, a gauge-independent Wilson-loop method is developed for numerically calculating the Chern number of multiple degenerate complex bands. Under open boundary conditions, we find that the conventional bulk-boundary correspondence does not break down with only on-site gain/loss due to the lack of non-Hermitian skin effect, but the dissipation of chiral edge states depends on the boundary selection, which may be used in the control of edge-state dynamics. Given the technical accessibility of state-dependent atom loss, this model could be realized in current cold-atom experiments."
2201.01217,Differentiating between sharp and smoother phase transitions in neutron stars,"['Jonas P. Pereira', 'Michał Bejger', 'J. Leszek Zdunik', 'Paweł Haensel']",ARXIV,http://arxiv.org/pdf/2201.01217v2,2022-01-04T16:03:38Z,2022-05-23T11:26:28Z,"['10.48550/arXiv.2201.01217', '10.1103/PhysRevD.105.123015']","The internal composition of neutron stars is still an open issue in astrophysics. Their innermost regions are impervious to light propagation and gravitational waves mostly carry global aspects of stars, meaning that only indirect inferences of their interiors could be obtained. Here we assume a hypothetical future scenario in which an equation of state softening due to a phase transition is identified and estimate the observational accuracy to differentiate a sharp phase transition from a smoother one (associated with a mixed phase/state due to the unknown value of the surface tension of dense matter) in a region of a hybrid star by means of some electromagnetic and gravitational wave observables. We show that different transition constructions lead to similar sequences of stellar configurations due to their shared thermodynamic properties. In the most optimistic case - a strong quark-hadron density jump phase transition - radius observations require fractional uncertainties smaller than $1\%-2\%$ to differentiate mixed states from sharp phase transitions. For tidal deformabilities, relative uncertainties should be smaller than $5\%-10\%$. However, for masses around the onset of stable quark cores, relative tidal deformability differences associated with strong sharp phase transitions and mixed states could be much larger (up to around $20\%-30\%$). All the above suggests that 2.5- and 3rd generation gravitational wave detectors and near-term electromagnetic missions may be able to start assessing some particular aspects of phase transitions in neutron stars. In addition, it points to some limitations on the equation of state recovery using typical neutron star observables and the impact of systematic uncertainties on modellings of the equation of state of hybrid stars. Finally, we briefly discuss other observables that may also be relevant for the probe of mixed states in stars."
2201.01218,Adaptive Template Enhancement for Improved Person Recognition using Small Datasets,"['Su Yang', 'Sanaul Hoque', 'Farzin Deravi']",ARXIV,http://arxiv.org/pdf/2201.01218v1,2022-01-03T10:14:38Z,2022-01-03T10:14:38Z,['10.48550/arXiv.2201.01218'],"A novel instance-based method for the classification of electroencephalography (EEG) signals is presented and evaluated in this paper. The non-stationary nature of the EEG signals, coupled with the demanding task of pattern recognition with limited training data as well as the potentially noisy signal acquisition conditions, have motivated the work reported in this study. The proposed adaptive template enhancement mechanism transforms the feature-level instances by treating each feature dimension separately, hence resulting in improved class separation and better query-class matching. The proposed new instance-based learning algorithm is compared with a few related algorithms in a number of scenarios. A clinical grade 64-electrode EEG database, as well as a low-quality (high-noise level) EEG database obtained with a low-cost system using a single dry sensor have been used for evaluations in biometric person recognition. The proposed approach demonstrates significantly improved classification accuracy in both identification and verification scenarios. In particular, this new method is seen to provide a good classification performance for noisy EEG data, indicating its potential suitability for a wide range of applications."
2201.01219,Multiscale Nonlocal Elasticity: A Distributed Order Fractional Formulation,"['Wei Ding', 'Sansit Patnaik', 'Fabio Semperlotti']",ARXIV,http://arxiv.org/pdf/2201.01219v1,2021-12-24T23:38:07Z,2021-12-24T23:38:07Z,['10.48550/arXiv.2201.01219'],"This study presents a generalized multiscale nonlocal elasticity theory that leverages distributed order fractional calculus to accurately capture coexisting multiscale and nonlocal effects within a macroscopic continuum. The nonlocal multiscale behavior is captured via distributed order fractional constitutive relations derived from a nonlocal thermodynamic formulation. The governing equations of the inhomogeneous continuum are obtained via the Hamilton principle. As a generalization of the constant order fractional continuum theory, the distributed order theory can model complex media characterized by inhomogeneous nonlocality and multiscale effects. In order to understand the correspondence between microscopic effects and the properties of the continuum, an equivalent mass-spring lattice model is also developed by direct discretization of the distributed order elastic continuum. Detailed theoretical arguments are provided to show the equivalence between the discrete and the continuum distributed order models in terms of internal nonlocal forces, potential energy distribution, and boundary conditions. These theoretical arguments facilitate the physical interpretation of the role played by the distributed order framework within nonlocal elasticity theories. They also highlight the outstanding potential and opportunities offered by this methodology to account for multiscale nonlocal effects. The capabilities of the methodology are also illustrated via a numerical study that highlights the excellent agreement between the displacement profiles and the total potential energy predicted by the two models under various order distributions. Remarkably, multiscale effects such as displacement distortion, material softening, and energy concentration are well captured at continuum level by the distributed order theory."
2201.01220,Phase diagram of nickelate superconductors calculated by dynamical vertex approximation,"['Karsten Held', 'Liang Si', 'Paul Worm', 'Oleg Janson', 'Ryotaro Arita', 'Zhicheng Zhong', 'Jan M. Tomczak', 'Motoharu Kitatani']",ARXIV,http://arxiv.org/pdf/2201.01220v1,2022-01-04T16:05:33Z,2022-01-04T16:05:33Z,"['10.48550/arXiv.2201.01220', '10.3389/fphy.2021.810394']","We review the electronic structure of nickelate superconductors with and without effects of electronic correlations. As a minimal model we identify the one-band Hubbard model for the Ni 3$d_{x^2-y^2}$ orbital plus a pocket around the $A$-momentum. The latter however merely acts as a decoupled electron reservoir. This reservoir makes a careful translation from {nominal} Sr-doping to the doping of the one-band Hubbard model mandatory. Our dynamical mean-field theory calculations, in part already supported by experiment, indicate that the $\Gamma$ pocket, Nd 4$f$ orbitals, oxygen 2$p$ and {the} other Ni 3$d$ orbitals are not relevant in the superconducting doping regime. The physics is completely different if topotactic hydrogen is present or the oxygen reduction is incomplete. Then, a two-band physics hosted by the Ni 3$d_{x^2-y^2}$ and 3$d_{3z^2-r^2}$ orbitals emerges. Based on our minimal modeling we calculated the superconducting $T_c$ vs. Sr-doping $x$ phase diagram prior to experiment using the dynamical vertex approximation. For such a notoriously difficult to determine quantity as $T_c$, the agreement with experiment is astonishingly good. The prediction that $T_c$ is enhanced with pressure or compressive strain, has been confirmed experimentally as well. This supports that the one-band Hubbard model plus an electron reservoir is the appropriate minimal model."
2201.01221,A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning,"['Xueguang Lyu', 'Andrea Baisero', 'Yuchen Xiao', 'Christopher Amato']",ARXIV,http://arxiv.org/pdf/2201.01221v2,2022-01-03T14:51:30Z,2022-05-25T17:55:25Z,['10.48550/arXiv.2201.01221'],"Centralized Training for Decentralized Execution, where training is done in a centralized offline fashion, has become a popular solution paradigm in Multi-Agent Reinforcement Learning. Many such methods take the form of actor-critic with state-based critics, since centralized training allows access to the true system state, which can be useful during training despite not being available at execution time. State-based critics have become a common empirical choice, albeit one which has had limited theoretical justification or analysis. In this paper, we show that state-based critics can introduce bias in the policy gradient estimates, potentially undermining the asymptotic guarantees of the algorithm. We also show that, even if the state-based critics do not introduce any bias, they can still result in a larger gradient variance, contrary to the common intuition. Finally, we show the effects of the theories in practice by comparing different forms of centralized critics on a wide range of common benchmarks, and detail how various environmental properties are related to the effectiveness of different types of critics."
2201.01222,The cluster structure function,"['Andrew R. Cohen', 'Paul M. B. Vitányi']",ARXIV,http://arxiv.org/pdf/2201.01222v3,2022-01-04T16:05:59Z,2022-10-14T13:18:00Z,['10.48550/arXiv.2201.01222'],"For each partition of a data set into a given number of parts there is a partition such that every part is as much as possible a good model (an ""algorithmic sufficient statistic"") for the data in that part. Since this can be done for every number between one and the number of data, the result is a function, the cluster structure function. It maps the number of parts of a partition to values related to the deficiencies of being good models by the parts. Such a function starts with a value at least zero for no partition of the data set and descents to zero for the partition of the data set into singleton parts. The optimal clustering is the one chosen to minimize the cluster structure function. The theory behind the method is expressed in algorithmic information theory (Kolmogorov complexity). In practice the Kolmogorov complexities involved are approximated by a concrete compressor. We give examples using real data sets: the MNIST handwritten digits and the segmentation of real cells as used in stem cell research."
2201.01223,Effects of ultrafast free-carrier dynamics on frequency comb generation in graphene-based microresonators,['Ambaresh Sahoo'],ARXIV,http://arxiv.org/pdf/2201.01223v1,2022-01-04T16:06:13Z,2022-01-04T16:06:13Z,['10.48550/arXiv.2201.01223'],"Manipulation of the dynamics of cavity solitons, precise control of frequency comb spectra and nonlinear response of microresonators through exploitation of the ultrafast optical properties of graphene can have an immense impact on the technological advancement of on-chip photonic devices. Here, we report that an efficient self-frequency blueshifted frequency comb at optical and near-infrared wavelengths can be achieved owing to the near-instantaneous free-carrier dynamics of graphene in a realistic graphene-covered silicon nitride microresonator. We perform a stability analysis to find the region of stable cavity soliton excitation, which reveals that the nonlinearity of graphene helps in improving the performance of the devices."
2201.01224,Sharp bounds on the least eigenvalue of a graph determined from edge clique partitions,"['Domingos M. Cardoso', 'Inês Serôdio Costa', 'Rui Duarte']",ARXIV,http://arxiv.org/pdf/2201.01224v4,2022-01-04T16:11:43Z,2022-02-24T15:17:10Z,['10.48550/arXiv.2201.01224'],"Sharp bounds on the least eigenvalue of an arbitrary graph are presented. Necessary and sufficient (just sufficient) conditions for the lower (upper) bound to be attained are deduced using edge clique partitions. As an application, we prove that the least eigenvalue of the $n$-Queens' graph $\mathcal{Q}(n)$ is equal to $-4$ for every $n \ge 4$ and it is also proven that the multiplicity of this eigenvalue is $(n-3)^2$. Additionally, some results on the edge clique partition graph parameters are obtained."
2201.01225,Propagation and attenuation of pulses driven by low velocity normal impacts in granular media,"['A. C. Quillen', 'Max Neiderbach', 'Bingcheng Suo', 'Juliana South', 'Esteban Wright', 'Nathan Skerrett', 'Paul Sánchez', 'Fernando David Cúñez', 'Peter Miklavcic', 'Heesam Askari']",ARXIV,http://arxiv.org/pdf/2201.01225v4,2022-01-04T16:12:21Z,2022-08-01T11:10:00Z,"['10.48550/arXiv.2201.01225', '10.1016/j.icarus.2022.115139']","We carry out experiments of low velocity normal impacts into granular materials that fill an approximately cylindrical 42 litre tub. Motions in the granular medium are tracked with an array of 7 embedded accelerometers. Longitudinal pulses excited by the impact attenuate and their shapes broaden and become smoother as a function of travel distance from the site of impact. Pulse propagation is not spherically symmetric about the site of impact. Peak amplitudes are about twice as large for the pulse propagating downward than at 45 degrees from vertical. An advection-diffusion model is used to estimate the dependence of pulse properties as a function of travel distance from the site of impact. The power law forms for pulse peak pressure, velocity and seismic energy depend on distance from impact to a power of -2.5 and this rapid decay is approximately consistent with our experimental measurements. Our experiments support a seismic jolt model, giving rapid attenuation of impact generated seismic energy into rubble asteroids, rather than a reverberation model, where seismic energy slowly decays. We apply our diffusive model to estimate physical properties of the seismic pulse that will be excited by the forthcoming DART mission impact onto the secondary, Dimorphos, of the asteroid binary (65803) Didymos system. We estimate that the pulse peak acceleration will exceed the surface gravity as it travels through the asteroid."
2201.01226,Adversarial Transformation of Spoofing Attacks for Voice Biometrics,"['Alejandro Gomez-Alanis', 'Jose A. Gonzalez-Lopez', 'Antonio M. Peinado']",ARXIV,http://arxiv.org/pdf/2201.01226v1,2022-01-04T16:14:03Z,2022-01-04T16:14:03Z,['10.48550/arXiv.2201.01226'],"Voice biometric systems based on automatic speaker verification (ASV) are exposed to \textit{spoofing} attacks which may compromise their security. To increase the robustness against such attacks, anti-spoofing or presentation attack detection (PAD) systems have been proposed for the detection of replay, synthesis and voice conversion based attacks. Recently, the scientific community has shown that PAD systems are also vulnerable to adversarial attacks. However, to the best of our knowledge, no previous work have studied the robustness of full voice biometrics systems (ASV + PAD) to these new types of adversarial \textit{spoofing} attacks. In this work, we develop a new adversarial biometrics transformation network (ABTN) which jointly processes the loss of the PAD and ASV systems in order to generate white-box and black-box adversarial \textit{spoofing} attacks. The core idea of this system is to generate adversarial \textit{spoofing} attacks which are able to fool the PAD system without being detected by the ASV system. The experiments were carried out on the ASVspoof 2019 corpus, including both logical access (LA) and physical access (PA) scenarios. The experimental results show that the proposed ABTN clearly outperforms some well-known adversarial techniques in both white-box and black-box attack scenarios."
2201.01227,Sparse Non-Convex Optimization For Higher Moment Portfolio Management,['Farshad Noravesh'],ARXIV,http://arxiv.org/pdf/2201.01227v2,2022-01-04T16:14:23Z,2022-01-06T13:29:47Z,['10.48550/arXiv.2201.01227'],"One of the reasons that higher order moment portfolio optimization methods are not fully used by practitioners in investment decisions is the complexity that these higher moments create by making the optimization problem nonconvex. Many few methods and theoretical results exists in the literature, but the present paper uses the method of successive convex approximation for the mean-variance-skewness problem."
2201.01228,Exponentially Convergent Direct Adaptive Pole Placement Control of Plants with Unmatched Uncertainty under FE Condition,"['Anton Glushchenko', 'Konstantin Lastochkin']",ARXIV,http://arxiv.org/pdf/2201.01228v4,2022-01-04T16:18:05Z,2022-04-11T09:24:59Z,['10.48550/arXiv.2201.01228'],"A new method of direct adaptive pole placement control (APPC) is developed for plants with unmatched uncertainty, which linearly depends on a state vector. It guarantees the exponential stability of a control system and exponential convergence of control law adjustable parameters to their true values when the regressor is finitely exciting. Considering the known classical APPC schemes and adaptive methods with exponential regulation, the advantages of the proposed one are that it does not require a priori information on a control input matrix and ensures the monotonic transient behavior of each adjustable parameter of the control law. The theoretical results are supported by the numerical experiments."
2201.01229,Impact of unplanned service disruptions on urban public transit systems,"['Baichuan Mo', 'Max Y von Franque', 'Haris N. Koutsopoulosc', 'John Attanuccid', 'Jinhua Zhao']",ARXIV,http://arxiv.org/pdf/2201.01229v1,2022-01-03T16:36:20Z,2022-01-03T16:36:20Z,['10.48550/arXiv.2201.01229'],"This paper proposes a general unplanned incident analysis framework for public transit systems from the supply and demand sides using automated fare collection (AFC) and automated vehicle location (AVL) data. Specifically, on the supply side, we propose an incident-based network redundancy index to analyze the network's ability to provide alternative services under a specific rail disruption. The impacts on operations are analyzed through the headway changes. On the demand side, the analysis takes place at two levels: aggregate flows and individual response. We calculate the demand changes of different rail lines, rail stations, bus routes, and bus stops to better understand the passenger flow redistribution under incidents. Individual behavior is analyzed using a binary logit model based on inferred passengers' mode choices and socio-demographics using AFC data. The public transit system of the Chicago Transit Authority is used as a case study. Two rail disruption cases are analyzed, one with high network redundancy around the impacted stations and the other with low. Results show that the service frequency of the incident line was largely reduced (by around 30% ~ 70%) during the incident time. Nearby rail lines with substitutional functions were also slightly affected. Passengers showed different behavioral responses in the two incident scenarios. In the low redundancy case, most of the passengers chose to use nearby buses to move, either to their destinations or to the nearby rail lines. In the high redundancy case, most of the passengers transferred directly to nearby lines. Corresponding policy implications and operating suggestions are discussed."
2201.01230,Robust Semi-supervised Federated Learning for Images Automatic Recognition in Internet of Drones,"['Zhe Zhang', 'Shiyao Ma', 'Zhaohui Yang', 'Zehui Xiong', 'Jiawen Kang', 'Yi Wu', 'Kejia Zhang', 'Dusit Niyato']",ARXIV,http://arxiv.org/pdf/2201.01230v1,2022-01-03T16:49:33Z,2022-01-03T16:49:33Z,['10.48550/arXiv.2201.01230'],"Air access networks have been recognized as a significant driver of various Internet of Things (IoT) services and applications. In particular, the aerial computing network infrastructure centered on the Internet of Drones has set off a new revolution in automatic image recognition. This emerging technology relies on sharing ground truth labeled data between Unmanned Aerial Vehicle (UAV) swarms to train a high-quality automatic image recognition model. However, such an approach will bring data privacy and data availability challenges. To address these issues, we first present a Semi-supervised Federated Learning (SSFL) framework for privacy-preserving UAV image recognition. Specifically, we propose model parameters mixing strategy to improve the naive combination of FL and semi-supervised learning methods under two realistic scenarios (labels-at-client and labels-at-server), which is referred to as Federated Mixing (FedMix). Furthermore, there are significant differences in the number, features, and distribution of local data collected by UAVs using different camera modules in different environments, i.e., statistical heterogeneity. To alleviate the statistical heterogeneity problem, we propose an aggregation rule based on the frequency of the client's participation in training, namely the FedFreq aggregation rule, which can adjust the weight of the corresponding local model according to its frequency. Numerical results demonstrate that the performance of our proposed method is significantly better than those of the current baseline and is robust to different non-IID levels of client data."
2201.01231,Characteristic curves for set-valued Hamilton-Jacobi equations,['Daniela Visetti'],ARXIV,http://arxiv.org/pdf/2201.01231v1,2022-01-04T16:26:20Z,2022-01-04T16:26:20Z,['10.48550/arXiv.2201.01231'],"The method of characteristics is extended to set-valued Hamilton-Jacobi equations. This problems arises from a calculus of variations' problem with a multicriteria Lagrangian function: through an embedding into a set-valued framework, a set-valued Hamilton-Jacobi equation is derived, where the Hamiltonian function is the Fenchel conjugate of the Lagrangian function. In this paper a method of characteristics is described and some results are given for the Fenchel conjugate."
2201.01232,"Exploring Longitudinal Cough, Breath, and Voice Data for COVID-19 Progression Prediction via Sequential Deep Learning: Model Development and Validation","['Ting Dang', 'Jing Han', 'Tong Xia', 'Dimitris Spathis', 'Erika Bondareva', 'Chloë Siegele-Brown', 'Jagmohan Chauhan', 'Andreas Grammenos', 'Apinan Hasthanasombat', 'Andres Floto', 'Pietro Cicuta', 'Cecilia Mascolo']",ARXIV,http://arxiv.org/pdf/2201.01232v2,2022-01-04T16:30:15Z,2022-06-22T12:53:57Z,"['10.48550/arXiv.2201.01232', '10.2196/37004']","Recent work has shown the potential of using audio data (eg, cough, breathing, and voice) in the screening for COVID-19. However, these approaches only focus on one-off detection and detect the infection given the current audio sample, but do not monitor disease progression in COVID-19. Limited exploration has been put forward to continuously monitor COVID-19 progression, especially recovery, through longitudinal audio data. Tracking disease progression characteristics could lead to more timely treatment. The primary objective of this study is to explore the potential of longitudinal audio samples over time for COVID-19 progression prediction and, especially, recovery trend prediction using sequential deep learning techniques. Crowdsourced respiratory audio data, including breathing, cough, and voice samples, from 212 individuals over 5-385 days were analyzed. We developed a deep learning-enabled tracking tool using gated recurrent units (GRUs) to detect COVID-19 progression by exploring the audio dynamics of the individuals' historical audio biomarkers. The investigation comprised 2 parts: (1) COVID-19 detection in terms of positive and negative (healthy) tests, and (2) longitudinal disease progression prediction over time in terms of probability of positive tests. The strong performance for COVID-19 detection, yielding an AUROC of 0.79, a sensitivity of 0.75, and a specificity of 0.71 supported the effectiveness of the approach compared to methods that do not leverage longitudinal dynamics. We further examined the predicted disease progression trajectory, displaying high consistency with test results with a correlation of 0.75 in the test cohort and 0.86 in a subset of the test cohort who reported recovery. Our findings suggest that monitoring COVID-19 evolution via longitudinal audio data has potential in the tracking of individuals' disease progression and recovery."
2201.01233,Discrete and continuous representations and processing in deep learning: Looking forward,"['Ruben Cartuyvels', 'Graham Spinks', 'Marie-Francine Moens']",ARXIV,http://arxiv.org/pdf/2201.01233v1,2022-01-04T16:30:18Z,2022-01-04T16:30:18Z,"['10.48550/arXiv.2201.01233', '10.1016/j.aiopen.2021.07.002']","Discrete and continuous representations of content (e.g., of language or images) have interesting properties to be explored for the understanding of or reasoning with this content by machines. This position paper puts forward our opinion on the role of discrete and continuous representations and their processing in the deep learning field. Current neural network models compute continuous-valued data. Information is compressed into dense, distributed embeddings. By stark contrast, humans use discrete symbols in their communication with language. Such symbols represent a compressed version of the world that derives its meaning from shared contextual information. Additionally, human reasoning involves symbol manipulation at a cognitive level, which facilitates abstract reasoning, the composition of knowledge and understanding, generalization and efficient learning. Motivated by these insights, in this paper we argue that combining discrete and continuous representations and their processing will be essential to build systems that exhibit a general form of intelligence. We suggest and discuss several avenues that could improve current neural networks with the inclusion of discrete elements to combine the advantages of both types of representations."
2201.01234,On the $p$-adic theory of local models,"['Johannes Anschütz', 'Ian Gleason', 'João Lourenço', 'Timo Richarz']",ARXIV,http://arxiv.org/pdf/2201.01234v1,2022-01-04T16:38:34Z,2022-01-04T16:38:34Z,['10.48550/arXiv.2201.01234'],"We prove the Scholze--Weinstein conjecture on the existence and uniqueness of local models of local Shimura varieties and the test function conjecture of Haines--Kottwitz in this setting. In order to achieve this, we establish the specialization principle for well-behaved $p$-adic kimberlites, show that these include the v-sheaf local models, determine their special fibers using hyperbolic localization for the \'etale cohomology of small v-stacks and analyze the resulting specialization morphism using convolution."
2201.01235,On the Minimal Adversarial Perturbation for Deep Neural Networks with Provable Estimation Error,"['Fabio Brau', 'Giulio Rossolini', 'Alessandro Biondi', 'Giorgio Buttazzo']",ARXIV,http://arxiv.org/pdf/2201.01235v1,2022-01-04T16:40:03Z,2022-01-04T16:40:03Z,"['10.48550/arXiv.2201.01235', '10.1109/TPAMI.2022.3195616']","Although Deep Neural Networks (DNNs) have shown incredible performance in perceptive and control tasks, several trustworthy issues are still open. One of the most discussed topics is the existence of adversarial perturbations, which has opened an interesting research line on provable techniques capable of quantifying the robustness of a given input. In this regard, the Euclidean distance of the input from the classification boundary denotes a well-proved robustness assessment as the minimal affordable adversarial perturbation. Unfortunately, computing such a distance is highly complex due the non-convex nature of NNs. Despite several methods have been proposed to address this issue, to the best of our knowledge, no provable results have been presented to estimate and bound the error committed. This paper addresses this issue by proposing two lightweight strategies to find the minimal adversarial perturbation. Differently from the state-of-the-art, the proposed approach allows formulating an error estimation theory of the approximate distance with respect to the theoretical one. Finally, a substantial set of experiments is reported to evaluate the performance of the algorithms and support the theoretical findings. The obtained results show that the proposed strategies approximate the theoretical distance for samples close to the classification boundary, leading to provable robustness guarantees against any adversarial attacks."
2201.01236,Left-exact Localizations of $\infty$-Topoi II: Grothendieck Topologies,"['Mathieu Anel', 'Georg Biedermann', 'Eric Finster', 'André Joyal']",ARXIV,http://arxiv.org/pdf/2201.01236v2,2022-01-04T16:40:59Z,2023-05-28T15:07:00Z,['10.48550/arXiv.2201.01236'],"We revisit the work of To\""en--Vezzosi and Lurie on Grothendieck topologies, using the new tools of acyclic classes and congruences. We introduce a notion of extended Grothendieck topology on any $\infty$-topos, and prove that the poset of extended Grothendieck topologies is isomorphic to that of topological localizations, hypercomplete localizations, Lawvere--Tierney topologies, and covering topologies (a variation on the notion of pretopology). It follows that these posets are small and have the structure of a frame. We revisit also the topological--cotopological factorization by introducing the notion of a cotopological morphism. And we revisit the notions of hypercompletion, hyperdescent, hypercoverings and hypersheaves associated to an extended Grothendieck topology. We also introduce the notion of forcing, which is a tool to compute with localizations of $\infty$-topoi."
2201.01237,A note on the steady Poiseuille flow of Carreau-Yasuda fluid,"['Nikolay Kutev', 'Sonia Tabakova']",ARXIV,http://arxiv.org/pdf/2201.01237v2,2022-01-04T16:41:31Z,2022-02-05T16:23:19Z,"['10.48550/arXiv.2201.01237', '10.1007/978-3-031-21484-4_10']","The steady Poiseuille flow of Carreau-Yasuda fluid in a pipe, caused by constant pressure gradient, is studied theoretically. It is proved that at some values of the viscosity model parameters, the problem has a classical solution, while at others - generalized solution. For the latter, a necessary and sufficient condition is found, which depends on the pressure gradient and Carreau-Yasuda model parameters."
2201.01238,Derived Langlands VII: The PSH Algebra of Products of General Linear Groups,['Victor P Snaith'],ARXIV,http://arxiv.org/pdf/2201.01238v1,2022-01-04T16:44:55Z,2022-01-04T16:44:55Z,['10.48550/arXiv.2201.01238'],In this article we put a very elaborate PSH-like structure on the $R_{+}(-)$ groups of products of finite general linear groups. This is not the case we want. Firstly one would really want the actual big PSH algebra of products of general linear groups with entries in a characteristic zero $p$-adic local field. There may be technical difficulties with this. However the $R_{+}(-)$ gadget for products of general linear groups with entries in a characteristic zero $p$-adic local field seems to work for us by allowing various reduction to compact open subgroups and reduction maps modulo different prime powers from there. These reductions may allow the verification of functional equations and analytic groups properties which characterise the Riemann zeta function and presumably similarly characterise the $2$-variable L-functions.
2201.01239,The Most Difference in Means: A Statistic for the Strength of Null and Near-Zero Results,"['Bruce A. Corliss', 'Taylor R. Brown', 'Tingting Zhang', 'Kevin A. Janes', 'Heman Shakeri', 'Philip E. Bourne']",ARXIV,http://arxiv.org/pdf/2201.01239v4,2022-01-04T16:46:44Z,2022-05-24T23:39:03Z,['10.48550/arXiv.2201.01239'],"Statistical insignificance does not suggest the absence of effect, yet scientists must often use null results as evidence of negligible (near-zero) effect size to falsify scientific hypotheses. Doing so must assess a result's null strength, defined as the evidence for a negligible effect size. Such an assessment would differentiate strong null results that suggest a negligible effect size from weak null results that suggest a broad range of potential effect sizes. We propose the most difference in means ($\delta_M$) as a two-sample statistic that can both quantify null strength and perform a hypothesis test for negligible effect size. To facilitate consensus when interpreting results, our statistic allows scientists to conclude that a result has negligible effect size using different thresholds with no recalculation required. To assist with selecting a threshold, $\delta_M$ can also compare null strength between related results. Both $\delta_M$ and the relative form of $\delta_M$ outperform other candidate statistics in comparing null strength. We compile broadly related results and use the relative $\delta_M$ to compare null strength across different treatments, measurement methods, and experiment models. Reporting the relative $\delta_M$ may provide a technical solution to the file drawer problem by encouraging the publication of null and near-zero results."
2201.01240,Feedback and Engagement on an Introductory Programming Module,"['Beate Grawemeyer', 'John Halloran', 'Matthew England', 'David Croft']",ARXIV,http://arxiv.org/pdf/2201.01240v1,2022-01-04T16:53:09Z,2022-01-04T16:53:09Z,['10.48550/arXiv.2201.01240'],"We ran a study on engagement and achievement for a first year undergraduate programming module which used an online learning environment containing tasks which generate automated feedback. Students could also access human feedback from traditional labs. We gathered quantitative data on engagement and achievement which allowed us to split the cohort into 6 groups. We then ran interviews with students after the end of the module to produce qualitative data on perceptions of what feedback is, how useful it is, the uses made of it, and how it bears on engagement. A general finding was that human and automated feedback are different but complementary. However there are different feedback needs by group. Our findings imply: (1) that a blended human-automated feedback approach improves engagement; and (2) that this approach needs to be differentiated according to type of student. We give implications for the design of feedback for programming modules."
2201.01241,Results of the EURADOS international comparison exercise on neutron spectra unfolding in Bonner spheres spectrometry,"['J. M. Gómez-Ros', 'R. Bedogni', 'C. Domingo', 'J. S. Eakins', 'N. Roberts', 'R. J. Tanner']",ARXIV,http://arxiv.org/pdf/2201.01241v2,2022-01-04T16:53:54Z,2022-04-21T13:28:48Z,"['10.48550/arXiv.2201.01241', '10.1016/j.radmeas.2022.106755']","This paper summarizes the results obtained from an international comparison exercise on neutron spectra unfolding in Bonner spheres spectrometry, organized within the activities of EURADOS working group 6: computational dosimetry. Four realistic situations were considered: a medical accelerator, a workplace field, an irradiation room and a skyshine scenario. The reference solutions are presented, given in terms of idealized fluence-energy distributions and dose rates, along with details of their derivation using verified Monte Carlo codes. The wide variety of unfolded results that were submitted by the participants are then provided, with some shown to agree well with the reference solutions but others showing significant energy-dependent discrepancies. Finally, explanations for some of these discrepancies are proposed, along with suggested methods for how they might be improved."
2201.01242,Evaluation of the Feasibility of Phosphorene for Electronic DNA Sequencing Using Density Functional Theory Calculations,"['Matthew B. Henry', 'Mukesh Tumbapo', 'Kolby Wilson', 'Benjamin O. Tayo']",ARXIV,http://arxiv.org/pdf/2201.01242v1,2022-01-04T16:54:18Z,2022-01-04T16:54:18Z,['10.48550/arXiv.2201.01242'],"Electronic DNA sequencing using two-dimensional (2D) materials such as graphene has recently emerged as the next-generation of DNA sequencing technology. Owing to its commercial availability and remarkable physical and conductive properties, graphene has been widely investigated for DNA sequencing by several theoretical and experimental groups. Despite this progress, sequencing using graphene remains a major challenge. This is due to the hydrophobic nature of graphene, which causes DNA bases to stick to its surface via strong {\pi}-{\pi} interactions, reducing translocation speed and increasing error rates. To circumvent this challenge, the scientific community has turned its attention to other 2D materials beyond graphene. One such material is phosphorene. In this article, we performed first-principle computational studies using density functional theory (DFT) to evaluate the ability of phosphorene to distinguish individual DNA bases using two detection principles, namely, nanopore and nanoribbon modalities. We observe that binding energies of DNA bases are lower in phosphorene compared to graphene. The energy gap modulations due to interaction with DNA bases are very significant in phosphorene compared to graphene. Our studies show that phosphorene is superior to graphene, and hence a promising alternative for electronic DNA sequencing."
2201.01243,"Eclipsing Binaries in Dynamically Interacting Close, Multiple Systems",['Tamás Borkovits'],ARXIV,http://arxiv.org/pdf/2201.01243v1,2022-01-04T16:54:28Z,2022-01-04T16:54:28Z,['10.48550/arXiv.2201.01243'],"Close, compact, hierarchical, multiple stellar systems, i.e., multiples having an outer orbital period from months to a few years, comprise a small, but continuously growing group of the triple and multiple star zoo. Many of them consist of at least one eclipsing pair of stars and, therefore, exhibit readily observable short-term dynamical interactions among the components. Thus, their dynamical and astrophysical properties can be explored with high precision. In this paper we present an overview of the history of the search for additional components around eclipsing binaries from the first serendipitous discoveries to more systematic recent studies. We describe the different observational detection methods and discuss their connections to the different kinds of astrophysical and dynamical information that can be mined from the different datasets. Moreover, the connection amongst the observable phenomena and the long-term dynamics of such systems is also discussed."
2201.01244,The Parental Active Model: a unifying stochastic description of self-propulsion,"['Lorenzo Caprini', 'Alexander Ralf Sprenger', 'Hartmut Löwen', 'René Wittmann']",ARXIV,http://arxiv.org/pdf/2201.01244v1,2022-01-04T16:56:05Z,2022-01-04T16:56:05Z,"['10.48550/arXiv.2201.01244', '10.1063/5.0084213']","We propose a new overarching model for self-propelled particles that flexibly generates a full family of ""descendants"". The general dynamics introduced in this paper, which we denote as ""parental"" active model (PAM), unifies two special cases commonly used to describe active matter, namely active Brownian particles (ABPs) and active Ornstein-Uhlenbeck particles (AOUPs). We thereby document the existence of a deep and close stochastic relationship between them, resulting in the subtle balance between fluctuations in the magnitude and direction of the self-propulsion velocity. Besides illustrating the relation between these two common models, the PAM can generate additional offspring, interpolating between ABP and AOUP dynamics, that could provide more suitable models for a large class of living and inanimate active matter systems, possessing characteristic distributions of their self-propulsion velocity. Our general model is evaluated in the presence of a harmonic external confinement. For this reference example, we present a two-state phase diagram which sheds light on the transition in the shape of the positional density distribution, from a unimodal Gaussian for AOUPs to a Mexican-hat-like profile for ABPs."
2201.01245,On the primality and elasticity of algebraic valuations of cyclic free semirings,"['Nancy Jiang', 'Bangzheng Li', 'Sophie Zhu']",ARXIV,http://arxiv.org/pdf/2201.01245v1,2022-01-04T17:01:36Z,2022-01-04T17:01:36Z,['10.48550/arXiv.2201.01245'],"A cancellative commutative monoid is atomic if every non-invertible element factors into irreducibles. Under certain mild conditions on a positive algebraic number $\alpha$, the additive monoid $M_\alpha$ of the evaluation semiring $\mathbb{N}_0[\alpha]$ is atomic. The atomic structure of both the additive and the multiplicative monoids of $\mathbb{N}_0[\alpha]$ has been the subject of several recent papers. Here we focus on the monoids $M_\alpha$, and we study its omega-primality and elasticity, aiming to better understand some fundamental questions about their atomic decompositions. We prove that when $\alpha$ is less than 1, the atoms of $M_\alpha$ are as far from being prime as they can possibly be. Then we establish some results about the elasticity of $M_\alpha$, including that when $\alpha$ is rational, the elasticity of $M_\alpha$ is full (this was previously conjectured by S. T. Chapman, F. Gotti, and M. Gotti)."
2201.01246,Efficient Quantum Feature Extraction for CNN-based Learning,"['Tong Dou', 'Guofeng Zhang', 'Wei Cui']",ARXIV,http://arxiv.org/pdf/2201.01246v2,2022-01-04T17:04:07Z,2022-01-07T01:35:49Z,['10.48550/arXiv.2201.01246'],"Recent work has begun to explore the potential of parametrized quantum circuits (PQCs) as general function approximators. In this work, we propose a quantum-classical deep network structure to enhance classical CNN model discriminability. The convolutional layer uses linear filters to scan the input data. Moreover, we build PQC, which is a more potent function approximator, with more complex structures to capture the features within the receptive field. The feature maps are obtained by sliding the PQCs over the input in a similar way as CNN. We also give a training algorithm for the proposed model. The hybrid models used in our design are validated by numerical simulation. We demonstrate the reasonable classification performances on MNIST and we compare the performances with models in different settings. The results disclose that the model with ansatz in high expressibility achieves lower cost and higher accuracy."
2201.01247,Value Functions Factorization with Latent State Information Sharing in Decentralized Multi-Agent Policy Gradients,"['Hanhan Zhou', 'Tian Lan', 'Vaneet Aggarwal']",ARXIV,http://arxiv.org/pdf/2201.01247v3,2022-01-04T17:05:07Z,2023-06-08T05:44:57Z,"['10.48550/arXiv.2201.01247', '10.1109/TETCI.2023.3293193']","Value function factorization via centralized training and decentralized execution is promising for solving cooperative multi-agent reinforcement tasks. One of the approaches in this area, QMIX, has become state-of-the-art and achieved the best performance on the StarCraft II micromanagement benchmark. However, the monotonic-mixing of per agent estimates in QMIX is known to restrict the joint action Q-values it can represent, as well as the insufficient global state information for single agent value function estimation, often resulting in suboptimality. To this end, we present LSF-SAC, a novel framework that features a variational inference-based information-sharing mechanism as extra state information to assist individual agents in the value function factorization. We demonstrate that such latent individual state information sharing can significantly expand the power of value function factorization, while fully decentralized execution can still be maintained in LSF-SAC through a soft-actor-critic design. We evaluate LSF-SAC on the StarCraft II micromanagement challenge and demonstrate that it outperforms several state-of-the-art methods in challenging collaborative tasks. We further set extensive ablation studies for locating the key factors accounting for its performance improvements. We believe that this new insight can lead to new local value estimation methods and variational deep learning algorithms. A demo video and code of implementation can be found at https://sites.google.com/view/sacmm."
2201.01248,Nodal domain count for the generalized graph $p$-Laplacian,"['Piero Deidda', 'Mario Putti', 'Francesco Tudisco']",ARXIV,http://arxiv.org/pdf/2201.01248v2,2022-01-04T17:06:54Z,2022-08-12T17:49:22Z,['10.48550/arXiv.2201.01248'],"Inspired by the linear Schr\""odinger operator, we consider a generalized $p$-Laplacian operator on discrete graphs and present new results that characterize several spectral properties of this operator with particular attention to the nodal domain count of its eigenfunctions. Just like the one-dimensional continuous $p$-Laplacian, we prove that the variational spectrum of the discrete generalized $p$-Laplacian on forests is the entire spectrum. Moreover, we show how to transfer Weyl's inequalities for the Laplacian operator to the nonlinear case and prove new upper and lower bounds on the number of nodal domains of every eigenfunction of the generalized $p$-Laplacian on generic graphs, including variational eigenpairs. In particular, when applied to the linear case $p=2$, in addition to recovering well-known features, the new results provide novel properties of the linear Schr\""odinger operator."
2201.01249,ExAID: A Multimodal Explanation Framework for Computer-Aided Diagnosis of Skin Lesions,"['Adriano Lucieri', 'Muhammad Naseer Bajwa', 'Stephan Alexander Braun', 'Muhammad Imran Malik', 'Andreas Dengel', 'Sheraz Ahmed']",ARXIV,http://arxiv.org/pdf/2201.01249v1,2022-01-04T17:11:28Z,2022-01-04T17:11:28Z,['10.48550/arXiv.2201.01249'],"One principal impediment in the successful deployment of AI-based Computer-Aided Diagnosis (CAD) systems in clinical workflows is their lack of transparent decision making. Although commonly used eXplainable AI methods provide some insight into opaque algorithms, such explanations are usually convoluted and not readily comprehensible except by highly trained experts. The explanation of decisions regarding the malignancy of skin lesions from dermoscopic images demands particular clarity, as the underlying medical problem definition is itself ambiguous. This work presents ExAID (Explainable AI for Dermatology), a novel framework for biomedical image analysis, providing multi-modal concept-based explanations consisting of easy-to-understand textual explanations supplemented by visual maps justifying the predictions. ExAID relies on Concept Activation Vectors to map human concepts to those learnt by arbitrary Deep Learning models in latent space, and Concept Localization Maps to highlight concepts in the input space. This identification of relevant concepts is then used to construct fine-grained textual explanations supplemented by concept-wise location information to provide comprehensive and coherent multi-modal explanations. All information is comprehensively presented in a diagnostic interface for use in clinical routines. An educational mode provides dataset-level explanation statistics and tools for data and model exploration to aid medical research and education. Through rigorous quantitative and qualitative evaluation of ExAID, we show the utility of multi-modal explanations for CAD-assisted scenarios even in case of wrong predictions. We believe that ExAID will provide dermatologists an effective screening tool that they both understand and trust. Moreover, it will be the basis for similar applications in other biomedical imaging fields."
2201.01250,Transfer Learning for Retinal Vascular Disease Detection: A Pilot Study with Diabetic Retinopathy and Retinopathy of Prematurity,"['Guan Wang', 'Yusuke Kikuchi', 'Jinglin Yi', 'Qiong Zou', 'Rui Zhou', 'Xin Guo']",ARXIV,http://arxiv.org/pdf/2201.01250v1,2022-01-04T17:14:42Z,2022-01-04T17:14:42Z,['10.48550/arXiv.2201.01250'],"Retinal vascular diseases affect the well-being of human body and sometimes provide vital signs of otherwise undetected bodily damage. Recently, deep learning techniques have been successfully applied for detection of diabetic retinopathy (DR). The main obstacle of applying deep learning techniques to detect most other retinal vascular diseases is the limited amount of data available. In this paper, we propose a transfer learning technique that aims to utilize the feature similarities for detecting retinal vascular diseases. We choose the well-studied DR detection as a source task and identify the early detection of retinopathy of prematurity (ROP) as the target task. Our experimental results demonstrate that our DR-pretrained approach dominates in all metrics the conventional ImageNet-pretrained transfer learning approach, currently adopted in medical image analysis. Moreover, our approach is more robust with respect to the stochasticity in the training process and with respect to reduced training samples. This study suggests the potential of our proposed transfer learning approach for a broad range of retinal vascular diseases or pathologies, where data is limited."
2201.01251,Multi-Stage Episodic Control for Strategic Exploration in Text Games,"['Jens Tuyls', 'Shunyu Yao', 'Sham Kakade', 'Karthik Narasimhan']",ARXIV,http://arxiv.org/pdf/2201.01251v3,2022-01-04T17:19:52Z,2022-03-16T01:46:38Z,['10.48550/arXiv.2201.01251'],"Text adventure games present unique challenges to reinforcement learning methods due to their combinatorially large action spaces and sparse rewards. The interplay of these two factors is particularly demanding because large action spaces require extensive exploration, while sparse rewards provide limited feedback. This work proposes to tackle the explore-vs-exploit dilemma using a multi-stage approach that explicitly disentangles these two strategies within each episode. Our algorithm, called eXploit-Then-eXplore (XTX), begins each episode using an exploitation policy that imitates a set of promising trajectories from the past, and then switches over to an exploration policy aimed at discovering novel actions that lead to unseen state spaces. This policy decomposition allows us to combine global decisions about which parts of the game space to return to with curiosity-based local exploration in that space, motivated by how a human may approach these games. Our method significantly outperforms prior approaches by 27% and 11% average normalized score over 12 games from the Jericho benchmark (Hausknecht et al., 2020) in both deterministic and stochastic settings, respectively. On the game of Zork1, in particular, XTX obtains a score of 103, more than a 2x improvement over prior methods, and pushes past several known bottlenecks in the game that have plagued previous state-of-the-art methods."
2201.01252,Laplacian Energies of Vertices,['José Guerrero'],ARXIV,http://arxiv.org/pdf/2201.01252v1,2022-01-04T17:21:40Z,2022-01-04T17:21:40Z,['10.48550/arXiv.2201.01252'],"In this work, we define the Laplacian and Normalized Laplacian energies of vertices in a graph, we derive some of its properties and relate them to combinatorial, spectral and geometric quantities of the graph."
2201.01253,Relaxation to steady states of a binary liquid mixture around an optically heated colloid,"['Takeaki Araki', 'Juan Ruben Gomez-Solano', 'Anna Maciołek']",ARXIV,http://arxiv.org/pdf/2201.01253v1,2022-01-04T17:27:05Z,2022-01-04T17:27:05Z,"['10.48550/arXiv.2201.01253', '10.1103/PhysRevE.105.014123']",We study the relaxation dynamics of a binary liquid mixture near a light-absorbing Janus particle after switching on and off illumination using experiments and theoretical models. The dynamics is controlled by the temperature gradient formed around the heated particle. Our results show that the relaxation is asymmetric: the approach to a nonequilibrium steady state is much slower than the return to thermal equilibrium. Approaching a nonequilibrium steady state is a two-step process leading to the behavior of the spatial variance of concentration field similar to the initial overshoot in response to an external field found in diverse soft materials. The initial growth of concentration fluctuations after switching on illumination follows a power law in agreement with the hydrodynamic and purely diffusive model. The energy out-flow from the system after switching off illumination is well described by a stretched exponential function of time with characteristic time proportional to the ratio of the energy stored in the steady state to the total energy flux in this state.
2201.01254,Trade-offs in the design and communication of flood-risk information,"['Courtney M. Cooper', 'Sanjib Sharma', 'Robert E. Nicholas', 'Klaus Keller']",ARXIV,http://arxiv.org/pdf/2201.01254v1,2022-01-04T17:31:41Z,2022-01-04T17:31:41Z,['10.48550/arXiv.2201.01254'],"There is an increasingly urgent need to develop knowledge and practices to manage climate risks. For example, flood-risk information can inform household decisions such as purchasing a home or flood insurance. However, flood-risk estimates are deeply uncertain, meaning that they are subject to sizeable disagreement. Available flood-risk estimates provide inconsistent and incomplete information and pose communication challenges. The effects of different choices of design and communication options can create confusion in decision-making processes. The climate services literature includes insights into desirable features for producing information that is credible and relevant. Using examples of riverine (fluvial) flood-risk information products and studies in the United States, we assess how existing risk characterizations integrate desirable features outlined in the climate services literature. Improved characterization and communication of decision-relevant (and often deep) uncertainties, including those arising from human decisions, is a crucial next step. We argue that producing relevant flood-risk information requires applying principles of open science and co-production."
2201.01255,Enhanced coupling of electron and nuclear spins by quantum tunneling resonances,"['Anatoli Tsinovoy', 'Or Katz', 'Arie Landau', 'Nimrod Moiseyev']",ARXIV,http://arxiv.org/pdf/2201.01255v1,2022-01-04T17:33:02Z,2022-01-04T17:33:02Z,"['10.48550/arXiv.2201.01255', '10.1103/PhysRevLett.128.013401']","Noble-gas spins feature hours long coherence times owing to their great isolation from the environment, and find practical usage in various applications. However, this isolation leads to extremely slow preparation times, relying on weak spin transfer from an electron-spin ensemble. Here we propose a controllable mechanism to enhance this transfer rate. We analyze the spin dynamics of helium-3 atoms with hot, optically-excited potassium atoms and reveal the formation of quasi-bound states in resonant binary collisions. We find a resonant enhancement of the spin-exchange cross section by up to six orders of magnitude and two orders of magnitude enhancement for the thermally averaged, polarization rate-coefficient. We further examine the effect for various other noble gases and find that the enhancement is universal. We outline feasible conditions under which the enhancement may be experimentally observed and practically utilized."
2201.01256,Minimizing plasma temperature for antimatter mixing experiments,"['E. D. Hunter', 'C. Amsler', 'H. Breuker', 'S. Chesnevskaya', 'G. Costantini', 'R. Ferragut', 'M. Giammarchi', 'A. Gligorova', 'G. Gosta', 'H. Higaki', 'Y. Kanai', 'C. Killian', 'V. Kletzl', 'V. Kraxberger', 'N. Kuroda', 'A. Lanz', 'M. Leali', 'V. Mäckel', 'G. Maero', 'C. Malbrunot', 'V. Mascagna', 'Y. Matsuda', 'S. Migliorati', 'D. J. Murtagh', 'Y. Nagata', 'A. Nanda', 'L. Nowak', 'E. Pasino', 'M. Romé', 'M. C. Simon', 'M. Tajima', 'V. Toso', 'S. Ulmer', 'U. Uggerhøj', 'L. Venturelli', 'A. Weiser', 'E. Widmann', 'T. Wolz', 'Y. Yamazaki', 'J. Zmeskal']",ARXIV,http://arxiv.org/pdf/2201.01256v2,2022-01-04T17:39:37Z,2022-02-02T19:04:10Z,"['10.48550/arXiv.2201.01256', '10.1051/epjconf/202226201007']","The ASACUSA collaboration produces a beam of antihydrogen atoms by mixing pure positron and antiproton plasmas in a strong magnetic field with a double cusp geometry. The positrons cool via cyclotron radiation inside the cryogenic trap. Low positron temperature is essential for increasing the fraction of antihydrogen atoms which reach the ground state prior to exiting the trap. Many experimental groups observe that such plasmas reach equilibrium at a temperature well above the temperature of the surrounding electrodes. This problem is typically attributed to electronic noise and plasma expansion, which heat the plasma. The present work reports anomalous heating far beyond what can be attributed to those two sources. The heating seems to be a result of the axially open trap geometry, which couples the plasma to the external (300 K) environment via microwave radiation."
2201.01257,TAMM: Tensor Algebra for Many-body Methods,"['Erdal Mutlu', 'Ajay Panyala', 'Nitin Gawande', 'Abhishek Bagusetty', 'Jinsung Kim', 'Karol Kowalski', 'Nicholas Bauman', 'Bo Peng', 'Jiri Brabec', 'Sriram Krishnamoorthy']",ARXIV,http://arxiv.org/pdf/2201.01257v4,2022-01-04T17:40:09Z,2023-07-10T17:54:44Z,"['10.48550/arXiv.2201.01257', '10.1063/5.0142433']","Tensor contraction operations in computational chemistry consume significant fractions of computing time on large-scale computing platforms. The widespread use of tensor contractions between large multi-dimensional tensors in describing electronic structure theory has motivated the development of multiple tensor algebra frameworks targeting heterogeneous computing platforms. In this paper, we present Tensor Algebra for Many-body Methods (TAMM), a framework for productive and performance-portable development of scalable computational chemistry methods. The TAMM framework decouples the specification of the computation and the execution of these operations on available high-performance computing systems. With this design choice, the scientific application developers (domain scientists) can focus on the algorithmic requirements using the tensor algebra interface provided by TAMM whereas high-performance computing developers can focus on various optimizations on the underlying constructs such as efficient data distribution, optimized scheduling algorithms, efficient use of intra-node resources (e.g., GPUs). The modular structure of TAMM allows it to be extended to support different hardware architectures and incorporate new algorithmic advances. We describe the TAMM framework and our approach to sustainable development of tensor contraction-based methods in computational chemistry applications. We present case studies that highlight the ease of use as well as the performance and productivity gains compared to other implementations."
2201.01258,On the Arens regularity of Frechet algebras and their biduals,"['Zahra Alimohammadi', 'Ali Rejali']",ARXIV,http://arxiv.org/pdf/2201.01258v1,2022-01-04T17:42:44Z,2022-01-04T17:42:44Z,['10.48550/arXiv.2201.01258'],"In This paper, we study the concept of weakly almost periodic functions on Frechet algebras. For a Frechet algebra A, we show that WAP(A)=wap(A). We also show that A** is Arens regular if and only if both A and WAP(A)* are Arens regular. Finally, for a sequence of Frechet algebras (An), we prove that the Frechet algebra \ell^1-\prod An is Arens regular if and only if each An is Arens regular."
2201.01259,Gauge Invariant Perturbations of General Spherically Symmetric Spacetimes,"['Wentao Liu', 'Xiongjun Fang', 'Jiliang Jing', 'Anzhong Wang']",ARXIV,http://arxiv.org/pdf/2201.01259v4,2022-01-04T17:43:16Z,2022-10-19T01:59:08Z,"['10.48550/arXiv.2201.01259', '10.1007/s11433-022-1956-4']","In this paper, the gauge choices in general spherically symmetric spacetimes have been explored. We construct the gauge invariant variables and the master equations for both the Detweiler easy gauge and the Regge-Wheeler gauge, respectively. The particular cases for $l=0,1$ are also been investigated. Our results provide analytical calculations of metric perturbation in general spherically symmetric spacetimes, which can be applied to various cases, including the Effective-One-Body problem. A simple example is presented to show how the metric perturbation components are related to the source perturbation terms."
2201.01260,Homogeneous functions with nowhere vanishing Hessian determinant,['Connor Mooney'],ARXIV,http://arxiv.org/pdf/2201.01260v1,2022-01-04T17:48:48Z,2022-01-04T17:48:48Z,['10.48550/arXiv.2201.01260'],"We prove that functions that are homogeneous of degree $\alpha \in (0,\,1)$ on $\mathbb{R}^n$ and have nowhere vanishing Hessian determinant cannot change sign."
2201.01261,ENI: Quantifying Environment Compatibility for Natural Walking in Virtual Reality,"['Niall L. Williams', 'Aniket Bera', 'Dinesh Manocha']",ARXIV,http://arxiv.org/pdf/2201.01261v3,2022-01-04T17:49:07Z,2023-07-04T04:03:49Z,"['10.48550/arXiv.2201.01261', '10.1109/VR51125.2022.00061']","We present a novel metric to analyze the similarity between the physical environment and the virtual environment for natural walking in virtual reality. Our approach is general and can be applied to any pair of physical and virtual environments. We use geometric techniques based on conforming constrained Delaunay triangulations and visibility polygons to compute the Environment Navigation Incompatibility (ENI) metric that can be used to measure the complexity of performing simultaneous navigation. We demonstrate applications of ENI for highlighting regions of incompatibility for a pair of environments, guiding the design of the virtual environments to make them more compatible with a fixed physical environment, and evaluating the performance of different redirected walking controllers. We validate the ENI metric using simulations and two user studies. Results of our simulations and user studies show that in the environment pair that our metric identified as more navigable, users were able to walk for longer before colliding with objects in the physical environment. Overall, ENI is the first general metric that can automatically identify regions of high and low compatibility in physical and virtual environments. Our project website is available at https://gamma.umd.edu/eni/."
2201.01262,An algebraic attack to the Bluetooth stream cipher E0,"['Roberto La Scala', 'Sergio Polese', 'Sharwan K. Tiwari', 'Andrea Visconti']",ARXIV,http://arxiv.org/pdf/2201.01262v2,2022-01-04T17:53:57Z,2022-08-08T11:59:15Z,['10.48550/arXiv.2201.01262'],"In this paper we study the security of the Bluetooth stream cipher E0 from the viewpoint it is a ""difference stream cipher"", that is, it is defined by a system of explicit difference equations over the finite field GF(2). This approach highlights some issues of the Bluetooth encryption such as the invertibility of its state transition map, a special set of 14 bits of its 132-bit state which when guessed implies linear equations among the other bits and finally a small number of spurious keys, with 83 guessed bits, which are compatible with a keystream of about 60 bits. Exploiting these issues, we implement an algebraic attack using Gr\""obner bases, SAT solvers and Binary Decision Diagrams. Testing activities suggest that the version based on Gr\""obner bases is the best one and it is able to attack E0 in about 2^79 seconds on an Intel i9 CPU. To the best of our knowledge, this work improves any previous attack based on a short keystream, hence fitting with Bluetooth specifications."
2201.01263,Positive scalar curvature on manifolds with boundary and their doubles,"['Jonathan Rosenberg', 'Shmuel Weinberger']",ARXIV,http://arxiv.org/pdf/2201.01263v2,2022-01-04T17:57:04Z,2022-05-25T21:18:44Z,['10.48550/arXiv.2201.01263'],"This paper is about positive scalar curvature on a compact manifold $X$ with non-empty boundary $\partial X$. In some cases, we completely answer the question of when $X$ has a positive scalar curvature metric which is a product metric near $\partial X$, or when $X$ has a positive scalar curvature metric with positive mean curvature on the boundary, and more generally, we study the relationship between boundary conditions on $\partial X$ for positive scalar curvature metrics on $X$ and the positive scalar curvature problem for the double $M=\operatorname{Dbl}(X,\partial X)$."
2201.01264,Light sources with bias tunable spectrum based on van der Waals interface transistors,"['Hugo Henck', 'Diego Mauro', 'Daniil Domaretskiy', 'Marc Philippi', 'Shahriar Memaran', 'Wenkai Zheng', 'Zhengguang Lu', 'Dmitry Shcherbakov', 'Chun Ning Lau', 'Dmitry Smirnov', 'Luis Balicas', 'Kenji Watanabe', ""Vladimir I. Fal'ko"", 'Ignacio Gutiérrez-Lezama', 'Nicolas Ubrig', 'Alberto F. Morpurgo']",ARXIV,http://arxiv.org/pdf/2201.01264v2,2022-01-04T17:57:58Z,2022-07-08T08:21:22Z,"['10.48550/arXiv.2201.01264', '10.1038/s41467-022-31605-9']","Light-emitting electronic devices are ubiquitous in key areas of current technology, such as data communications, solid-state lighting, displays, and optical interconnects. Controlling the spectrum of the emitted light electrically, by simply acting on the device bias conditions, is an important goal with potential technological repercussions. However, identifying a material platform enabling broad electrical tuning of the spectrum of electroluminescent devices remains challenging. Here, we propose light-emitting field-effect transistors based on van der Waals interfaces of atomically thin semiconductors as a promising class of devices to achieve this goal. We demonstrate that large spectral changes in room-temperature electroluminescence can be controlled both at the device assembly stage -- by suitably selecting the material forming the interfaces -- and on-chip, by changing the bias to modify the device operation point. Even though the precise relation between device bias and kinetics of the radiative transitions remains to be understood, our experiments show that the physical mechanism responsible for light emission is robust, making these devices compatible with simple large areas device production methods."
2201.01265,Limits on primordial black holes detectability with Isatis: A BlackHawk tool,['Jérémy Auffinger'],ARXIV,http://arxiv.org/pdf/2201.01265v2,2022-01-04T18:00:31Z,2022-03-09T09:01:45Z,"['10.48550/arXiv.2201.01265', '10.1140/epjc/s10052-022-10199-y']","Primordial black holes (PBHs) are convenient candidates to explain the elusive dark matter (DM). However, years of constraints from various astronomical observations have constrained their abundance over a wide range of masses, leaving only a narrow window open at $10^{17}\,{\rm g} \lesssim M \lesssim 10^{22}\,$g for all DM in the form of PBHs. We reexamine this disputed window with a critical eye, interrogating the general hypotheses underlying the direct photon constraints. We review 4 levels of assumptions: i) instrument characteristics, ii) prediction of the (extra)galactic photon flux, iii) statistical method of signal-to-data comparison and iv) computation of the Hawking radiation rate. Thanks to Isatis, a new tool designed for the public Hawking radiation code BlackHawk, we first revisit the existing and prospective constraints on the PBH abundance and investigate the impact of assumptions i)-iv). We show that the constraints can vary by several orders of magnitude, advocating the necessity of a reduction of the theoretical sources of uncertainties. Second, we consider an ""ideal"" instrument and we demonstrate that the PBH DM scenario can only be constrained by the direct photon Hawking radiation phenomenon below $M_{\rm max} \sim 10^{20}\,$g. The upper part of the mass window should therefore be closed by other means."
2201.01266,Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images,"['Ali Hatamizadeh', 'Vishwesh Nath', 'Yucheng Tang', 'Dong Yang', 'Holger Roth', 'Daguang Xu']",ARXIV,http://arxiv.org/pdf/2201.01266v1,2022-01-04T18:01:34Z,2022-01-04T18:01:34Z,['10.48550/arXiv.2201.01266'],"Semantic segmentation of brain tumors is a fundamental medical image analysis task involving multiple MRI imaging modalities that can assist clinicians in diagnosing the patient and successively studying the progression of the malignant entity. In recent years, Fully Convolutional Neural Networks (FCNNs) approaches have become the de facto standard for 3D medical image segmentation. The popular ""U-shaped"" network architecture has achieved state-of-the-art performance benchmarks on different 2D and 3D semantic segmentation tasks and across various imaging modalities. However, due to the limited kernel size of convolution layers in FCNNs, their performance of modeling long-range information is sub-optimal, and this can lead to deficiencies in the segmentation of tumors with variable sizes. On the other hand, transformer models have demonstrated excellent capabilities in capturing such long-range information in multiple domains, including natural language processing and computer vision. Inspired by the success of vision transformers and their variants, we propose a novel segmentation model termed Swin UNEt TRansformers (Swin UNETR). Specifically, the task of 3D brain tumor semantic segmentation is reformulated as a sequence to sequence prediction problem wherein multi-modal input data is projected into a 1D sequence of embedding and used as an input to a hierarchical Swin transformer as the encoder. The swin transformer encoder extracts features at five different resolutions by utilizing shifted windows for computing self-attention and is connected to an FCNN-based decoder at each resolution via skip connections. We have participated in BraTS 2021 segmentation challenge, and our proposed model ranks among the top-performing approaches in the validation phase. Code: https://monai.io/research/swin-unetr"
2201.01267,Robust absolute solar flux density calibration for the Murchison Widefield Array,"['Devojyoti Kansabanik', 'Surajit Mondal', 'Divya Oberoi', 'Ayan Biswas', 'Shilpi Bhunia']",ARXIV,http://arxiv.org/pdf/2201.01267v2,2022-01-04T18:02:49Z,2022-03-02T13:55:13Z,"['10.48550/arXiv.2201.01267', '10.3847/1538-4357/ac4bba']","Sensitive radio instruments are optimized for observing faint astronomical sources, and usually need to attenuate the received signal when observing the Sun. There are only a handful of flux density calibrators which can comfortably be observed with the same attenuation setup as the Sun. Additionally, for wide field-of-view (FoV) instruments like the Murchison Widefield Array (MWA) calibrator observations are generally done when the Sun is below the horizon to avoid the contamination from solar emissions. These considerations imply that the usual radio interferometric approach to flux density calibration is not applicable for solar imaging. A novel technique, relying on a good sky model and detailed characterization of the MWA hardware, was developed for solar flux density calibration for MWA. Though successful, this technique is not general enough to be extended to the data from the extended configuration of the MWA Phase II. Here, we present a robust flux density calibration method for solar observations with MWA independent of the array configuration. We use different approaches -- the serendipitous presence of strong sources; detection of numerous background sources using high dynamic range images in the FoV along with the Sun and observations of strong flux density calibrators with and without the additional attenuation used for solar observations; to obtain the flux scaling parameters required for the flux density calibration. Using the present method, we have achieved an absolute flux density uncertainty $\sim10\%$ for solar observations even in the absence of dedicated calibrator observations."
2201.01268,Geometrical representation of subshifts for primitive substitutions,['Paul Mercat'],ARXIV,http://arxiv.org/pdf/2201.01268v2,2022-01-04T18:04:53Z,2023-09-20T09:08:05Z,['10.48550/arXiv.2201.01268'],"For any primitive substitution whose Perron eigenvalue is Pisot unit, we construct a domain exchange measurably conjugated to the subshift. And we give a condition for the subshift to be a finite extension of a torus translation. For the particular case of weakly irreducible Pisot substitution, we show that the subshift is either a finite extension of a torus translation, either a power of the subshift is weakly mixing. And we provide an algorithm to compute eigenvalues of the subshift associated to any primitive pseudo-unimodular substitution."
2201.01269,The overlap distribution at two temperatures for the branching Brownian motion,['Benjamin Bonnefont'],ARXIV,http://arxiv.org/pdf/2201.01269v1,2022-01-04T18:05:52Z,2022-01-04T18:05:52Z,['10.48550/arXiv.2201.01269'],"We study the overlap distribution of two particles chosen under the Gibbs measure at two temperatures for the branching Brownian motion. We first prove the convergence of the overlap distribution using the extended convergence of the extremal process obtained by Bovier and Hartung. We then prove that the mean overlap of two points chosen at different temperatures is strictly smaller than in Derrida's random energy model. The proof of this last result is achieved with the description of the decoration point process obtained by A\""id\'ekon, Berestycki, Brunet and Shi. To our knowledge, it is the first time that this description is being used."
2201.01270,"The Muirhead-Rado inequality, 2: Symmetric means and inequalities",['Melvyn B. Nathanson'],ARXIV,http://arxiv.org/pdf/2201.01270v1,2022-01-04T18:07:17Z,2022-01-04T18:07:17Z,['10.48550/arXiv.2201.01270'],Preliminary results from Nathanson [5] are used to prove the Muirhead and Rado inequalities.
2201.01271,A tale of two double quasars: Hubble constant tension or biases?,"['Luis J. Goicoechea', 'Vyacheslav N. Shalyapin']",ARXIV,http://arxiv.org/pdf/2201.01271v1,2022-01-04T18:08:44Z,2022-01-04T18:08:44Z,['10.48550/arXiv.2201.01271'],"For a flat $\Lambda$CDM (standard) cosmology, a small sample of gravitationally lensed quasars with measured time delays has recently provided a value of the Hubble constant $H_0$ in tension with the $Planck$ flat $\Lambda$CDM result. Trying to check if this tension is real or not, we used basic observational constraints for two double quasars of the GLENDAMA sample (SBS 0909+532 and SDSS J1339+1310) to discuss the underlying value of $H_0$ in a standard cosmology. For SBS 0909+532, we were not able to obtain a reliable measurement of $H_0$. However, the current data of SDSS J1339+1310 are consistent with $H_0$ around 67.8 km s$^{-1}$ Mpc$^{-1}$ and $\sigma (H_0)/H_0 \sim$ 10%. Although the formal uncertainty is still large and mainly due to the lack of details on the mass density profile of the main lens galaxy, the central value of $H_0$ coincides with that of the TDCOSMO+SLACS collaboration (using gravitational lens systems) and is within the 1$\sigma$ interval from $Planck$ cosmic microwave background data. After getting these preliminary encouraging results through only one double quasar, we are currently planning to use several GLENDAMA systems to accurately measure the Hubble constant and put constraints on other cosmological parameters."
2201.01272,Resilience Aspects in Distributed Wireless Electroencephalographic Sampling,"['R. Natarov', 'O. Sudakov', 'Z. Dyka', 'I. Kabin', 'O. Maksymyuk', 'O. Iegorova', 'O. Krishtal', 'P. Langendörfer']",ARXIV,http://arxiv.org/pdf/2201.01272v1,2022-01-04T18:11:36Z,2022-01-04T18:11:36Z,"['10.48550/arXiv.2201.01272', '10.1109/MECO49872.2020.9134157']",Resilience aspects of remote electroencephalography sampling are considered. The possibility to use motion sensors data and measurement of industrial power network interference for detection of failed sampling channels is demonstrated. No significant correlation between signals of failed channels and motion sensors data is shown. Level of 50 Hz spectral component from failed channels significantly differs from level of 50 Hz component of normally operating channel. Conclusions about application of these results for increasing resilience of electroencephalography sampling is made.
2201.01273,Joint Sub-carrier and Power Allocation for Efficient Communication of Cellular UAVs,"['H. Hellaoui', 'M. Bagaa', 'A. Chelli', 'T. Taleb']",ARXIV,http://arxiv.org/pdf/2201.01273v1,2022-01-03T10:31:40Z,2022-01-03T10:31:40Z,['10.48550/arXiv.2201.01273'],"Cellular networks are expected to be the main communication infrastructure to support the expanding applications of Unmanned Aerial Vehicles (UAVs). As these networks are deployed to serve ground User Equipment (UES), several issues need to be addressed to enhance cellular UAVs'services.In this paper, we propose a realistic communication model on the downlink,and we show that the Quality of Service (QoS)for the users is affected by the number of interfering BSs and the impact they cause. The joint problem of sub-carrier and power allocation is therefore addressed. Given its complexity, which is known to be NP-hard, we introduce a solution based on game theory. First, we argue that separating between UAVs and UEs in terms of the assigned sub-carriers reduces the interference impact on the users. This is materialized through a matching game. Moreover, in order to boost the partition, we propose a coalitional game that considers the outcome of the first one and enables users to change their coalitions and enhance their QoS. Furthermore, a power optimization solution is introduced, which is considered in the two games. Performance evaluations are conducted, and the obtained results demonstrate the effectiveness of the propositions."
2201.01274,Coherent structures in plane channel flow of dilute polymer solutions with vanishing inertia,['Alexander Morozov'],ARXIV,http://arxiv.org/pdf/2201.01274v2,2022-01-04T18:14:31Z,2022-06-06T15:02:51Z,"['10.48550/arXiv.2201.01274', '10.1103/PhysRevLett.129.017801']","When subjected to sufficiently strong velocity gradients, solutions of long, flexible polymers exhibit flow instabilities and chaotic motion, often referred to as elastic turbulence. Its mechanism differs from the familiar, inertia-driven turbulence in Newtonian fluids, and is poorly understood. Here, we demonstrate that the dynamics of purely elastic pressure-driven channel flows of dilute polymer solutions are organised by exact coherent structures that take the form of two-dimensional travelling waves. Our results demonstrate that no linear instability is required to sustain such travelling wave solutions, and that their origin is purely elastic in nature. We show that the associated stress profiles are characterised by thin, filament-like arrangements of polymer stretch, which is sustained by a solitary pair of vortices. We discuss the implications of the travelling wave solutions for the transition to elastic turbulence in straight channels, and propose ways for their detection in experiments."
2201.01275,Local Quadruple Pattern: A Novel Descriptor for Facial Image Recognition and Retrieval,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.01275v1,2022-01-03T08:04:38Z,2022-01-03T08:04:38Z,['10.48550/arXiv.2201.01275'],"In this paper a novel hand crafted local quadruple pattern (LQPAT) is proposed for facial image recognition and retrieval. Most of the existing hand-crafted descriptors encodes only a limited number of pixels in the local neighbourhood. Under unconstrained environment the performance of these descriptors tends to degrade drastically. The major problem in increasing the local neighbourhood is that, it also increases the feature length of the descriptor. The proposed descriptor try to overcome these problems by defining an efficient encoding structure with optimal feature length. The proposed descriptor encodes relations amongst the neighbours in quadruple space. Two micro patterns are computed from the local relationships to form the descriptor. The retrieval and recognition accuracies of the proposed descriptor has been compared with state of the art hand crafted descriptors on bench mark databases namely; Caltech-face, LFW, Colour-FERET, and CASIA-face-v5. Result analysis shows that the proposed descriptor performs well under uncontrolled variations in pose, illumination, background and expressions."
2201.01276,Local Directional Gradient Pattern: A Local Descriptor for Face Recognition,"['Soumendu Chakraborty', 'Satish Kumar Singh', 'Pavan Chakraborty']",ARXIV,http://arxiv.org/pdf/2201.01276v1,2022-01-03T08:34:25Z,2022-01-03T08:34:25Z,['10.48550/arXiv.2201.01276'],"In this paper a local pattern descriptor in high order derivative space is proposed for face recognition. The proposed local directional gradient pattern (LDGP) is a 1D local micropattern computed by encoding the relationships between the higher order derivatives of the reference pixel in four distinct directions. The proposed descriptor identifies the relationship between the high order derivatives of the referenced pixel in four different directions to compute the micropattern which corresponds to the local feature. Proposed descriptor considerably reduces the length of the micropattern which consequently reduces the extraction time and matching time while maintaining the recognition rate. Results of the extensive experiments conducted on benchmark databases AT&T, Extended Yale B and CMU-PIE show that the proposed descriptor significantly reduces the extraction as well as matching time while the recognition rate is almost similar to the existing state of the art methods."
2201.01277,LSB Based Non Blind Predictive Edge Adaptive Image Steganography,"['Soumendu Chakraborty', 'Anand Singh Jalal', 'Charul Bhatnagar']",ARXIV,http://arxiv.org/pdf/2201.01277v1,2022-01-03T08:46:23Z,2022-01-03T08:46:23Z,"['10.48550/arXiv.2201.01277', '10.1007/s11042-016-3449-4']",Image steganography is the art of hiding secret message in grayscale or color images. Easy detection of secret message for any state-of-art image steganography can break the stego system. To prevent the breakdown of the stego system data is embedded in the selected area of an image which reduces the probability of detection. Most of the existing adaptive image steganography techniques achieve low embedding capacity. In this paper a high capacity Predictive Edge Adaptive image steganography technique is proposed where selective area of cover image is predicted using Modified Median Edge Detector (MMED) predictor to embed the binary payload (data). The cover image used to embed the payload is a grayscale image. Experimental results show that the proposed scheme achieves better embedding capacity with minimum level of distortion and higher level of security. The proposed scheme is compared with the existing image steganography schemes. Results show that the proposed scheme achieves better embedding rate with lower level of distortion.
2201.01278,Understanding Power and Energy Utilization in Large Scale Production Physics Simulation Codes,"['Brian S. Ryujin', 'Arturo Vargas', 'Ian Karlin', 'Shawn A. Dawson', 'Kenneth Weiss', 'Adam Bertsch', 'M. Scott McKinley', 'Michael R. Collette', 'Si D. Hammond', 'Kevin Pedretti', 'Robert N. Rieben']",ARXIV,http://arxiv.org/pdf/2201.01278v1,2022-01-04T18:18:30Z,2022-01-04T18:18:30Z,['10.48550/arXiv.2201.01278'],"Power is an often-cited reason for moving to advanced architectures on the path to Exascale computing. This is due to the practical concern of delivering enough power to successfully site and operate these machines, as well as concerns over energy usage while running large simulations. Since accurate power measurements can be difficult to obtain, processor thermal design power (TDP) is a possible surrogate due to its simplicity and availability. However, TDP is not indicative of typical power usage while running simulations. Using commodity and advance technology systems at Lawrence Livermore National Laboratory (LLNL) and Sandia National Laboratory, we performed a series of experiments to measure power and energy usage in running simulation codes. These experiments indicate that large scale LLNL simulation codes are significantly more efficient than a simple processor TDP model might suggest."
2201.01279,Hawking temperature and the bound on greybody factors in $D = 4$ double field theory,['Yang Liu'],ARXIV,http://arxiv.org/pdf/2201.01279v1,2021-12-31T14:27:42Z,2021-12-31T14:27:42Z,"['10.48550/arXiv.2201.01279', '10.1140/epjc/s10052-022-11022-4']","We investigate the basic properties of Hawking radiation for spherical solutions in $D = 4$ double field theory. We give the expression of the Hawking temperature for the solution and then discuss the results of various limits. We find that for all these limits only Schwarzschild solution and F-JNW solution can generate Hawking radiation. Moreover, we obtain the lower bound on greybody factors $\sigma_l(\omega)$ for the spherical solutions in $D = 4$ double field theory. In particular, we calculate the bound on greybody factors $\sigma_l(\omega)$ for F-JNW solution. For F-JNW solution, $\sigma_l(\omega)$ monotonically increases with the increase of $a(b)$ for fixed $b(a)$."
2201.01280,The Effect of Rényi Entropy on Hawking Radiation,['Yang Liu'],ARXIV,http://arxiv.org/pdf/2201.01280v1,2021-12-31T14:15:30Z,2021-12-31T14:15:30Z,['10.48550/arXiv.2201.01280'],"It is widely believed that Hawking radiation originates from excitations near the horizons of black holes. However, Giddings proposed that the Hawking radiation spectrum that characterizes evaporating semi-classical black holes originates from a quantum atmosphere, which extends beyond the horizon of a black hole. Although several research projects have been conducted in this field, they have not yet taken into account the effect of R\'enyi entropy. In the present article, we will therefore consider the effect of R\'enyi entropy on Hawking radiation power. We assume that if the effect of R\'enyi entropy is very small, we suggest that the Hawking radiation should originate from the quantum atmosphere which extends beyond the black hole's horizon for finite dimensions. That is, that Giddings' suggestion is the more likely of the above possibilities. However, for infinite dimensions, both suggestions are equally credible. We briefly consider the very large effect of R\'enyi entropy on Hawking radiation power as well. We find that if the effect of R\'enyi entropy is very large and {\omega}/T_{BH} is very small, then the power spectral density S_R is proportional to the power spectral density S_{BH}."
2201.01281,The emerging spectrum of flexible work locations: implications for travel demand and carbon emissions,"['Nicholas S. Caros', 'Xiaotong Guo', 'Jinhua Zhao']",ARXIV,http://arxiv.org/pdf/2201.01281v2,2022-01-04T18:23:19Z,2023-03-10T19:26:18Z,['10.48550/arXiv.2201.01281'],"Many studies of the effect of remote work on travel demand assume that remote work takes place entirely at home. Recent evidence, however, shows that in the United States, remote workers are choosing to spend approximately one third of their remote work hours outside of the home at cafes, co-working spaces or the homes of friends and family. Commutes to these ""third places"" could offset much of the reduction in congestion and carbon emissions from commuting that could be expected from greater shares of remote work. To estimate the impact of third places on congestion and carbon emission from commuting, this study uses a national survey of thousands of remote workers and large-scale mobile trace data to predict current and future commuting patterns for the Chicago metropolitan area. The study reveals that ignoring third places leads to an underestimation of carbon emissions from commute-based travel demand by 470 gigatons per year, or 24% of the total true emissions. Moreover, if workers' latent desire for greater levels of remote work are realized in the future, the emissions benefits will be reduced further. The spatial analyses imply that there is a decrease in visits to the city center and outskirts, but an increase in visits to near suburban areas. Implications of these results for urban transportation and land use policy are discussed."
2201.01282,Examples of pairs of ordered congruent-like n-gons with different areas,"['Michele Gaeta', 'Giovanni Vincenzi']",ARXIV,http://arxiv.org/pdf/2201.01282v1,2021-12-25T05:56:04Z,2021-12-25T05:56:04Z,['10.48550/arXiv.2201.01282'],"In this Paper, for every $n>5$, we show examples of pairs articulated $n$-gons $P$ and $P'$ of different area such that every ordered sequence of internal angles of $P$ coincide with some ordered sequence of internal angles of $P'$."
2201.01283,Self-supervised Learning from 100 Million Medical Images,"['Florin C. Ghesu', 'Bogdan Georgescu', 'Awais Mansoor', 'Youngjin Yoo', 'Dominik Neumann', 'Pragneshkumar Patel', 'R. S. Vishwanath', 'James M. Balter', 'Yue Cao', 'Sasa Grbic', 'Dorin Comaniciu']",ARXIV,http://arxiv.org/pdf/2201.01283v1,2022-01-04T18:27:04Z,2022-01-04T18:27:04Z,['10.48550/arXiv.2201.01283'],"Building accurate and robust artificial intelligence systems for medical image assessment requires not only the research and design of advanced deep learning models but also the creation of large and curated sets of annotated training examples. Constructing such datasets, however, is often very costly -- due to the complex nature of annotation tasks and the high level of expertise required for the interpretation of medical images (e.g., expert radiologists). To counter this limitation, we propose a method for self-supervised learning of rich image features based on contrastive learning and online feature clustering. For this purpose we leverage large training datasets of over 100,000,000 medical images of various modalities, including radiography, computed tomography (CT), magnetic resonance (MR) imaging and ultrasonography. We propose to use these features to guide model training in supervised and hybrid self-supervised/supervised regime on various downstream tasks. We highlight a number of advantages of this strategy on challenging image assessment problems in radiography, CT and MR: 1) Significant increase in accuracy compared to the state-of-the-art (e.g., AUC boost of 3-7% for detection of abnormalities from chest radiography scans and hemorrhage detection on brain CT); 2) Acceleration of model convergence during training by up to 85% compared to using no pretraining (e.g., 83% when training a model for detection of brain metastases in MR scans); 3) Increase in robustness to various image augmentations, such as intensity variations, rotations or scaling reflective of data variation seen in the field."
2201.01284,(5+1)-Dimensional Analytical Brane-World Models: Intersecting Thick Branes,"['Henrique Matheus Gauy', 'Alex E. Bernardini']",ARXIV,http://arxiv.org/pdf/2201.01284v1,2022-01-04T18:28:02Z,2022-01-04T18:28:02Z,['10.48550/arXiv.2201.01284'],"Two co-dimensional thick brane-worlds are investigated in quite general terms for two intersecting scalar fields generating the extra dimension defect. In general, when one considers two co-dimensional thick brane-worlds, the warp factor is constructed as a string-like defect. Considering a twofold-warp factor constructed from two intersecting warp factors, an alternative bulk configuration is examined. With the brane localization thus driven by two crossing scalar fields, the possible solvable models obtained from such a two co-dimensional setup are systematically discussed. The obtained solutions are classified as five different models organized into two subsets for which some of their physical properties are evaluated. For models $I$ and $II$, in the first subset, Einstein equation solutions are rigidly defined, up to some arbitrary constant. For models $III$, $IV$ and $V$, in the second subset, an additional degree of freedom not constrained by Einstein equations is admitted. The solutions are all obtained from a departure statement of assuming a conformally flat metric for the internal space, which is concomitant to the proper choice of coordinates. Eventual singularities in the curvature are identified, however, without affecting the physical appeal of the solutions described in terms of the stress energy tensor patterns, which are shown to be free of singularities for model $IV$, besides admitting straightforward reductions to $(4+1)$-dimensions. In particular, from the framework of models $III$ and $IV$, one is able to achieve brane-world solutions over two different geometries of $\mathbb{S}^{2}$ which, as demonstrated, can be reduced to trivial and non-trivial extensions of the well-known $(4+1)$-dimensional brane-worlds."
2201.01285,Dynamic Suffix Array with Polylogarithmic Queries and Updates,"['Dominik Kempa', 'Tomasz Kociumaka']",ARXIV,http://arxiv.org/pdf/2201.01285v1,2022-01-04T18:28:45Z,2022-01-04T18:28:45Z,"['10.48550/arXiv.2201.01285', '10.1145/3519935.3520061']","The suffix array $SA[1..n]$ of a text $T$ of length $n$ is a permutation of $\{1,\ldots,n\}$ describing the lexicographical ordering of suffixes of $T$, and it is considered to be among of the most important data structures in string algorithms, with dozens of applications in data compression, bioinformatics, and information retrieval. One of the biggest drawbacks of the suffix array is that it is very difficult to maintain under text updates: even a single character substitution can completely change the contents of the suffix array. Thus, the suffix array of a dynamic text is modelled using suffix array queries, which return the value $SA[i]$ given any $i\in[1..n]$. Prior to this work, the fastest dynamic suffix array implementations were by Amir and Boneh. At ISAAC 2020, they showed how to answer suffix array queries in $\tilde{O}(k)$ time, where $k\in[1..n]$ is a trade-off parameter, with $\tilde{O}(\frac{n}{k})$-time text updates. In a very recent preprint [2021], they also provided a solution with $O(\log^5 n)$-time queries and $\tilde{O}(n^{2/3})$-time updates. We propose the first data structure that supports both suffix array queries and text updates in $O({\rm polylog}\,n)$ time (achieving $O(\log^4 n)$ and $O(\log^{3+o(1)} n)$ time, respectively). Our data structure is deterministic and the running times for all operations are worst-case. In addition to the standard single-character edits (character insertions, deletions, and substitutions), we support (also in $O(\log^{3+o(1)} n)$ time) the ""cut-paste"" operation that moves any (arbitrarily long) substring of $T$ to any place in $T$. We complement our structure by a hardness result: unless the Online Matrix-Vector Multiplication (OMv) Conjecture fails, no data structure with $O({\rm polylog}\,n)$-time suffix array queries can support the ""copy-paste"" operation in $O(n^{1-\epsilon})$ time for any $\epsilon>0$."
2201.01286,Catching Polygons,"['Bradley McCoy', 'Eli Quist', 'Anna Schenfisch']",ARXIV,http://arxiv.org/pdf/2201.01286v1,2022-01-04T18:29:03Z,2022-01-04T18:29:03Z,['10.48550/arXiv.2201.01286'],"Consider an arrangement of $k$ lines intersecting the unit square. There is some minimum scaling factor so that any placement of a rectangle with aspect ratio $1 \times p$ with $p\geq 1$ must non-transversely intersect some portion of the arrangement or unit square. Assuming the lines of the arrangement are axis-aligned, we show the optimal arrangement depends on the aspect ratio of the rectangle. In particular, the optimal arrangement is either evenly spaced parallel lines or an evenly spaced grid of lines. We present the precise aspect ratios of rectangles for which each of the two nets is optimal."
2201.01287,An equivariant neural operator for developing nonlocal tensorial constitutive models,"['Jiequn Han', 'Xu-Hui Zhou', 'Heng Xiao']",ARXIV,http://arxiv.org/pdf/2201.01287v2,2022-01-04T18:30:32Z,2022-12-01T20:11:55Z,"['10.48550/arXiv.2201.01287', '10.1016/j.jcp.2023.112243']","Developing robust constitutive models is a fundamental and longstanding problem for accelerating the simulation of complicated physics. Machine learning provides promising tools to construct constitutive models based on various calibration data. In this work, we propose a neural operator to develop nonlocal constitutive models for tensorial quantities through a vector-cloud neural network with equivariance (VCNN-e). The VCNN-e respects all the invariance properties desired by constitutive models, faithfully reflects the region of influence in physics, and is applicable to different spatial resolutions. By design, the model guarantees that the predicted tensor is invariant to the frame translation and ordering (permutation) of the neighboring points. Furthermore, it is equivariant to the frame rotation, i.e., the output tensor co-rotates with the coordinate frame. We evaluate the VCNN-e by using it to emulate the Reynolds stress transport model for turbulent flows, which directly computes the Reynolds stress tensor to close the Reynolds-averaged Navier--Stokes (RANS) equations. The evaluation is performed in two situations: (1) emulating the Reynolds stress model through synthetic data generated from the Reynolds stress transport equations with closure models, and (2) predicting the Reynolds stress by learning from data generated from direct numerical simulations. Such a priori evaluations of the proposed network pave the way for developing and calibrating robust and nonlocal, non-equilibrium closure models for the RANS equations."
2201.01288,"Automated Graph Machine Learning: Approaches, Libraries and Directions","['Xin Wang', 'Ziwei Zhang', 'Wenwu Zhu']",ARXIV,http://arxiv.org/pdf/2201.01288v1,2022-01-04T18:31:31Z,2022-01-04T18:31:31Z,['10.48550/arXiv.2201.01288'],"Graph machine learning has been extensively studied in both academic and industry. However, as the literature on graph learning booms with a vast number of emerging methods and techniques, it becomes increasingly difficult to manually design the optimal machine learning algorithm for different graph-related tasks. To tackle the challenge, automated graph machine learning, which aims at discovering the best hyper-parameter and neural architecture configuration for different graph tasks/data without manual design, is gaining an increasing number of attentions from the research community. In this paper, we extensively discuss automated graph machine approaches, covering hyper-parameter optimization (HPO) and neural architecture search (NAS) for graph machine learning. We briefly overview existing libraries designed for either graph machine learning or automated machine learning respectively, and further in depth introduce AutoGL, our dedicated and the world's first open-source library for automated graph machine learning. Last but not least, we share our insights on future research directions for automated graph machine learning. This paper is the first systematic and comprehensive discussion of approaches, libraries as well as directions for automated graph machine learning."
2201.01289,Self-directed Machine Learning,"['Wenwu Zhu', 'Xin Wang', 'Pengtao Xie']",ARXIV,http://arxiv.org/pdf/2201.01289v2,2022-01-04T18:32:06Z,2022-01-08T04:55:40Z,['10.48550/arXiv.2201.01289'],"Conventional machine learning (ML) relies heavily on manual design from machine learning experts to decide learning tasks, data, models, optimization algorithms, and evaluation metrics, which is labor-intensive, time-consuming, and cannot learn autonomously like humans. In education science, self-directed learning, where human learners select learning tasks and materials on their own without requiring hands-on guidance, has been shown to be more effective than passive teacher-guided learning. Inspired by the concept of self-directed human learning, we introduce the principal concept of Self-directed Machine Learning (SDML) and propose a framework for SDML. Specifically, we design SDML as a self-directed learning process guided by self-awareness, including internal awareness and external awareness. Our proposed SDML process benefits from self task selection, self data selection, self model selection, self optimization strategy selection and self evaluation metric selection through self-awareness without human guidance. Meanwhile, the learning performance of the SDML process serves as feedback to further improve self-awareness. We propose a mathematical formulation for SDML based on multi-level optimization. Furthermore, we present case studies together with potential applications of SDML, followed by discussing future research directions. We expect that SDML could enable machines to conduct human-like self-directed learning and provide a new perspective towards artificial general intelligence."
2201.01290,Restoring the structure: A modular analysis of ego-driven organizational networks,"['Robert P. Dalka', 'Justyna P. Zwolak']",ARXIV,http://arxiv.org/pdf/2201.01290v1,2022-01-04T18:39:55Z,2022-01-04T18:39:55Z,['10.48550/arXiv.2201.01290'],"Organizational network analysis (ONA) is a method for studying interactions within formal organizations. The utility of ONA has grown substantially over the years as means to analyze the relationships developed within and between teams, departments, and other organizational units. The mapping and quantifying of these relationships have been shown to provide insight into the exchange of information and resources, the building of social capital, and the spread of culture within and between organizations. However, the ethical concerns regarding personally identifiable information (PII) that exist for traditional social science research are made more pertinent in ONA, as the relational nature of the network may leave participants open to identification by organization management. To address this, we propose a method of generating a network of organizational groups (e.g. units, departments, teams) through the projection of ego-networks absent of PII. We validate this method through modular analysis of the resulting networks and compare the identified structure to a known structure of the organization. The methodology lays a foundation for performing ONA that needs only anonymous ego-centric data to identify large-scale aspects of organizational structures."
2201.01291,AVIP: a low temperature plasma code,"['Lionel Cheng', 'Nicolas Barleon', 'Olivier Vermorel', 'Benedicte Cuenot', 'Anne Bourdon']",ARXIV,http://arxiv.org/pdf/2201.01291v2,2022-01-04T18:43:24Z,2022-09-06T14:50:34Z,['10.48550/arXiv.2201.01291'],"A new unstructured, massively parallel code dedicated to low temperature plasmas, AVIP, is presented to simulate plasma discharges in interaction with combustion. The plasma species are modeled in a drift-diffusion formulation and the Poisson equation is solved consistently with the charged species. Plasma discharges introduce stiff source terms on the reactive Navier-Stokes equations and Riemann solvers, more robust than the schemes available in AVBP, have been implemented in AVIP and reported back in AVBP to solve the reactive Navier-Stokes equations. The validation of all the numerical schemes is carried out in this paper where numerous validation cases are presented for the plasma drift-diffusions equations and the reactive Navier-Stokes equations."
2201.01292,Klein-Gordon equation in $q$-deformed Euclidean space,['Hartmut Wachter'],ARXIV,http://arxiv.org/pdf/2201.01292v1,2022-01-04T18:46:43Z,2022-01-04T18:46:43Z,['10.48550/arXiv.2201.01292'],"We introduce $q$-versions of the Klein-Gordon equation in the three-dimensional $q$-deformed Euclidean space. We determine plane wave solutions to our $q$-deformed Klein-Gordon equations. We show that these plane wave solutions form a complete orthogonal system. We discuss the propagators of our $q$-deformed Klein-Gordon equations. We derive continuity equations for the charge density, the energy density, and the momentum density of a $q$-deformed spin-zero particle."
2201.01293,A Transformer-Based Siamese Network for Change Detection,"['Wele Gedara Chaminda Bandara', 'Vishal M. Patel']",ARXIV,http://arxiv.org/pdf/2201.01293v7,2022-01-04T18:55:22Z,2022-09-02T01:41:29Z,['10.48550/arXiv.2201.01293'],"This paper presents a transformer-based Siamese network architecture (abbreviated by ChangeFormer) for Change Detection (CD) from a pair of co-registered remote sensing images. Different from recent CD frameworks, which are based on fully convolutional networks (ConvNets), the proposed method unifies hierarchically structured transformer encoder with Multi-Layer Perception (MLP) decoder in a Siamese network architecture to efficiently render multi-scale long-range details required for accurate CD. Experiments on two CD datasets show that the proposed end-to-end trainable ChangeFormer architecture achieves better CD performance than previous counterparts. Our code is available at https://github.com/wgcban/ChangeFormer."
2201.01294,3DVSR: 3D EPI Volume-based Approach for Angular and Spatial Light field Image Super-resolution,"['Trung-Hieu Tran', 'Jan Berberich', 'Sven Simon']",ARXIV,http://arxiv.org/pdf/2201.01294v1,2022-01-04T18:57:00Z,2022-01-04T18:57:00Z,"['10.48550/arXiv.2201.01294', '10.1016/j.sigpro.2021.108373']","Light field (LF) imaging, which captures both spatial and angular information of a scene, is undoubtedly beneficial to numerous applications. Although various techniques have been proposed for LF acquisition, achieving both angularly and spatially high-resolution LF remains a technology challenge. In this paper, a learning-based approach applied to 3D epipolar image (EPI) is proposed to reconstruct high-resolution LF. Through a 2-stage super-resolution framework, the proposed approach effectively addresses various LF super-resolution (SR) problems, i.e., spatial SR, angular SR, and angular-spatial SR. While the first stage provides flexible options to up-sample EPI volume to the desired resolution, the second stage, which consists of a novel EPI volume-based refinement network (EVRN), substantially enhances the quality of the high-resolution EPI volume. An extensive evaluation on 90 challenging synthetic and real-world light field scenes from 7 published datasets shows that the proposed approach outperforms state-of-the-art methods to a large extend for both spatial and angular super-resolution problem, i.e., an average peak signal to noise ratio improvement of more than 2.0 dB, 1.4 dB, and 3.14 dB in spatial SR $\times 2$, spatial SR $\times 4$, and angular SR respectively. The reconstructed 4D light field demonstrates a balanced performance distribution across all perspective images and presents superior visual quality compared to the previous works."
2201.01295,On the Covariant Hamilton-Jacobi Equation for the Teleparallel Equivalent of General Relativity,"['Monika E. Pietrzyk', 'Cécile Barbachoux']",ARXIV,http://arxiv.org/pdf/2201.01295v1,2022-01-04T18:57:32Z,2022-01-04T18:57:32Z,['10.48550/arXiv.2201.01295'],The covariant Hamilton-Jacobi equation for the Teleparallel Equivalent of General Relativity is derived based on the analysis of the second-class constraints within the covariant Hamiltonian theory of De Donder-Weyl according to the constraints algorithm developed by Kanatchikov.
2201.01296,Dynamical tuning of the chemical potential to achieve a target particle number in grand canonical Monte Carlo simulations,"['Cole Miles', 'Benjamin Cohen-Stead', 'Owen Bradley', 'Steven Johnston', 'Richard Scalettar', 'Kipton Barros']",ARXIV,http://arxiv.org/pdf/2201.01296v2,2022-01-04T18:59:50Z,2022-04-14T04:21:26Z,"['10.48550/arXiv.2201.01296', '10.1103/PhysRevE.105.045311']","We present a method to facilitate Monte Carlo simulations in the grand canonical ensemble given a target mean particle number. The method imposes a fictitious dynamics on the chemical potential, to be run concurrently with the Monte Carlo sampling of the physical system. Corrections to the chemical potential are made according to time-averaged estimates of the mean and variance of the particle number, with the latter being proportional to thermodynamic compressibility. We perform a variety of tests, and in all cases find rapid convergence of the chemical potential -- inexactness of the tuning algorithm contributes only a minor part of the total measurement error for realistic simulations."
2201.01297,Online Multi-Object Tracking with Unsupervised Re-Identification Learning and Occlusion Estimation,"['Qiankun Liu', 'Dongdong Chen', 'Qi Chu', 'Lu Yuan', 'Bin Liu', 'Lei Zhang', 'Nenghai Yu']",ARXIV,http://arxiv.org/pdf/2201.01297v1,2022-01-04T18:59:58Z,2022-01-04T18:59:58Z,['10.48550/arXiv.2201.01297'],"Occlusion between different objects is a typical challenge in Multi-Object Tracking (MOT), which often leads to inferior tracking results due to the missing detected objects. The common practice in multi-object tracking is re-identifying the missed objects after their reappearance. Though tracking performance can be boosted by the re-identification, the annotation of identity is required to train the model. In addition, such practice of re-identification still can not track those highly occluded objects when they are missed by the detector. In this paper, we focus on online multi-object tracking and design two novel modules, the unsupervised re-identification learning module and the occlusion estimation module, to handle these problems. Specifically, the proposed unsupervised re-identification learning module does not require any (pseudo) identity information nor suffer from the scalability issue. The proposed occlusion estimation module tries to predict the locations where occlusions happen, which are used to estimate the positions of missed objects by the detector. Our study shows that, when applied to state-of-the-art MOT methods, the proposed unsupervised re-identification learning is comparable to supervised re-identification learning, and the tracking performance is further improved by the proposed occlusion estimation module."
2201.01298,On the nature of radio-wave radiation from particle cascades,['Clancy W. James'],ARXIV,http://arxiv.org/pdf/2201.01298v1,2022-01-04T01:57:28Z,2022-01-04T01:57:28Z,"['10.48550/arXiv.2201.01298', '10.1103/PhysRevD.105.023014']","The nature of the radio-wave radiation generated by particle cascades in both the Earth's atmosphere and dense media such as ice has, historically, been much debated. This situation changed in the early 2010's, with the community converging on the common terminology of ""geomagnetic"" and ""Askaryan"" radiation to describe the two emission mechanisms. However, this convergence arose from discussions at various conferences and workshops, and was ultimately reached through agreement between simulation codes and experimental measurements. In this article therefore, I use relatively simple geometrical arguments, and a minimum of calculations based on single particle tracks, to explain the nature of radiation from extensive air showers (EAS) and cascades in dense media such as ice. I identify well-determined frequency regimes where the radiation from the Askaryan effect will be bremsstrahlung-like and Cherenkov-like, being respectively below/above 1 GHz in EAS and 100 MHz in dense media; and where geomagnetic emission will be transverse-current-like and where it will resemble synchrotron radiation, respectively below/above a few GHz in EAS, depending on the height of cascade development. I suggest how these transitions in the nature of the emission may be experimentally observed."
2201.01299,"Von Neumann's book, the Compton-Simon experiment and the collapse hypothesis",['R. N. Sen'],ARXIV,http://arxiv.org/pdf/2201.01299v1,2022-01-04T10:50:08Z,2022-01-04T10:50:08Z,['10.48550/arXiv.2201.01299'],"Few things in physics have caused so much hand-wringing as von Neumann's collapse hypothesis. Unable to derive it mathematically, von Neumann attributed it to interaction with the observer's brain! Few physicists agreed, but tweaks of von Neumann's measurement theory did not lead to collapse, and Shimony and Brown proved theorems establishing `the insolubility of the quantum measurement problem'. Many different `interpretations' of quantum mechanics were put forward, none gained a consensus, and some scholars suggested that the foundations of quantum mechanics were flawed to begin with. Yet, in the last ninety years, no-one looked into now von Neumann had arrived at his collapse hypothesis! Von Neumann based his argument on the experiment of Compton and Simon. But, by comparing readings from von Neumann's book and the Compton-Simon paper, we find that the experiment provides no evidence for the collapse hypothesis; von Neumann had misread it completely! We suggest that von Neumann had relied on his phenomenal memory rather than the printed Compton-Simon paper, and his memory had failed him for once. Our finding has considerable implications for physics, which -- briefly sketched here -- will be discussed elsewhere in detail. An Appendix raises some questions for historians of physics."
